## 向量索引的维度跟索引类型有哪些？

答：向量索引的维度是指向量的长度，也就是向量中包含的浮点数的个数。向量的维度决定了向量所能表示的信息的复杂度和精度。一般来说，向量的维度越高，向量所能表示的信息越丰富，但也越难进行检索和计算。不同的应用场景可能需要不同的向量维度，例如文本嵌入通常在几百到几千维之间，而图像嵌入通常在几千到几万维之间。

向量索引的类型是指用于存储和检索向量的数据结构和算法。向量索引的类型决定了向量检索的效率和准确度。一般来说，向量索引可以分为两大类：精确索引和近似索引。精确索引可以保证找到与查询向量最相似的向量，但是计算代价很高，只适合小规模数据集。近似索引可以在牺牲一定准确度的情况下，大大提高检索速度和扩展性，适合大规模数据集。

不同的向量索引类型有不同的优缺点和适用场景，例如：

- 线性扫描：最简单的精确索引方法，就是遍历所有向量，计算与查询向量的相似度，然后排序返回。这种方法没有任何预处理或空间优化，因此非常慢，只适合极小规模数据集。
- 倒排文件：一种常用的精确索引方法，就是将每个向量分成若干段，并为每个段建立一个倒排列表，记录包含该段的所有向量的ID。这样，在检索时，只需要查找与查询向量相同段的倒排列表，然后对候选向量进行精确计算。这种方法可以大大减少检索范围，提高检索速度，但是需要较大的存储空间，并且对于高维或稀疏向量效果不佳。
- 局部敏感哈希：一种常用的近似索引方法，就是将每个向量映射到一个或多个哈希桶中，使得相似的向量有较高概率落入同一个桶。这样，在检索时，只需要查找与查询向量相同桶的候选向量，然后对其进行排序返回。这种方法可以有效降低检索复杂度，并且支持多种相似度度量，但是需要调整合适的哈希函数和参数，并且可能存在哈希冲突或丢失最近邻。
- 乘积量化：一种常用的近似索引方法，就是将每个向量分成若干子向量，并为每个子向量建立一个有限大小的码本，记录子向量可能取值的离散集合。这样，在存储时，只需要记录每个子向量对应码本中的编码，在检索时，只需要对编码进行快速比较或计算近似距离。这种方法可以大大压缩存储空间，并且提高检索速度，但是需要预先训练码本，并且牺牲一定准确度。
- 图搜索：一种常用的近似索引方法，就是将所有向量构建成一个图结构，并为每个节点（即每个向量）维护一个邻居列表，记录与其最相似的若干节点。这样，在检索时，只需要从一个随机节点开始，在图上进行贪心遍历或随机游走，直到找到局部最优或全局最优节点作为结果返回。这种方法可以有效利用数据之间的结构信息，并且支持动态更新数据集，但是需要预先构建图结构，并且可能存在局部最优或陷入死循环。

Pinecone是一个云端的向量数据库服务，它支持多种维度和类型的向量索引。根据官方文档：

- Pinecone支持任意正整数作为向量维度
- Pinecone支持三种类型的向量索引：flat、ivf和hnsw
- flat类型是线性扫描方法，适合小规模数据集或对准确度要求很高的场景
- ivf类型是乘积量化方法，适合中等规模数据集或对速度和空间要求较高的场景
- hnsw类型是图搜索方法，适合大规模数据集或对动态更新要求较高的场景

## Vector search 中的 distance metrics 是什么？

答：Vector search distance metrics是指用于衡量两个向量之间相似度或距离的度量标准。不同的距离度量可能反映不同的向量特征或关系，因此在进行向量检索时，需要根据具体的应用场景和数据特点选择合适的距离度量。

举例来说，假设我们有以下四个向量：

- A = [1, 2]
- B = [3, 4]
- C = [5, 6]
- D = [-1, -2]

我们可以用不同的距离度量来计算它们之间的相似度或距离，例如：

- 内积：内积是两个向量的点乘，它反映了两个向量在同一方向上的投影长度的乘积。内积越大，表示两个向量越相似。例如，A和B的内积是11，A和D的内积是-5，所以A和B更相似。
- 余弦相似度：余弦相似度是两个向量的夹角的余弦值，它反映了两个向量之间的方向相似度。余弦相似度越接近1，表示两个向量越相似。例如，A和B的余弦相似度是0.98，A和D的余弦相似度是-1，所以A和B更相似。
- 欧氏距离：欧氏距离是两个向量之间的直线距离，它反映了两个向量之间的绝对差异。欧氏距离越小，表示两个向量越相似。例如，A和B的欧氏距离是2.83，A和D的欧氏距离是4.24，所以A和B更相似。
- 曼哈顿距离：曼哈顿距离是两个向量之间的坐标差的绝对值之和，它反映了两个向量在各个维度上的差异。曼哈顿距离越小，表示两个向量越相似。例如，A和B的曼哈顿距离是4，A和D的曼哈顿距离是6，所以A和B更相似。
- 汉明距离：汉明距离是两个二进制向量之间不同位的个数，它反映了两个向量在二进制表示上的差异。汉明距离越小，表示两个向量越相似。例如，如果我们将A、B、C、D转换为二进制形式：

  - A = [01, 10]
  - B = [11, 00]
  - C = [01, 10]
  - D = [11, 00]

  那么A和B的汉明距离是4，A和C的汉明距离是0，所以A和C更相似。

问：向量数据是如何存储的？

答：向量数据的存储方式取决于向量数据库的具体实现，不同的方案可能有不同的优化技术。但是一般来说，向量数据的存储可以分为两个层次：

- 数据层：这一层负责存储向量数据的原始值，以及与之相关的结构化数据，如主键、标签等。数据层通常采用分布式文件系统或对象存储系统来实现，以支持海量数据的存储和备份。例如，Milvus²使用MinIO作为其数据层的存储系统。
- 索引层：这一层负责为向量数据构建索引结构，以加速相似度搜索的效率。索引层通常采用各种近似最近邻（ANN）算法来实现，如LSH³、k-d tree⁴、PQ等。索引层通常需要占用较少的存储空间，但是需要较高的计算能力。例如，Milvus支持多种索引类型，如IVF_FLAT、IVF_SQ8、HNSW等。

向量数据库在存储向量数据时，通常需要在数据层和索引层之间进行同步和更新，以保证数据的一致性和可用性。同时，向量数据库还需要提供查询接口和分析接口，以方便用户对向量数据进行检索和分析。

例子：

假设我们有一些向量数据，它们是由一些数字组成的，比如[1,2,3]，[4,5,6]，[7,8,9]等。我们想把这些向量数据存储起来，方便以后查找和分析。

- 一种方法是用数据层，就是把向量数据的原始值直接存储在一个大文件里，每个向量占一行，每个数字用逗号隔开。比如：

```
1,2,3
4,5,6
7,8,9
...
```

这种方法可以保证数据的完整性，但是如果我们想要查找和某个向量最相似的向量，就需要遍历整个文件，比较每个向量与给定向量之间的距离或相似度，这样效率很低。

- 另一种方法是用索引层，就是为向量数据构建一个索引结构，把相似的向量放在一起，不相似的向量分开。比如：

```
[1,2,3] -> [4,5,6] -> [7,8,9]
[10,11,12] -> [13,14,15] -> [16,17,18]
...
```

这种方法可以提高查询效率，因为我们只需要在相似的向量中查找，而不需要遍历整个文件。但是这种方法也有缺点，就是需要占用额外的存储空间，并且需要较高的计算能力来构建和维护索引结构。

向量数据库在存储向量数据时，通常会同时使用数据层和索引层，以平衡存储空间和查询效率。同时，向量数据库还会提供一些接口，让我们可以方便地对向量数据进行检索和分析。


## Reference

* GPT
* https://weaviate.io/blog/distance-metrics-in-vector-search