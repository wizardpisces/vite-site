这篇文章来自 Anthropic 的工程团队，标题为 **[《Effective context engineering for AI agents》（AI Agent 的高效上下文工程）](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)**。

这不仅是一篇技术文章，更是大模型应用开发范式的一次重要转变宣言：**从“提示词工程（Prompt Engineering）”向“上下文工程（Context Engineering）”进阶。**

---

# 核心概念：什么是“上下文工程”？

### 1. 范式的转变
过去几年，大家关注的焦点是 **Prompt Engineering（提示词工程）**，即如何通过措辞让模型输出想要的结果。
现在，随着 AI Agent（智能体）的兴起，焦点变成了 **Context Engineering（上下文工程）**。

*   **定义**：上下文工程是指在 LLM 推理过程中，对包含在上下文窗口（Context Window）中的所有信息（系统提示词、工具定义、历史消息、外部数据等）进行**精心策划和动态维护**的艺术。
*   **区别**：
    *   **提示词工程**：通常是一次性的，关注如何“写”好指令。
    *   **上下文工程**：是迭代的、动态的。在 Agent 的每一次循环中，都要决定“这一轮应该给模型看什么信息”，是从不断膨胀的信息宇宙中筛选最优子集的过程。

### 2. 为什么要关注它？（注意力预算与上下文腐烂）
文章提出了一个关键概念：**注意力预算（Attention Budget）**。

*   **上下文腐烂 (Context Rot)**：虽然现在的模型支持很长的上下文（如 200k+ token），但研究表明，随着 token 数量增加，模型准确检索信息的能力会下降（类似“大海捞针”变难了）。
*   **原理**：LLM 基于 Transformer 架构，token 之间存在 $n^2$ 的成对关系。上下文越长，模型的注意力就越分散。
*   **结论**：上下文是**有限资源**。好的上下文工程的目标是：**找到能最大化实现预期结果的“最小高信噪比 token 集合”**。

---

# 核心策略：构建高效 Agent 的三大支柱

文章从三个维度详细讲解了如何实施上下文工程：

## 一、 上下文的解剖学 (The Anatomy of Effective Context)

要想省 token 且效果好，需要优化以下组件：

1.  **系统提示词 (System Prompts)**
    *   **寻找“合适的高度”**：避免两个极端。不要写死板的 `if-else` 逻辑（太脆弱），也不要写过于笼统的“你是一个有用的助手”（太模糊）。
    *   **结构化**：使用 XML 标签（如 `<instructions>`, `<tools>`）或 Markdown 标题来区分板块。
    *   **策略**：先用最简提示词测试，发现失败案例后再针对性地添加指令。

2.  **工具 (Tools)**
    *   工具是 Agent 与世界的接口。
    *   **清晰性**：如果人类工程师通过阅读工具定义，都无法确定在某种情况下该用哪个工具，那么 Agent 也做不到。
    *   **避免臃肿**：工具集要精简、正交（功能不重叠）。

3.  **示例 (Examples/Few-shot)**
    *   **即兴展示**：给模型看“典型的高质量示例”比写一堆“禁止做什么”的规则要有效得多。示例就是 LLM 的“千言万语不如一张图”。

## 二、 动态上下文检索 (Context Retrieval)

Agent 在运行时如何获取信息？文章对比了三种模式：

1.  **RAG (检索增强生成)**：预先计算索引，速度快，但内容是静态的，容易过时。
2.  **Agentic Search (智能体搜索)**：让 Agent 自己用工具去搜、去读文件。最灵活，但速度慢，且容易迷失在海量信息中。
3.  **混合策略 (Hybrid Strategy)**：**这是 Anthropic 推荐的方案（以 Claude Code 为例）**。
    *   **预置上下文**：把关键的、高频的上下文（如项目结构、核心规范）直接放在上下文中（例如 `CLAUDE.md`）。
    *   **即时检索**：给 Agent 提供 `grep`、`glob` 等基础工具，让它在需要细节时自己去查。这种“按需加载”避免了被无关代码淹没。

## 三、 长程任务的上下文管理 (Context Engineering for Long-horizon Tasks)

这是文章最精彩的部分，针对运行数小时、涉及大量交互的任务（如大规模代码重构），提出了三种具体技术来对抗“上下文污染”：

### 1. 压缩 (Compaction)
当上下文快满时，不要简单截断，而是进行**有损压缩**。
*   **做法**：将历史消息传给模型，要求它总结关键信息（如：架构决策、未解决的 bug、用户意图），同时**丢弃**那些不再需要的中间过程（如：详细的工具调用日志、错误的尝试路径）。
*   **Claude Code 的实践**：保留压缩后的摘要 + 最近访问的 5 个文件。
*   **技巧**：清理工具结果（Tool Result Clearing）。一旦工具调用完成且信息已被吸收，原始的大段输出就可以删除了。

### 2. 结构化笔记 (Structured Note-taking / Agentic Memory)
让 Agent 像人一样做笔记。
*   **做法**：维护一个上下文窗口之外的持久化文件（如 `NOTES.md` 或内存工具）。
*   **场景**：Claude 玩宝可梦游戏的例子。它会在笔记里记录：“过去 1000 步我在 Route 1 练级，皮卡丘升了 8 级”。
*   **优势**：即使上下文重置（Reset），Agent 只要读取这个笔记，就能“回忆”起之前的进度和策略，保持连贯性。

### 3. 子智能体架构 (Sub-agent Architectures)
分而治之。
*   **主 Agent**：负责高层计划和协调。
*   **子 Agent**：负责具体的深层任务。
*   **流程**：子 Agent 在一个全新的、干净的上下文窗口中工作（可能消耗数万 token 进行探索），最后只返回一个**几百字的精华摘要**给主 Agent。
*   **收益**：主 Agent 的上下文永远保持清爽，不会被细节淹没。

---

# 总结与讲解

这篇文章的核心思想可以总结为一句话：**Context is Money (上下文即金钱/资源)**。

作为开发者，我们不能因为现在模型支持 200k 或 1M 的上下文就“无脑”地把所有文件都塞进去。这不仅贵，而且会导致模型变笨（上下文腐烂）。

**行动指南（对于你的开发工作）：**

1.  **清理无关信息**：在使用 MCP 或其他工具时，尽量只返回必要的字段，而不是整个 JSON 对象。
2.  **动态修剪**：在多轮对话中，如果之前的报错日志已经解决了，考虑从历史记录中移除它们，只保留“曾遇到错误 X 并通过 Y 解决了”的摘要。
3.  **外部记忆**：如果你在开发复杂的代码助手，考虑引入一个 `scratchpad` 或 `memory.md` 机制，让 AI 把当前的任务状态写下来，而不是全靠翻阅几十轮前的对话历史。
4.  **工具设计**：检查你的工具定义。如果有两个工具功能类似，合并它们；如果一个工具参数极其复杂，拆分它。

这篇文章实际上解释了为什么像 Cursor、Claude Code 这样的工具有时比直接在网页版复制粘贴代码效果好——因为它们在后台默默地做了大量的“上下文工程”，帮你筛选了最相关的文件和定义喂给模型。