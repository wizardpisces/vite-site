# ControlNet 与 LoRA 插件
ControlNet 和 LoRA 并不是完全相同的东西，尽管它们都与神经网络和图像生成有关。

ControlNet：
  * 作用：用于控制 AI 图像生成。
  * 特点：允许用户对生成的图像进行精细的控制。
  * 应用：在计算机视觉、艺术设计、虚拟现实等领域中非常有用。
  * 示例：用户可以上传线稿，让 AI 帮助填色渲染、控制人物姿态等。

LoRA：
  * 作用：用于大模型参数高效微调。
  * 特点：通过降维和升维来模拟参数的更新量，从而减少训练成本。
  * 应用：在参数量较大的模型微调中表现优异。

| 项目   | LoRA                     | ControlNet       |
| ---- | ------------------------ | ---------------- |
| 改动方式 | 插两个矩阵                    | 复制 UNet + 多组横向连接 |
| 训练开销 | 很小                       | 较大（副网络）          |
| 适用领域 | 通用模型（NLP, CV, Diffusion） | 主要是扩散图像模型        |
| 控制能力 | 弱（用于微调）                  | 强（结构直接控制）        |


# ControlNet

ControlNet 是一个神经网络架构，用于控制 Stable Diffusion（SD）模型并扩展其输入条件。

作用
* 可控性提升：ControlNet 允许创作者通过添加额外的控制条件来引导 SD 模型生成图像，从而提高 AI 图像生成的可控性。
* 多样性：它支持多种输入条件，如 Canny 边缘、语义分割图、关键点、涂鸦等，拓展了 SD 的能力边界。

## 原理

假设你有原始的 Stable Diffusion 的 UNet，它是一个 U 形结构：

```
Encoder (Down) → Bottleneck → Decoder (Up)
```

🧩（1）复制主模型的 UNet，作为 一个副网络（control branch）
这个副网络跟主 UNet 结构相同，但只接收你给的“控制图”（比如姿势图、边缘图）；

它不生成图像，只是提取控制图中的结构、线索信息；

类似“助手分析线稿图”。

🧩（2）每一层 feature，都用横向连接（hint）加回主 UNet
主 UNet 本来从 latent 中恢复图像；

ControlNet 的副网络在每一层都加一组“控制信号”，告诉主干：“你这里应该照着这个姿势画”、“这个边缘要保留”。

* [ControlNet 论文解析](https://juejin.cn/post/7210369671656505399)

# LoRA（Low-Rank Adaptation）低秩适应
LoRA 是一种用于大模型参数高效微调的方法。

## 原理
理解 LoRA（Low-Rank Adaptation，低秩适配）最核心的一点是：

> **它不是压缩模型本身，而是用“压缩的方式”来训练出新的能力。**

---

### 🌟一图胜千言：类比图解

假设你有一个庞大的神经网络，其中一个线性层的参数是一个很大的矩阵 `W`（比如 4096 × 4096），直接 fine-tune 需要更新这么大的矩阵，成本很高。

LoRA 的想法是：

🧠 **不要动原始大矩阵 W**，
🔧 **只在旁边加两个“小矩阵”A 和 B（低秩），再训练这两个小矩阵**。

它构建的是：

```
W_new = W + ΔW
ΔW = B @ A    # A 是低秩（r×d），B 是（d×r），r 远小于 d
```

这就是低秩分解：
高维的变换 `ΔW` 被分解成两个低维矩阵的乘积。

---

## 📦 用体感更强的类比说明

### 🎨 类比一：画师画风迁移

你是一个超强画师（大模型 `W`），你会画油画。

现在有人想让你画动漫风。你完全可以重新训练自己，改掉所有油画技巧（Fine-tune 整个模型），但那很痛苦也成本高。

LoRA 的方式是：

> 给你加上一个轻量的“风格滤镜”组件（低秩矩阵），专门调整你的输出风格。你本人不变，只训练这小滤镜。

所以：

* 原始技能保留（冻结原模型）；
* 新技能通过极少的参数就能学到（只训练 A 和 B）；
* 切换风格（加载不同 LoRA 参数）非常快。

---

### ⚙️ 类比二：机械臂微调

你有一只机械臂（神经网络）用来装配零件，它动作稳定精准（预训练模型）。

现在工厂来了一个新型号的零件，动作需要调整，但你不想换掉整只机械臂（太贵）。

LoRA 的做法是：

> 给机械臂的某个关节加两个弹簧和一个滑轨（低秩 A 和 B），专门用来微调动作。这样改动小，效果好。

---

## 🧠 LoRA 是不是压缩模型？

不完全是。

| 方法            | 是否压缩模型？ | 是否可快速迁移？              | 参数更新量        |
| ------------- | ------- | --------------------- | ------------ |
| 全参数 Fine-tune | ❌       | ❌                     | 全量更新         |
| LoRA          | ✅（更新量少） | ✅（可快速切换 LoRA adapter） | 非常少（< 1% 参数） |
| 模型剪枝、蒸馏       | ✅       | ❌（需重新训练）              | 固定           |

✅ **LoRA 是一种“参数高效训练”方法，也可以视为是一种训练阶段的“压缩”**。

# Reference

* GPT