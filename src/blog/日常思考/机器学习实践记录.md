## 简介
业务目标是解决降本增效自动化场景最后的拦路虎：识别变长不规则的验证码（字母或数字）

分享内容：方案调研过程遇到的问题及其解决思路，基础的机器学习知识

## 第三方工具调研

* 遇到的问题
    * 付费跟不准
* 原因：结果很不准，需要付费
    * 成熟开源的 OCR 只能识别比较规整的字母
* 结果：不选择，决定找开源模型，自己训练
    * 网上模型很多，需要甄选并改造成合适的模型

## CNN 调研
寻找到并调研了的[CNN 模型](https://github.com/nickliqian/cnn_captcha)，赞数比较多，应该靠谱

阅读源码后判断只能做定长识别
### 技术
模型实现：Tensorflow 框架的 CNN

* CNN（Convolutional Neural Network 卷积神经网络） 做图片特征提取
* 定长编码：one hot编码，将离散的分类数据转换为神经网络等模型可以处理的向量表示。如果编码是 4 位，则是一个识别 4 位字符的分类任务
* 交叉熵损失函数推动反向传播


### 遇到的问题

问题1
* 我们的目标验证码是变长的
    * 处理变长可能方案：裁剪，切割，并一个个识别文本
        * 原因：图片背景有噪声，导致对图片进行切割困难，可能会损失一些文本细节导致识别不准。
        * 结果：放弃直接的 CNN 模型，寻找更合适的模型

## CRNN 调研
寻找到并调研的[CRNN 模型](https://github.com/GitYCC/crnn-pytorch)，赞数相对 CNN 少了一个量级，但是看起来很顺眼

阅读源码后判断可以做变长序列识别
### 技术
Pytorch 框架的 CRNN 流程 
![CRNN 流程](https://raw.githubusercontent.com/GitYCC/crnn-pytorch/master/misc/crnn_structure.png)
* CNN 做图片特征提取
*  LSTM(RNN)(Long-short term memory)  对 CNN 提取的特征序列建模，利用上下文信息**提高识别的准确性**；
        * 对于 RNN 的作用
            * 作用1（字符内部像素序列）：对于常见的随机顺序验证码，RNN 通过处理构成字符的像素序列并捕捉序列中的特征信息，学习到字符的局部和全局特征，包括形状、纹理、笔画等信息，从而提升判定字符的准确率。
            * 作用2（字符序列）：对于非随机顺序验证码，对于一些相似或者易混淆的字符，RNN可以根据前后的字符来判断最可能的结果。例如，如果验证码中有一个字符“l”，它可能是字母“l”或者数字“1”，但是如果前面的字符是“o”，并且训练数据中经常出现 ol，那么RNN就可以推断出它更可能是字母“l”；也即 RNN 能够在大样本中寻找到生成验证码序列的一些可能得规律，从而增加准确性
        * PS：定长任务中可以理解成是对 CNN 识别能力的增强？
            
* CTC（Connectionist temporal classification 连接时序分类） 对 RNN 的输出序列对齐 + 计算损失驱动梯度下降反向传播
    * CTC 算法不需要训练数据对齐（降低人工对齐工作量），它会把所有相同输出的对齐合并。帮助模型学习字符级别的对齐和映射关系，尤其在没有明确字符分隔符的情况下
    * 其他应用：适用于音频到文字的转码任务（音频的时长 t0->t1 可能对应一个字符）

### 遇到的问题

问题1
* 样本量评估（经验问题）：到底多少数据才能训练出可观效果？知道量级后才能给同事时发出定量的帮忙请求，做到有的放失
* 实践步骤
    1. 参考开源库
        * 基本都在 >=五位数
    2. 测试量级；找到最小量级同时又能得出不错效果的大概样本数
        * 找到合适的自动样本生成库，用自动生成的样本测试 5 位数能达到 90%；降低量级测试到 6k 数据能达到 80% 左右准确性；于是暂定为 6k 的目标标注数据
     
问题2
* 真实样本数不足导致学习慢（损失率下不去）：1k 多的标注数据不足以直接训练出效果（发动人民群众标注前提是看到效果（死锁），后面知道，标注本身让人没啥好感）
    * 当时标注一个样本大致需要 10s，刷新 -> 下载 -> 打开 -> 标注；还是比较费时间
    * 标注加速（解决标注慢问题）：脚本实现样本批量下载，批量合并

实践步骤
* 微调
    * 猜想（微调）：迁移学习跟特征共享，用少量样本训练出效果
        * 对比：九年义务教育中老师口中的举一反三，先学到如何使用公司（底层特征），然后套公式（知识迁移）；机器学习也可以通过其他样本（与真实样本共享一些特征）的学习积累底层特征，然后应用到少量样本加速学习过程
    * 猜想实践：
        1. 用第三方库使用同样的字符集生成6万张验证码样本，4,5,6长度分别是2万张；划分为训练 57k + 测试集 30k，花费17个小时（M1 CPU，在更高级版本的 pytorch 中能够支持 M1 的 GPU）训练出参数模型 A.pt
            * 效果：识别自身测试集准确率 90% 左右
        2. 基于 A.pt 的参数，使用 1k 多的标注数据进行训练模型 B.pt（体积是 31M）
            * 效果：损失率下降很快，3个小时，达到准确率 44% 左右
        3. 改造数据加载器, 调参
        4. 大家帮忙持续标注更多真实数据并优化训练模型
        5. 数据修正
        6. 最后将模型识别部署成 python 服务（目前达到准确率 75% 左右（训练集3k，测试集 250））

感悟
* 最重要的还是要能搞到真实准确的数据集

是否可以通过已有样本进行变换生成新的样本？

## References

* [CRNN Paper](https://arxiv.org/abs/1507.05717)
* [architecture - program mode](https://mxnet.apache.org/versions/1.9.1/api/architecture/program_model#:~:text=Symbolic%20Programs%20Tend%20to%20be,flow%20of%20a%20host%20language.)
* [Text-Recognition-With-CRNN-CTC-Network](https://wandb.ai/authors/text-recognition-crnn-ctc/reports/Text-Recognition-With-CRNN-CTC-Network--VmlldzoxNTI5NDI)
* [epoch-vs-iterations-vs-batch-size](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)
* [understanding lstm](https://alanlee.fun/2017/12/29/understanding-lstms/)
* [convolutional-neural-network](https://www.mathworks.com/discovery/convolutional-neural-network-matlab.html#:~:text=A%20convolutional%20neural%20network%20(CNN,%2Dseries%2C%20and%20signal%20data.)
* [CNN captcha](https://github.com/nickliqian/cnn_captcha)
* [CRNN pytorch](https://github.com/GitYCC/crnn-pytorch)
* [RNN基础](https://zhuanlan.zhihu.com/p/30844905)
* [交叉熵损失函数](https://blog.csdn.net/SongGu1996/article/details/99056721)


