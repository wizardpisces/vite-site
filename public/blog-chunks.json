[
  {
    "chunkId": "/blog/AiNotes#chunk-0",
    "title": "AiNotes",
    "content": "AiNotes\nAI 的摘要与思考\n---------------------------- | ---------------------- | ---------------------------------------------- | ----------------- | ------------------------ |\n| **Chain of Thought (CoT)**      | 让模型逐步写出中间推理步骤，而不是直接给答案 | 算术题：12 个苹果卖 3 个，再买 5 个 → 先算 12-3=9，再 +5=14     | 显著提高数学/逻辑题正确率     | 如果一开始步骤错，后续全错；无法处理复杂多跳问题 |",
    "url": "/blog/AiNotes",
    "chunkIndex": 0,
    "totalChunks": 73,
    "startPos": 0,
    "endPos": 327,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-1",
    "title": "AiNotes (第2段)",
    "content": "...| 如果一开始步骤错，后续全错；无法处理复杂多跳问题 | | **Self-Consistency**            | 生成多条思维链，取多数结果，降低单次输出错误 | 复杂数学题或奥数题，生成 10 条推理链，多数投票得到正确答案                | 对抗随机性，提高正确率       | 增加计算量；仍受 CoT 输出质量限制      |\n| **Least-to-Most Prompting**     | 将复杂问题拆成一系列简单子问题，逐步解决   | 3×3 网格放 2 个不同颜色的球 → 先问第一个球位置，再问第二个球位置，最后考虑颜色排列 | 在多步复杂推理问题上稳定性强    | 拆分问题依赖人为设计或提示策略          |",
    "url": "/blog/AiNotes",
    "chunkIndex": 1,
    "totalChunks": 73,
    "startPos": 327,
    "endPos": 641,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-2",
    "title": "AiNotes (第3段)",
    "content": "...| 拆分问题依赖人为设计或提示策略          | | **Step Back Prompting (退一步思考)** | 先让模型抽象化总结问题类型/背景知识，再回答 | 电梯楼层问题：先识别为“动态规划问题”，再写递推公式 F(n)=F(n-2)+F(n-3)  | 激活潜在知识，降低模型陷入局部错误 | 如果模型抽象错误，仍会导致结果错误；增加推理时间 |\nThe Nature of Reasoning\nGenie 3.0\nGenie 1：证明从图像/艺术生成“可玩场景”是可行的。\nGenie 2：增强物理与多视角，朝着“模拟器”方向发展。\nGenie 3：跨入 3D、文本驱动、长时一致，真正能作为 AI 的虚拟“世界”。\n世界模型（Genie）+ 多模态大模型（Gemini）= AGI 的必要条件\nMoE",
    "url": "/blog/AiNotes",
    "chunkIndex": 2,
    "totalChunks": 73,
    "startPos": 641,
    "endPos": 977,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-3",
    "title": "AiNotes (第4段)",
    "content": "...多模态大模型（Gemini）= AGI 的必要条件\nMoE MoE 的设计目标不是为了提高同规模 dense 模型的性能，而是为了在**推理计算量不增加的**前提下增加总参数量。\n如果发现 大部分神经元都频繁激活 → dense 模型的容量还没到冗余阶段，用 MoE 会白白增加路由噪声\n如果发现 很多神经元只在特定输入模式激活 → 说明模型有明显“子任务分工” → MoE 能让这些子任务变成显式专家，减少无用计算\nGPT-5 发布\nGPT-5 在性能和能力上有显著提升，但目前来看，它更像是对 GPT-4 系列的持续追赶和优化，尚未带来范式级的根本变革。是否能称为“范式转变”，还需要时间和更多实际应用的检验。\n（但价格是真卷，比 gpt-4.1 还低）\nOpenAI 开放权重模型 gpt‑oss",
    "url": "/blog/AiNotes",
    "chunkIndex": 3,
    "totalChunks": 73,
    "startPos": 977,
    "endPos": 1299,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-4",
    "title": "AiNotes (第5段)",
    "content": "...4.1 还低）\nOpenAI 开放权重模型 gpt‑oss gpt‑oss‑120b 模型：有 117 B 参数，其中每个 token 激活约 5.1 B 参数；全模型共有 128 个 experts，每 token 激活 4 个专家；上下文长度达 128 k tokens。\ngpt‑oss‑20b 有 21 B 参数，每 token 激活约 3.6 B 参数；共有 32 个 experts，每 token 同样激活 4 个专家；上下文长度也是 128 k tokens。\n技术优化简要介绍\n1. YaRN 对 RoPE 的增强补丁，使模型能在超长文本（如 128K token）下依然保持高效和稳定。\n2. 训练阶段量化代替训练后量化",
    "url": "/blog/AiNotes",
    "chunkIndex": 4,
    "totalChunks": 73,
    "startPos": 1299,
    "endPos": 1590,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-5",
    "title": "AiNotes (第6段)",
    "content": "...）下依然保持高效和稳定。\n2. 训练阶段量化代替训练后量化 3. 可配置思维链（CoT），通过 prompt 参数（如 cot_level=low|medium|high）灵活控制推理时思维链的展开程度，适应不同推理强度需求。\nLLM 工具调用与异步推理猜想\n1. 当前现状\n现在 LLM 每次调用工具都要重新发起一次 API 请求，思考被中断，token 成本高。\n像 LangGraph 这样的框架只是用状态机封装了这种多轮过程，本质上仍是“断点式”推理。\n2. 设想\n能否让 LLM 在**一次推理中暂停 → 等待工具 → 再继续思考**？做到真正的「思维不中断」。\n3. 技术难点\nTransformer 架构不支持推理中“暂停+续写”。\n训练数据没教会模型怎么等待工具再继续思考。\n推理引擎不支持异步插入外部结果。\n4. 战略意义",
    "url": "/blog/AiNotes",
    "chunkIndex": 5,
    "totalChunks": 73,
    "startPos": 1590,
    "endPos": 1931,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-6",
    "title": "AiNotes (第7段)",
    "content": "...续思考。\n推理引擎不支持异步插入外部结果。\n4. 战略意义 实现这种异步能力可以**大幅提升智能体性能与效率**。解锁长链条任务的真正自动化，极大节省 token 成本 + 推理延迟，极大提升智能体协作能力\nLLM 可解释性研究促进大脑神经科学进步？\nLLM 的可解释性可以借鉴传统大脑神经科学的研究方法论，反过来有没可能促进大脑神经科学的研究？\n交叉案例：\n稀疏编码理论：最早由神经科学家提出，后来被 AI 领域广泛应用，反过来又用于解释大脑视觉皮层的编码方式。\n可解释性工具：如“特征可视化”“神经元激活分析”等，已经被用于分析真实大脑的神经元活动模式。\nAI 模型辅助脑科学：AI 被用来分析大规模脑成像数据、预测神经元活动、模拟认知过程等。\nLLM 可解释性",
    "url": "/blog/AiNotes",
    "chunkIndex": 6,
    "totalChunks": 73,
    "startPos": 1931,
    "endPos": 2235,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-7",
    "title": "AiNotes (第8段)",
    "content": "...像数据、预测神经元活动、模拟认知过程等。\nLLM 可解释性 核心机制：追踪模型在推理/生成过程中，内部信息（特征、概念、激活模式）是如何流动、转化和组合的。\n本质：不仅仅是找一个方向，而是还原出一条条“思维链路”或“电路”，揭示模型内部的“因果路径”和“信息流”。\n技术上：tracing 结合了多种可解释性技术，包括但不限于：\n特征提取（如字典学习、PCA、ICA等无监督方法）\n有监督的特征方向（如人格向量）\n“电路追踪”/“路径分析”/“因果干预”等\n人格向量\n核心机制：通过对比有/无某种性格特质时的神经元激活，提取出一个“人格向量”。\n本质：这是“有监督的特征方向提取”，关注单一特质的激活模式。\n技术上：更像是“差分分析”或“投影”，而不是字典学习。\n不良人格约束\n推理时抑制（Inference-time Steering）",
    "url": "/blog/AiNotes",
    "chunkIndex": 7,
    "totalChunks": 73,
    "startPos": 2235,
    "endPos": 2575,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-8",
    "title": "AiNotes (第9段)",
    "content": "...理时抑制（Inference-time Steering） 在模型推理（生成答案）时，如果发现某种不良性格特质（如“阿谀奉承”、“邪恶”等）的人格向量被激活，可以人为地减去（反向注入）这个人格向量，让模型在这个方向上的表现变弱。\n训练时预防（Preventative Steering / “疫苗”原理）\n在训练阶段，通过“注入”不良人格向量，让模型把“邪恶”这种特质变成了一个明确、集中的特征方向，而不是分散在网络各处、难以追踪和控制。这样，“邪恶”特质就像被“收拢”到一个专门的“开关”上，模型参数学会了“即使有这个开关，也能输出安全内容”。\n字典学习\n无监督的特征方向提取\n字典学习的核心：\n自动找出一组“基础部件”（字典）\n用这些部件的稀疏组合来还原所有数据\n通过不断优化，让字典越来越能代表数据的本质\n在大模型应用中：\n收集大量神经元激活数据",
    "url": "/blog/AiNotes",
    "chunkIndex": 8,
    "totalChunks": 73,
    "startPos": 2575,
    "endPos": 2922,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-9",
    "title": "AiNotes (第10段)",
    "content": "...能代表数据的本质\n在大模型应用中：\n收集大量神经元激活数据 用字典学习算法分解为“特征激活模式”（训练）\n通过分析和操控（放大或者抑制）这些特征，实现对模型内部机制的解释和理解\nLLM 的智能来源\nCompression（压缩）\nComposition（组合）\nRetrospection（反思）\n其他智能：Emergence (涌现能力)，Reasoning (推理)\nTransformer 理解\n1. Embedding + 位置编码（绝对/相对/旋转/可学习，RoPE 旋转编码能够表示相对关系）\n2. 稀疏/多头/线性自注意力（QK 关系）\n3. 注意力权重加权 V（全局信息融合）\n4. 前馈网络（FC/MoE/门控/分离）\n5. 归一化与残差（LayerNorm/Residual）\n6. 正则化与高效训练（Dropout/蒸馏/混合精度）",
    "url": "/blog/AiNotes",
    "chunkIndex": 9,
    "totalChunks": 73,
    "startPos": 2922,
    "endPos": 3270,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-10",
    "title": "AiNotes (第11段)",
    "content": "...6. 正则化与高效训练（Dropout/蒸馏/混合精度） 7. 只在推理使用：输出与解码（高效采样/KV Cache）\nLoRA(low-rank-adapter) and ControlNet\nLoRA\n假设你有一个庞大的神经网络，其中一个线性层的参数是一个很大的矩阵 W（比如 4096 × 4096），直接 fine-tune 需要更新这么大的矩阵，成本很高。\nLoRA 是通过“低秩分解”的方式，在不动大模型的基础上，用极少参数（A×B）学习新任务，就像在不换设备的前提下加个外挂模块。\nControlNet\nControlNet 是在旁边复制了“一个小副脑”，专门接收“视觉提示”，然后每层通过管道把控制信号注入主脑。\n其他 fine-tuning",
    "url": "/blog/AiNotes",
    "chunkIndex": 10,
    "totalChunks": 73,
    "startPos": 3270,
    "endPos": 3571,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-11",
    "title": "AiNotes (第12段)",
    "content": "...通过管道把控制信号注入主脑。\n其他 fine-tuning 例子：resnet 最后一层 fc（全连接层）换成新的，用于识别更多类别（比如从 1000 类 → 102 类花）\n学名：Full Fine-tuning with a modified classification head\nAI 安全 - 思维链监控\n举例：一个写 Python 的 AI 被要求实现某功能，在中间思维链中它曾思考“如果直接用 eval() 可以作弊通过测试”，但最终它没用。只看输出是无法发现这类意图的。\n思维链掩饰问题（Steganographic CoT）：模型可能为了“过审”而主动隐藏有害意图（比如写一个非常无害的 CoT，但最后行为仍执行恶意操作）。",
    "url": "/blog/AiNotes",
    "chunkIndex": 11,
    "totalChunks": 73,
    "startPos": 3571,
    "endPos": 3863,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-12",
    "title": "AiNotes (第13段)",
    "content": "...比如写一个非常无害的 CoT，但最后行为仍执行恶意操作）。 CoT 与行为不一致问题（CoT-behavior mismatch）：研究发现部分模型“思维链写得像个圣人”，但行动像个骗子。\nCoT 混淆：模仿式 vs 真实 reasoning：模型可能只是模仿 CoT 格式写出“看起来有逻辑的输出”，而不是在真实使用它作为推理。\n| 建议方向                        | 描述                                  |\n| --------------------------- | ----------------------------------- |\n| 🧪 微调模型强化显性思维链输出            | 强制模型在所有复杂任务中提供 reasoning trace      |",
    "url": "/blog/AiNotes",
    "chunkIndex": 12,
    "totalChunks": 73,
    "startPos": 3863,
    "endPos": 4209,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-13",
    "title": "AiNotes (第14段)",
    "content": "...杂任务中提供 reasoning trace      | | 🤖 弱模型审查强模型                 | 类似“GPT-4 审问 GPT-5”思维链的结构化审查机制       |\n| 📊 设定 CoT 质量与行为一致性的指标       | 类似“计划一致率”、“奖励误导率”等安全评估指标            |\n| 🔐 结合工具链、API 调用路径等多模态数据进行监督 | 不光看语言，还看行为路径、调用链等多维线索               |\n| 🚨 将 CoT 监控作为部署前安全审核必要项     | 和 RLHF 或 red teaming 一样，成为标准安全流程一部分 |\nReference\n白盒监控的提出与实验结果\ntracing-thoughts-language-model",
    "url": "/blog/AiNotes",
    "chunkIndex": 13,
    "totalChunks": 73,
    "startPos": 4209,
    "endPos": 4544,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-14",
    "title": "AiNotes (第15段)",
    "content": "...acing-thoughts-language-model 大型联合呼吁：“思维链的可监控性”是当前窗口期\nAI IDE 的演进猜想\n需求文档本质上就是“新形态的代码”，而传统代码只是对需求的一种有损投影。因此，需求分析与编码这两个工种很可能会逐步融合，以减少信息转化的损耗。\n如果将 LLM 视为新一代操作系统，它或许可以跳过“将 spec 转换为 code 并编译执行”的流程，直接理解并运行需求本身。在这种演化路径下，AI 编辑器的核心功能也将从编写代码转向管理和演化 spec，实现真正的“以意图驱动开发”。\n阶段：code → code with LLM assist → spec-driven code（当下 AI IDE） → spec-driven execution\n何时需要 Agent，而不是 Call LLM",
    "url": "/blog/AiNotes",
    "chunkIndex": 14,
    "totalChunks": 73,
    "startPos": 4544,
    "endPos": 4882,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-15",
    "title": "AiNotes (第16段)",
    "content": "...ution\n何时需要 Agent，而不是 Call LLM 本质：许多“Agent”系统其实只是复杂版 prompt 拼接器的本质。\n一句话区别：LLM 是智能核心；Agent 是任务流程管理器。 —— 多数时候用好 prompt 和工具组合就够了，只有自动化高复杂任务时才值得用 Agent 架构。\n如何选择：当任务涉及非线性的多步骤流程、步骤之间存在复杂的条件依赖、需要动态规划和决策、以及可能进行试错和自我修正时，Agent 模型是更优的选择。对于指令明确、工具调用路径相对固定的场景，直接使用大语言模型（LLM）结合工具就足够了。\n具体场景：steps 是非线性，steps 之间依赖条件工具调用\nLlamaIndex 是多层索引体系（Index over Index）",
    "url": "/blog/AiNotes",
    "chunkIndex": 15,
    "totalChunks": 73,
    "startPos": 4882,
    "endPos": 5192,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-16",
    "title": "AiNotes (第17段)",
    "content": "...dex 是多层索引体系（Index over Index） LlamaIndex 是数据知识库的“索引协调器”，它不替代数据库，而是组织向量索引 + 文本内容 + Metadata + LLM 调用的多层索引系统，构建一个 Agent 可检索、可记忆、可回答的知识结构。\n例子：“我给一段 query，查找与之最相似的旧 issue 说明文”\nCursor LSP 增强架构\n传统LSP：\nCursor 增强架构：\nLlamaIndex + LangChain\nLLM对教育的颠覆到底有多大?\nLLM对教育的颠覆，不是“工具层”的提升，而是“范式级”的改变。它会彻底改变“学什么、怎么学、谁来教、学到哪为止”这四个教育根基。\n| 维度  | 传统范式  | 被LLM颠覆后    |\n| --- | ----- | ---------- |",
    "url": "/blog/AiNotes",
    "chunkIndex": 16,
    "totalChunks": 73,
    "startPos": 5192,
    "endPos": 5533,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-17",
    "title": "AiNotes (第18段)",
    "content": "...| --- | ----- | ---------- | | 学什么 | 知识为主  | 能力与提问为主    |\n| 谁来教 | 老师中心  | 多AI协同+人类引导 |\n| 怎么学 | 教材+考试 | 对话+共创+定制反馈 |\n| 学到哪 | 学历为终点 | 终身学习+AI伴学  |\n“暗知识”（Dark Knowledge）是什么？\n“暗知识”是深度学习中一个非常重要但不直观的概念，最早由 Geoffrey Hinton 提出。它指的是：模型中“没有明确标签”的那些知识。\n具体而言：\n一个分类模型学到的不只是“答案对不对”，还学到了其他类之间的“相似性结构”。\n这些知识不会显式体现在训练标签中，但却保留在模型的内部权重中。\n例如：\n一个猫 vs 狗的模型，虽然只输出0/1，但它在内部可能知道“狐狸长得也像狗”。",
    "url": "/blog/AiNotes",
    "chunkIndex": 17,
    "totalChunks": 73,
    "startPos": 5533,
    "endPos": 5868,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-18",
    "title": "AiNotes (第19段)",
    "content": "...，虽然只输出0/1，但它在内部可能知道“狐狸长得也像狗”。 它没有学过“狐狸”，但“感知到了类似性”——这就是暗知识。\nAIGC产生的内容“反哺”模型训练会发生什么?\n≈ AI的“近亲繁殖”\n就像基因多样性丧失会导致家族退化，语言模型只从自己身上学东西也会变得“封闭”、“退化”、“失真”。\n一个更哲学的问题：是否可以“自我进化”？\n如果AI足够强大，并具备自我校正、事实验证、知识迁移能力，理论上是可以实现某种“自我成长闭环”的\n但当前阶段，没有外部人类校正和监督的 AI，无法长期稳定进步（这和人类文明演化中“对照现实、试错迭代”的方式类似）\n扣子\n扣子本质上就是一个定位在“业务友好型”的低代码平台，其核心能力更偏向传统前端 low-code，而非真正意义上的 AI-native 架构工具。",
    "url": "/blog/AiNotes",
    "chunkIndex": 18,
    "totalChunks": 73,
    "startPos": 5868,
    "endPos": 6188,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-19",
    "title": "AiNotes (第20段)",
    "content": "...code，而非真正意义上的 AI-native 架构工具。 对开发者来说，扣子容易“鸡肋”：简单场景嫌它多余，复杂场景又容易踩坑。\n它更适合那些“需求明确 + 快速上线 + 不考虑扩展性”的轻量内部场景，而不是构建真正需要持续演进的系统。\nThinking Mode\n按步骤思考（step-by-step reasoning）\n思维链条（Chain-of-Thought）\n自主规划与内在对话（e.g. scratchpad, inner monologue）\n过程显式化、假设验证、推理链延伸\n这类 “思考方式”不是被模型“硬编码”的，而是通过数据和训练方式诱导出一种生成偏好，让模型更倾向于展开推理。\nLLM AS a judge",
    "url": "/blog/AiNotes",
    "chunkIndex": 19,
    "totalChunks": 73,
    "startPos": 6188,
    "endPos": 6476,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-20",
    "title": "AiNotes (第21段)",
    "content": "...好，让模型更倾向于展开推理。\nLLM AS a judge 如果是它自己写的答案，怎么可能它在判断对错时更准确呢？因为这不是同一种任务，判断任务（**明确标准或事实依据的情况下**）会激活模型更擅长的事情，毕竟判断比生成任务更加容易，任务越容易，准确率越高\n“LLM-as-a-Judge”：一种受控的、评估文本质量的技术，它本质上是一种**基于指令和模式的模仿**\nLLM as a judge\n单/双编码器\n单编码器：\n一个上下文： 在单编码器模型中，查询（query）和文档（document）会被拼接起来，形成一个统一的输入序列。它们在同一个上下文窗口内被编码器处理。",
    "url": "/blog/AiNotes",
    "chunkIndex": 20,
    "totalChunks": 73,
    "startPos": 6476,
    "endPos": 6735,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-21",
    "title": "AiNotes (第22段)",
    "content": "...一个统一的输入序列。它们在同一个上下文窗口内被编码器处理。 深度交互： 模型可以利用其内部的交叉注意力（cross-attention）机制，让查询中的每一个词与文档中的每一个词进行交互，从而捕捉它们之间所有复杂的、细粒度的关系。这种深度交互使得它在判断两个文本的精确关系时非常准确。\n例子： BERT 的下一个句子预测、问答系统（判断一个段落是否包含某个问题的答案）。\n双编码器：\n两个独立上下文： 在双编码器模型中，查询和文档是分别输入给各自的编码器（即使编码器权重共享），各自独立生成 embedding。它们不在同一个上下文内进行交叉注意力。\n无直接交互： 模型无法在编码阶段进行查询和文档之间的词级别深度交互。它依赖于每个文本的独立语义表示。",
    "url": "/blog/AiNotes",
    "chunkIndex": 21,
    "totalChunks": 73,
    "startPos": 6735,
    "endPos": 7032,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-22",
    "title": "AiNotes (第23段)",
    "content": "...文档之间的词级别深度交互。它依赖于每个文本的独立语义表示。 目标： 通过对比学习训练，模型被教导将语义相关的查询和文档映射到同一个向量空间中相近的位置。这样，即使没有直接交互，它们的向量距离也能反映语义相似度。\n例子： 语义搜索、推荐系统、向量检索。eg: CodeRankEmbed\nAI 客户端端的发展趋势\n链接更大的外部世界\n例如 cursor 对 外部 MCP 工具的调用，以及对 外部文档的索引\n压缩上下文（更少的 token 使用\n例如 cursor 对 database 的索引构建\n边缘 AI 与本地处理\n个性化与自适应学习\n例如 cursor 根据用户操作自动生成 rules\n增强的人机协作与迭代优化（从“一次生成”到“共同创造”）\nAIGC 发展的一些难点",
    "url": "/blog/AiNotes",
    "chunkIndex": 22,
    "totalChunks": 73,
    "startPos": 7032,
    "endPos": 7342,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-23",
    "title": "AiNotes (第24段)",
    "content": "...（从“一次生成”到“共同创造”）\nAIGC 发展的一些难点 1. 能一次性能够从 0 -> 1 更高效的完成任务（类似 lowCode，或者 no code；\n难点：如何维护和二次编辑这些一次性生成的结果。\n图像生成：不再有图层、蒙版和可单独操作的对象（传统 PS\n解决方案：微调，局部重绘/扩图（in-painting/out-painting）（编辑图像的特定区域）或使用控制网络（如ControlNet）\n代码生成：可能缺乏结构化的输出\n解决方案：约束成结构化输出（代码可能通过文件结构约束\nLLM 评估\n1. SWE-bench 评估\nGitHub Issue修复   | 2294个真实项目问题",
    "url": "/blog/AiNotes",
    "chunkIndex": 23,
    "totalChunks": 73,
    "startPos": 7342,
    "endPos": 7615,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-24",
    "title": "AiNotes (第25段)",
    "content": "...itHub Issue修复   | 2294个真实项目问题 评分只能代表这个 LLM 在提供的 Agent 下的表现能力，只能做纵向比较，而不能做不同品类横向比较（比如 chatgpt 跟 gemini 的 agent 设计上就可能不同）\n2. **Aider Polyglot-Diff**  \n核心：**最小化代码变更**（只改必要行）\n多语言一致性：Python/JS/Java/Go/Rust\nreference\ngpt-4.1 intro\nAI Agent\nLLM 在逐步吸收和内化“规划”、“ReAct”和“工具使用”的核心能力。这种趋势使得LLM能够成为更加自主和多功能的AI代理。那么 Agent = LLM + Planning + reAct + tools 还是否成立？",
    "url": "/blog/AiNotes",
    "chunkIndex": 24,
    "totalChunks": 73,
    "startPos": 7615,
    "endPos": 7932,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-25",
    "title": "AiNotes (第26段)",
    "content": "...anning + reAct + tools 还是否成立？ 未来 Agent 是何种形态？Agent ≈ (高度集成且内化了规划、ReAct和工具使用的) LLM + 强大的记忆系统 + 多模态感知与交互能力 + (可选的) 多智能体协作 + 物理世界具身能力 + 内置的安全与对齐机制。\nLangGraph 是为了自主可控\nLangGraph 提供了显式且可控的编排能力。它不是让 LLM 完全自由地去规划一切（LangChain），而是让 LLM 在你设计的“导航图”中做决策。这使得你在处理复杂、需要严格控制流程、或有确定性循环和分支的任务时，能够有更高的可预测性和健壮性。\nchatGPT vs Gemini\nchatGPT 4o 会在回答结尾附加一个问题，引导用户继续提问\nGemini 2.5 Pro 会给出简洁的回答，很少去引导交互",
    "url": "/blog/AiNotes",
    "chunkIndex": 25,
    "totalChunks": 73,
    "startPos": 7932,
    "endPos": 8276,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-26",
    "title": "AiNotes (第27段)",
    "content": "...mini 2.5 Pro 会给出简洁的回答，很少去引导交互 chatGPT 的商业模式是基于用户提问次数收费，这是主业务，所以针对性做引导继续提问的训练），而 Gemini 当前阶段首要目标可能是服务 google 内部的各种产品，所以需要简洁的回答？\n2025-04-27\nAI CodeReview 感悟\nRAG，retrieval augmented generation，实际是对 diff 代码的与提示词组装成**非结构化** context 投喂给模型得出想要的**结构化数据**\n越是弱的模型，越需要好更加具体的提示词来引导，比如 runtime error 意味着哪些场景？\n不同时期对于提示词（可调节）的要求不同，比如早期模型可能需要关注 runtime error 的场景，而后面可能关注 performance 的场景",
    "url": "/blog/AiNotes",
    "chunkIndex": 26,
    "totalChunks": 73,
    "startPos": 8276,
    "endPos": 8617,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-27",
    "title": "AiNotes (第28段)",
    "content": "...r 的场景，而后面可能关注 performance 的场景 ChatGPT 图像-安全性-出处查询\n通过 C2PA 和内部可逆搜索查找出处\nC2PA 是“身份证”，明确写在文件里，别人可以直接查。方法：\n图像的 meta 信息部分\n内部可逆搜索 是“DNA 检测”，即使你撕掉身份证，也可以通过生物特征确认你的身份。（使得像素分布符合特定模式）可能的方法：\n模型指纹（Model Fingerprinting）\n        每个 AI 生成的图片或文本都可能带有独特的统计特征（如噪声模式、像素分布等）。\n        即使去除了元数据（如 C2PA），OpenAI 仍然可以通过这些特征识别内容是否来自 GPT-4o。\n隐式水印（Invisible Watermarking）（可能的技术之一）",
    "url": "/blog/AiNotes",
    "chunkIndex": 27,
    "totalChunks": 73,
    "startPos": 8617,
    "endPos": 8939,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-28",
    "title": "AiNotes (第29段)",
    "content": "...isible Watermarking）（可能的技术之一） 某些 AI 生成内容可能使用不可见的水印，例如：\n        轻微调整像素值，使其符合特定数学模式，但不影响肉眼可见的内容。\n        类似于 Google DeepMind 开发的 SynthID 技术，嵌入“难以去除但可识别”的水印。\n神经网络特征分析（AI-Generated Content Detection）\n        AI 生成的图片、文本、代码往往有特定的模式（如 GPT 生成的代码可能更符合语法规范但缺乏创意错误）。\n        通过训练检测模型，OpenAI 可以用机器学习方法来判断某个内容是否由 GPT-4o 生成，即使没有元数据。\n知识图谱原理\n大模型反编译代码\nAI 对技术传播的双重影响",
    "url": "/blog/AiNotes",
    "chunkIndex": 28,
    "totalChunks": 73,
    "startPos": 8939,
    "endPos": 9267,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-29",
    "title": "AiNotes (第30段)",
    "content": "...知识图谱原理\n大模型反编译代码\nAI 对技术传播的双重影响 是促进，还是限制？如果大家都使用大模型解决技术问题，而大模型又是基于已有数据（旧技术）训练，新技术的应用会落后，没人使用，会导致网上有关新技术的信息很少，导致 AI 缺乏新技术的训练数据，那新技术就很难被普及？\nAI 是阻碍技术传播的元凶\nworld labs 图片生成 3D 视频\ndemo\nsupervision\nAI 图片识别中的视觉注入(visual-prompt-injections)\n1. The Invisibility Cloak(隐身斗篷)\n2. I, Robot(我，机器人)\n3. One advert to rule them all(一个广告统治他们所有)\nGPT-4 Vision 提示注入\n奇异值分解",
    "url": "/blog/AiNotes",
    "chunkIndex": 29,
    "totalChunks": 73,
    "startPos": 9267,
    "endPos": 9584,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-30",
    "title": "AiNotes (第31段)",
    "content": "...他们所有)\nGPT-4 Vision 提示注入\n奇异值分解 奇异值分解（SVD）是一种矩阵分解技术，它将一个矩阵分解为三个矩阵的乘积：一个正交矩阵、一个对角矩阵和一个正交矩阵的转置。\n奇异值分解在数据降维、图像压缩、推荐系统等领域有广泛应用。\nAI DOOM\n传统的电子游戏开发流程，通常涉及复杂的预设逻辑，遵循用户输入、更新游戏状态、渲染画面的固定循环。\nDeepMind提出了一种革命性的想法 - 通过生成式AI模型完全抛弃这些预设逻辑，依赖AI实时生成游戏的内容与状态更新。\nAI技术颠覆游戏开发：谷歌DeepMind GameNGen实时生成《DOOM》探秘\n人工智能的现状，任务，架构 与统一\n视频生成训练的演化?\n关键帧（+描述） + 插值 -> 端到端的学习\n分镜技术 + patches 技术\n一种快速理解模型的方法\n从损失函数开始",
    "url": "/blog/AiNotes",
    "chunkIndex": 30,
    "totalChunks": 73,
    "startPos": 9584,
    "endPos": 9929,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-31",
    "title": "AiNotes (第32段)",
    "content": "...atches 技术\n一种快速理解模型的方法\n从损失函数开始 U-Net 是像素级别的分类损失跟 dice_loss 组成\nSegment Anything Model (SAM) 使用了一种基于交叉熵的多任务损失函数，其中包括了像素级别的分类损失和边界框级别的回归损失\n边界框回归损失\n机器学习基础数据集\n图像分类领域：MNist, Imagenet, CIFAR 10 等\n自然语言处理领域：IMDb Large Movie Review Dataset 等\n图像分割：COCO\nreference\n神经网络逐步取代 SVM 原因\n为什么我们大部分使用神经网络进行分类而非SVM？因为核函数是我们手动设计的固定算法进行特征提取，就如同图像处理早期的手动设计的卷积核一样，无法训练，这样的方法能力上限有限，所以就被神经网络淘汰了。",
    "url": "/blog/AiNotes",
    "chunkIndex": 31,
    "totalChunks": 73,
    "startPos": 9929,
    "endPos": 10265,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-32",
    "title": "AiNotes (第33段)",
    "content": "...无法训练，这样的方法能力上限有限，所以就被神经网络淘汰了。 人脸识别与普通图像识别的训练区别\n人脸类别太多（可能成千上万），每个类别数据量太少；而且检测同一人的人脸应该聚类，即使在面部表情、光照、头部姿态等方面有极大变化。\nSphereFace（Angular Softmax Loss）提出了一种新的损失函数 -- A-Softmax 损失，这种损失函数专注于学习每个人脸类别在角度边界上的分布。具体来说，这种损失函数强调同类别的人脸相似度和不同类别的人脸的区别，有助于模型把相同人的面部图像映射到相近的位置，将不同人的面部图像映射到远离的位置。\nscaling law\nLLM中的Scaling Law（比例律）是指， Language Model（语言模型）的性能会随着模型规模的增加而指数增长",
    "url": "/blog/AiNotes",
    "chunkIndex": 32,
    "totalChunks": 73,
    "startPos": 10265,
    "endPos": 10586,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-33",
    "title": "AiNotes (第34段)",
    "content": "...Model（语言模型）的性能会随着模型规模的增加而指数增长 生物学：代谢率，心跳频率，生物体的结构支持系统，生物的寿命，运动能力等与体型关系\n社会性：人群规模对社会行为和现象；例如，城市规模与城市发展、社会交流以及资源利用之间可能存在一些规模效应\nTowhee 框架\n是一个用于处理非结构化数据的框架，它利用最新的机器学习模型来创建 ETL（提取、转换、加载）流水线。非结构化数据是指无法存储在表格或键值对格式中的数据，如图像、视频、文本等。\nVGG 网络\n视觉几何组（Visual Geometry Group）所开发，VGG网络使得网络设计的理念发生了重要转变，即通过重复使用简单的层结构（3x3卷积核和2x2池化层）并深化网络结构，来提高性能。VGG网络同时还证实了深度是实现优秀性能的关键因素之一。\n感知损失（perceptual loss）",
    "url": "/blog/AiNotes",
    "chunkIndex": 33,
    "totalChunks": 73,
    "startPos": 10586,
    "endPos": 10932,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-34",
    "title": "AiNotes (第35段)",
    "content": "...关键因素之一。\n感知损失（perceptual loss） 也称为内容损失（content loss），是一种在深度学习特别是在视觉相关任务中使用的损失函数。它不同于传统的像素级损失函数（例如L1损失和L2损失），感知损失更注重于图像内容的感知相似性而不只是像素值的相似性。\n例子:假设我们正在进行一个图像风格迁移任务，其中目标是将一幅图像的风格（如梵高的画风）迁移到另一幅图像上，同时保留图像的内容。理想情况下，生成的图像应该在视觉上看起来要有梵高笔触风格的颜色和纹理，但同时能识别出原图的内容（如城市的轮廓、天空的位置等）。\n在这个任务中，如果使用像素级损失，那么模型可能会非常注重确保生成图像在像素层面与原图尽可能接近，而忽视了风格上的转变。这可能导致风格迁移效果不明显。",
    "url": "/blog/AiNotes",
    "chunkIndex": 34,
    "totalChunks": 73,
    "startPos": 10932,
    "endPos": 11242,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-35",
    "title": "AiNotes (第36段)",
    "content": "...接近，而忽视了风格上的转变。这可能导致风格迁移效果不明显。 实现方式：如果使用感知损失来训练模型，我们会首先通过一个预先训练好的深度CNN（如VGG网络）传递原图和生成图，然后计算这两幅图在某些内部层激活值的差异。这些层的激活值代表了图像的高级特征，所以这种差异反映了它们在内容和感知上的相似度。最小化这种差异可以鼓励生成的图像在视觉感知层面上更贴近原图的内容，同时也有目标风格的特质。\n适用任务：风格迁移、超分辨率和图像合成等。\n问题：哪一图层是提取的风格信息？\n>>在CNN中，随着层级的加深：\n初始层主要捕捉基础信息，如边缘和颜色。这些层对图片细节的响应很敏感，但并不捕捉具体的风格信息。\n中间层捕捉更复杂的特征，如纹理和图案，这些正是构成图像风格的要素。\n深层则表示更高级的内容，例如图像中的对象和整体布局。\nstable diffusion",
    "url": "/blog/AiNotes",
    "chunkIndex": 35,
    "totalChunks": 73,
    "startPos": 11242,
    "endPos": 11588,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-36",
    "title": "AiNotes (第37段)",
    "content": "...图像中的对象和整体布局。\nstable diffusion stable diffusion 是一个生成模型\n目标：用降噪网络生成清晰的图像（加噪是辅助训练降噪）\n类比：类似 GAN 模型，只不过 GAN 是个步骤的对抗训练，而 SD 是一个多步骤\n方法\n加噪过程（前向过程）是一个马尔可夫链，它逐步将随机噪声添加到数据中，直到数据变成纯噪声。这个过程是可控的，因为我们知道每一步加入的噪声量。通过这种方式，模型可以学习在任何给定的时间步骤预测噪声的分布。\n降噪过程（逆向过程）中，模型使用在加噪过程中学到的知识来预测噪声，并从噪声数据中去除这些噪声，逐步恢复出清晰的数据。如果没有加噪过程，模型就没有机会学习这些噪声分布的信息，也就无法有效地进行降噪和数据重建\n疑问\nSD 中将加噪图片输入U-Net中预测噪声如何理解？",
    "url": "/blog/AiNotes",
    "chunkIndex": 36,
    "totalChunks": 73,
    "startPos": 11588,
    "endPos": 11920,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-37",
    "title": "AiNotes (第38段)",
    "content": "...疑问\nSD 中将加噪图片输入U-Net中预测噪声如何理解？ \"预测噪声\"是扩散模型的一部分，它涉及到将图像从含有噪声的状态逐步恢复到清晰的状态。SD模型首先将一张完全随机的噪声图像（或者是经过一系列噪声添加步骤后的图像）输入到U-Net中。U-Net的目标是预测这张噪声图像中的原始噪声成分。一旦预测出这些噪声，模型就可以从噪声图像中去除它们，从而使图像逐渐变得更清晰。\n降噪过程中的预测噪声跟实际噪声的对比，这里的实际噪声是从加噪中得到的么？\n什么是噪声分布信息？\n噪声类型（高斯噪声等），噪声参数（均值方差），时间依赖项（噪声的量和性质会随着时间步骤的推进而改变）\n神经网络可解释性\n增量学习",
    "url": "/blog/AiNotes",
    "chunkIndex": 37,
    "totalChunks": 73,
    "startPos": 11920,
    "endPos": 12189,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-38",
    "title": "AiNotes (第39段)",
    "content": "...质会随着时间步骤的推进而改变）\n神经网络可解释性\n增量学习 理论：增量学习的核心在于模型能够通过不断学习新数据来提升自身的性能，即使这些数据是由模型自身已经准确识别过的。源于人类的终身学习能力，即不断获取、调整和转移知识的能力，同时避免灾难性遗忘——即新知识的学习对旧知识造成的干扰。\n思考：意味着模型识别准确的新数据再来投喂给模型本身训练也能提升模型准确率？\ndata-centric AI \nData-centric AI is the discipline of systematically engineering the data used to build an AI system. — Andrew Ng\nSAM  data-centric AI\n核函数\nkernel function or kernel trick",
    "url": "/blog/AiNotes",
    "chunkIndex": 38,
    "totalChunks": 73,
    "startPos": 12189,
    "endPos": 12527,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-39",
    "title": "AiNotes (第40段)",
    "content": "...rnel function or kernel trick 概念：将原始空间中的向量作为输入向量，并返回特征空间（转换后的数据空间,可能是高维）中向量的点积的函数称为核函数。\n简单理解：一种便捷的计算在高维空间里的内积的方法。高维空间的数据计算存在困难。所以替代方案是在特征空间中计算相似度度量，而不是计算向量的坐标，然后应用只需要该度量值的算法。用点积(dot product)表示相似性度量。\n歧义：把数据从低维映射到高维的是映射函数而不是核函数\n带例子的核函数解释\n核函数概念\n嵌入层\n嵌入层是一种将离散值转换为连续向量的技术；\n例如：torch.nn.Embedding(10, 5) 将创建一个嵌入层，该层可以将离散值（例如：[1,'a','你好']）映射到连续向量空间中的 5 维向量。\n如何理解这里的离散跟连续呢？",
    "url": "/blog/AiNotes",
    "chunkIndex": 39,
    "totalChunks": 73,
    "startPos": 12527,
    "endPos": 12862,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-40",
    "title": "AiNotes (第41段)",
    "content": "...续向量空间中的 5 维向量。\n如何理解这里的离散跟连续呢？ 向量里的每一项是否连续，决定了向量本身是连续的还是离散的。例如：[0.2,0.3,0.5] 是一个连续向量，因为它的每一项都是实数，而实数是连续的。 这样的向量可以进行连续的运算和比较，比如求和，求差，求点积，求模长等。\n而离散是指每一项都不是连续的。例如，[1,‘a’,‘你好’]是一个离散向量，因为它的每一项都是离散的，而且不能进行连续的运算和比较。中的1不可能是’a’，因为它们属于不同的集合，也没有定义它们之间的转换规则。\n机器学习与英语学习",
    "url": "/blog/AiNotes",
    "chunkIndex": 40,
    "totalChunks": 73,
    "startPos": 12862,
    "endPos": 13088,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-41",
    "title": "AiNotes (第42段)",
    "content": "...的集合，也没有定义它们之间的转换规则。\n机器学习与英语学习 机器学习的内容输出可以类比为通过沉浸式学习英语后能够说出英语，其中另一种方式是通过先学习词法和语法规则。在机器学习中，模型通过大量的数据输入（数据投喂）来理解其中的潜在规律和特征。类似地，通过沉浸式学习英语，我们可以在大量的语言环境中感知和理解英语的潜在规律和特征，从而能够流利地说出英语。\n早期的人工智能（通过条件语句进行判断然后做输出）与先学习词法和语法规则的方法与相似。早期的人工智能系统通常使用预定义的规则和条件语句来处理输入并生成输出。这些规则和条件语句基于词法和语法规则，用于处理特定的输入情况。类似地，通过先学习词法和语法规则，我们可以在语言学习中掌握词汇和语法规则，并使用它们来理解和生成语言。",
    "url": "/blog/AiNotes",
    "chunkIndex": 41,
    "totalChunks": 73,
    "startPos": 13088,
    "endPos": 13394,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-42",
    "title": "AiNotes (第43段)",
    "content": "...语言学习中掌握词汇和语法规则，并使用它们来理解和生成语言。 两种机器学习区别：通过先预定义的规则和条件语句的方法在一些特定场景下具有**精确性和可解释性**的优势，而通过机器学习从数据中学习的方法则**更加灵活、适应性强，并能够处理复杂情况**。\n两种英语学习区别：通过先学习词法和语法规则来学习英语可以提供**结构化学习和准确性**，但**缺乏实际应用，语感欠缺，学习繁琐**，而沉浸式学习英语则更加贴近**实际应用、注重流利性和文化融合**，但**需要环境支持，初始困难**。\n思考：意味着初始的时候先了解基本语法，后续不断去读各种精选文章（而不是研究更深的语法规则）才是英文学习的最佳路线？而机器学习没有初始化烦恼，所以直接去学海量数据就好？\nGAN，VAE，Diffusion 生成模型理解\n潜空间",
    "url": "/blog/AiNotes",
    "chunkIndex": 42,
    "totalChunks": 73,
    "startPos": 13394,
    "endPos": 13718,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-43",
    "title": "AiNotes (第44段)",
    "content": "...GAN，VAE，Diffusion 生成模型理解\n潜空间 GAN 是先随机一个符合高斯分布潜在空间作为Generator输入生成图片，然后投喂给Discriminate 作为输入判定然后做 反向传播；\nVAE 是通过训练 Encoder 将输入映射到复合高斯分布（实际通过训练得到均值和方差）的潜在空间，然后解码器通过对潜在空间解码得到输出；数据先降维再升维\n在 MNist 中潜在空间可以是20维长度的向量，来表示 20 个不同的均值和方差分布，来代表 20 个可能的特征？\nDiffusion模型和其他生成模型一样，实现从噪声（采样自简单的分布）生成目标数据样本。",
    "url": "/blog/AiNotes",
    "chunkIndex": 43,
    "totalChunks": 73,
    "startPos": 13718,
    "endPos": 13974,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-44",
    "title": "AiNotes (第45段)",
    "content": "...模型一样，实现从噪声（采样自简单的分布）生成目标数据样本。 核心原理是通过一个随机的前向过程（Forward Process）和一个去噪的逆向过程（Reverse Process）来实现从噪声（Noise）到目标数据样本（Data Sample）的转换。\nDiffusion vs GAN\n速度：Diffusion 需要多步骤到图片，而 GAN 是一步到位；所以Diffusion 会慢，但是训练过程也更稳定\n应用面：扩散模型可以利用多种条件来控制生成的图像，比如文本描述、图像掩码、深度图等，而 GAN 通常只能利用类别标签或噪声作为条件。这使得扩散模型可以更灵活地应用于不同的任务，比如图像编辑、图像修复、图像翻译等\nDiffusion 模型过程\n初始噪声：从某个先验分布中生成初始噪声信号。",
    "url": "/blog/AiNotes",
    "chunkIndex": 44,
    "totalChunks": 73,
    "startPos": 13974,
    "endPos": 14293,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-45",
    "title": "AiNotes (第46段)",
    "content": "...n 模型过程\n初始噪声：从某个先验分布中生成初始噪声信号。 扩散过程：通过一系列步骤，将当前噪声信号逐渐扩散，以生成下一个时间步的噪声信号。这个过程中使用了逆扩散方程，可以将当前步骤的噪声信号映射到上一步骤的噪声信号。\n逆扩散采样：通过逆扩散过程中的采样操作，将当前噪声信号转化为以下一步的噪声信号。\n生成器网络：使用生成器网络将当前噪声信号映射回高维空间，生成一帧图像。\n损失函数与优化：根据生成图像与目标真实图像之间的差异，定义适当的损失函数，并通过反向传播和优化算法来更新生成器网络的参数。\n理解 VAE\n“局部是由于方差控制，而全局是由于均值控制”这句话强调了在VAE模型中，方差向量主要影响生成数据的局部细节和变异性，而均值向量则决定了数据在潜在空间中的全局分布和结构。\nVAE理论跟数学\n变分推理\nKL 散度",
    "url": "/blog/AiNotes",
    "chunkIndex": 45,
    "totalChunks": 73,
    "startPos": 14293,
    "endPos": 14624,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-46",
    "title": "AiNotes (第47段)",
    "content": "...的全局分布和结构。\nVAE理论跟数学\n变分推理\nKL 散度 在训练辨别模型时，为了简化计算，人们往往直接对交叉熵进行优化。 而在 在训练生成模型时，为了使分布与相互接近，我们必须直接对KL散度进行优化。\n自信息、熵、交叉熵与KL散度 的推导\nKL-Divergence 与交叉熵\nKL 散度形象说明（翻译）\nEM——期望最大 算法\n交叉熵\n贝叶斯定理\n自由能\n深度学习优化器\n优化方向\n基于动量（NAG）\n基于自动学习率 （例如 RMSprop，配置训练简单）\n结合两者的（Adam 一般最优）\n为什么 WGAN 选择 RMSprop 作为优化器，而不是 Adam?",
    "url": "/blog/AiNotes",
    "chunkIndex": 46,
    "totalChunks": 73,
    "startPos": 14624,
    "endPos": 14878,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-47",
    "title": "AiNotes (第48段)",
    "content": "...AN 选择 RMSprop 作为优化器，而不是 Adam? >> WGAN的目标是通过最小化生成器和判别器之间的Wasserstein距离来提高生成样本的质量。传统的生成对抗网络（GANs）在训练过程中容易出现梯度伪影的问题（告诉你错了，但并没有指出错在哪里，导致更新方向错误，把正确改掉，错误留下），即判别器的梯度无法提供有关生成器当前状态的准确信息，导致训练不稳定。RMSProp优化算法通过自适应地调整学习率来减轻梯度伪影问题，有助于更稳定地训练WGAN。\n深度学习——优化器算法Optimizer详解（BGD、SGD、MBGD、Momentum、NAG、Adagrad、Adadelta、RMSprop、Adam）\n反向传播\n有一个简单的神经元函数 y = w * x，模拟计算梯度和进行反向传播的过程。",
    "url": "/blog/AiNotes",
    "chunkIndex": 47,
    "totalChunks": 73,
    "startPos": 14878,
    "endPos": 15205,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-48",
    "title": "AiNotes (第49段)",
    "content": "...数 y = w * x，模拟计算梯度和进行反向传播的过程。 一次权重更新过程（给定初始数据输入 x = 1，w = 10，实际输出是 10，期望输出 y1 = 2 则 目标 w 为 2）：\n计算损失：\n计算梯度：\n反向传播：\nCGAN MNIST 训练步骤\n1. 固定 generator （ real_label = [batch_size, 10] 的对真实 label的 one-hot 编码 ）\n用真数据训练 output_label = Discriminator(real_image)，d_real_loss = BCELoss(out_label,real_label)",
    "url": "/blog/AiNotes",
    "chunkIndex": 48,
    "totalChunks": 73,
    "startPos": 15205,
    "endPos": 15469,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-49",
    "title": "AiNotes (第50段)",
    "content": "...BCELoss(out_label,real_label) 用虚假数据（噪音 + 真实标签 [batch_size, noise_dim（满足0~1正态分布）] + real_label = [batch_size, noise_dim+10] = z_tensor ）\n训练 fake_image = Generator(z_tensor) 得出 fake_image( Tensor[batch_size, 1, 28, 28])\n再次 out_label = Discriminator(fake_image) ，d_fake_loss = BCELoss(out_label,fake_label(全0))\n计算 D_loss = d_real_loss + d_fake_loss 反向传播，更新 Discriminator",
    "url": "/blog/AiNotes",
    "chunkIndex": 49,
    "totalChunks": 73,
    "startPos": 15469,
    "endPos": 15807,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-50",
    "title": "AiNotes (第51段)",
    "content": "...ke_loss 反向传播，更新 Discriminator 2. 固定 discriminator\n由 fake_image = Generator(z_tensor)\n由 Discriminator(fake_image) 得出 out_label ，g_loss = BCELoss(out_label,real_label)\n计算 G_loss = g_loss 反向传播，更新 Generator\n预处理\n归一化：一种常见的图像预处理操作，它用于将图像的像素值归一化为均值为0、标准差为1的分布，或者只将数据收窄到 -1 ~ 1 之间。常用于 CNN 网络数据预处理",
    "url": "/blog/AiNotes",
    "chunkIndex": 50,
    "totalChunks": 73,
    "startPos": 15807,
    "endPos": 16065,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-51",
    "title": "AiNotes (第52段)",
    "content": "...收窄到 -1 ~ 1 之间。常用于 CNN 网络数据预处理 加速训练：常用的激活函数如 Sigmoid 和 Tanh 在输入值较大或较小的区域会饱和，导致梯度接近或完全为零，从而使梯度下降变得非常缓慢或停滞。通过将像素值缩放到 -1 到 1 的范围，可以使输入值位于激活函数的线性区域，避免梯度饱和问题，提高网络的训练效果。\n模型稳定性：在优化算法中，例如梯度下降法，较大的梯度值可能导致参数更新过大，从而使优化过程不稳定甚至发散。通过将像素值缩放到 -1 到 1 的范围，可以将梯度控制在较小的范围内，提高优化算法的数值稳定性，使模型更容易收敛。\n数据分布一致性：将像素值缩放到 -1 到 1 的范围可以使不同图像之间的像素分布更加一致。这样做的目的是确保输入数据的统计特性在整个训练集上是相似的，从而提高模型的泛化能力。",
    "url": "/blog/AiNotes",
    "chunkIndex": 51,
    "totalChunks": 73,
    "startPos": 16065,
    "endPos": 16398,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-52",
    "title": "AiNotes (第53段)",
    "content": "...的统计特性在整个训练集上是相似的，从而提高模型的泛化能力。 推广：Batch Normalization (BN) 层作用类似，但是应用在**训练阶段**，对每个小批量数据进行标准化\n损失函数\n交叉熵\n熵：阿根廷 1/4概率打进决赛 ，1/2 概率获得冠军，1/8 获得冠军，则有 f(1/8) = f(1/2) + f(1/4)，f(x) := 信息量，推出可能的 f(x) := -log(x) （log 2为底单调上升，加负号才则单调向下）",
    "url": "/blog/AiNotes",
    "chunkIndex": 52,
    "totalChunks": 73,
    "startPos": 16398,
    "endPos": 16592,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-53",
    "title": "AiNotes (第54段)",
    "content": "...og(x) （log 2为底单调上升，加负号才则单调向下） 交叉熵：KL 散度是一种用于衡量两个概率分布之间差异的度量，KL(P || Q) = Σ(P(i) * log(P(i) / Q(i)))，固定分布 P 的时候 KL 散度可以化简为交叉熵 KL(P || Q) = Σ(P(i) * log(P(i) / Q(i))) = -Σ(P(i) * log(Q(i))) = -H(P, Q)；可以很好的用于机器学习损失计算\n问题\n回归跟分类区别？\n分类例子：识别图片是猫还是狗\n回归例子：通过特征1-n预测房价\n思考：分类跟回归的区别是目标的 离散跟连续 区别？还是说输出的label之间是否有“距离度量”？\n为什么交叉熵适合分类，而 MSE 适合回归?\n交叉熵",
    "url": "/blog/AiNotes",
    "chunkIndex": 53,
    "totalChunks": 73,
    "startPos": 16592,
    "endPos": 16897,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-54",
    "title": "AiNotes (第55段)",
    "content": "...”？\n为什么交叉熵适合分类，而 MSE 适合回归?\n交叉熵 概率解释性：交叉熵基于概率分布之间的差异进行度量，更适合分类问题，因为分类问题通常涉及对不同类别的概率分布进行建模和预测。\n梯度更强烈：相对于MSE，交叉熵的梯度更加陡峭，这可以加快模型的收敛速度。对于分类问题，更快的收敛速度可能是一个优势。\nMES\n数学上的合理性：MSE 是对预测值与真实值的差异的平方进行度量，可以提供对预测误差的较为精确的度量。\n对异常值不敏感：平方差的计算使得 MSE 对异常值不敏感，因为平方操作会放大异常值的影响。这在某些回归问题中可能是有益的。\nReference\n王木头学科学\nhttps://zhuanlan.zhihu.com/p/104130889\n回归与分类问题区别\nTransformer \npositional encoding",
    "url": "/blog/AiNotes",
    "chunkIndex": 54,
    "totalChunks": 73,
    "startPos": 16897,
    "endPos": 17235,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-55",
    "title": "AiNotes (第56段)",
    "content": "...nsformer \npositional encoding 位置编码的要求：选择正弦跟余弦组合编码\n每个位置都有唯一的编码。\n在不同长度的句子中，两个时间步之间的距离应该一致。\n模型不受句子长短的影响，并且编码范围是有界的。（不会随着句子加长数字就无限增大）\n必须是确定性的。\n总结\n问题及其解答：\n为什么没有直接使用 1,2,3...这种线性编码？\n原因：周期性模式在位置编码中的不同维度上呈现出不同的变化速度和周期（下面例子会说明）\n捕捉长距离依赖关系（线性模式也能做到，但是不够精细）\n提供更丰富的表示能力：较低频率的维度具有较长的周期，可以捕捉到大范围的序列结构，而较高频率的维度可以更细致地表示局部模式和短距离的依赖关系。\n避免过拟合：随着句子变长，这些值可能会变得特别大，并且我们的模型可能会遇到比训练时更长的句子\n思考例子：",
    "url": "/blog/AiNotes",
    "chunkIndex": 55,
    "totalChunks": 73,
    "startPos": 17235,
    "endPos": 17575,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-56",
    "title": "AiNotes (第57段)",
    "content": "...大，并且我们的模型可能会遇到比训练时更长的句子\n思考例子： 第一个词编码为 [1,2,3]， 则位置可用向量 [秒，分，时]来表示；第二个词编码为 [4,5,6]， 则位置可用向量 [秒 + 1，分 + 1/60，时 + 1/360] 来表示\n周期：在一个词向量上会出现不同的周期变化，能同时追踪近距离跟远距离的词关系：秒针走一个周期 60 秒，分针走一步；分走一个周期 60 分， 时针+1；\n周期设定：通过设定 秒，分，时之间的周期关系（比如可以设定600秒，分针才走一步，则会拉上周期变化，追踪更远的词关系）\nReference\npositional encoding blog\npositional encoding stackexchange + youtube\nself-attention\n思考",
    "url": "/blog/AiNotes",
    "chunkIndex": 56,
    "totalChunks": 73,
    "startPos": 17575,
    "endPos": 17900,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-57",
    "title": "AiNotes (第58段)",
    "content": "...e + youtube\nself-attention\n思考 多头注意力机制与卷积的多通道（channel）进行类比。多头注意力机制和卷积的多通道都涉及并行地学习不同的特征表示。它们都致力于提取输入数据的多样化特征，并捕捉输入中的不同模式和关联性。\nReference\nself-attention\nmulti-head attention in transformer)\none hot 编码\nOne-hot 编码是一种将离散的分类标签转换为二进制向量的方法，它的优点是可以消除不同类别之间的偏序关系，使得特征之间的距离计算更加合理。（方便在机器学习分类任务计算 LOSS）\n例子\n比如，有一个离散型特征，代表工作类型，该离散型特征，共有三个取值，不使用one-hot编码，其表示分别是x_1 = (1), x_2 = (2), x_3 = (3)。",
    "url": "/blog/AiNotes",
    "chunkIndex": 57,
    "totalChunks": 73,
    "startPos": 17900,
    "endPos": 18246,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-58",
    "title": "AiNotes (第59段)",
    "content": "...= (1), x_2 = (2), x_3 = (3)。 两个工作之间的距离是，(x_1, x_2) = 1, d(x_2, x_3) = 1, d(x_1, x_3) = 2。那么x_1和x_3工作之间就越不相似吗？显然这样的表示，计算出来的特征的距离是不合理。\n那如果使用one-hot编码，则得到x_1 = (1, 0, 0), x_2 = (0, 1, 0), x_3 = (0, 0, 1)，那么两个工作之间的距离就都是sqrt(2).即每两个工作之间的距离是一样的，显得更合理。\n实现\n思考：如果是不定长编码，该如何改进?\n机器学习：数据预处理之独热编码（One-Hot）\nCRNN + CTC 解决变长文本识别\nCTC 如何计算预测序列跟目标序列的相识度？",
    "url": "/blog/AiNotes",
    "chunkIndex": 58,
    "totalChunks": 73,
    "startPos": 18246,
    "endPos": 18553,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-59",
    "title": "AiNotes (第60段)",
    "content": "...变长文本识别\nCTC 如何计算预测序列跟目标序列的相识度？ 1. 生成 time step 的预测概率（有 CRNN 模型输出），每个 time step 会有对类别的预测概率向量\n2. 通过算法将所有可能路径的概率相加，并取对数（通常用于数值稳定性）得到最终的相似度分数。\nReference\n深度学习编程范式\nTensorflow vs Pytorch（符号式（也叫声明式）与命令式程序）\n命令式\n更加灵活：原生语言的灵活性跟运行时断点\n对应符号式（DSL）：\n节省内存：掌控全局的内存分析并优化\n符号图：!符号图\n类比：类似 react jsx命令式（直接难优化）模板跟 vue 的声明式（真正执行前能做各种运行时优化）模板？\nReference blog\n机器学习分类的一点技巧\n对数据进行分类\n有特征：直接通过已经有的分类进行绘制图",
    "url": "/blog/AiNotes",
    "chunkIndex": 59,
    "totalChunks": 73,
    "startPos": 18553,
    "endPos": 18895,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-60",
    "title": "AiNotes (第61段)",
    "content": "...巧\n对数据进行分类\n有特征：直接通过已经有的分类进行绘制图 先通过特征维度绘制图；例如：数据集仅包含两个分离相当明显的聚类。其中一个簇包含 Iris setosa，而另一个簇包含 Iris virginica 和 Iris versicolor；通过特征绘制出的图会分成明显2堆，其中一堆是交错2种类型 Iris\n如果没有明显的聚类，并且数据维度多，可以通过 PCA 等方式降维后再分\n无特征：则先通过 KMeans 能方式聚类，再通过有特征方式分析\n尝试理解 ONNX （Open Neural Network Exchange）\n是什么？ONNX = （模型本身 + 模型训练好的权重跟偏置）的一种更加抽象的表达",
    "url": "/blog/AiNotes",
    "chunkIndex": 60,
    "totalChunks": 73,
    "startPos": 18895,
    "endPos": 19174,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-61",
    "title": "AiNotes (第62段)",
    "content": "...模型本身 + 模型训练好的权重跟偏置）的一种更加抽象的表达 如何表示？使用预定义的 operator（描述输入与输出的关系，例如：add算子=  inputA + inputB = OutputC，可拓展）来描述模型，用向量描述训练好的参数\n作用？实现不同深度学习框架和平台之间的模型互操作性\n为什么 pytorch 在导出 ONNX 的时候需要传入一组输入？原因：\nONNX 并非像编译器一样彻底解析原模型的代码，记录所有控制流；而是不考虑控制流的静态图\n而是利用 pytorch trace 机制，将参数传入模型执行，并记录执行这组输入对应的计算图\n深度学习中的 Epoch 和 Batch\n1. Epoch 是什么？ \n一次 Epoch = 让所有数据通过模型正向+反向传播一次 = 一个完整的学习周期\n2. Epoch 设置多少次合适？\n无定论：",
    "url": "/blog/AiNotes",
    "chunkIndex": 61,
    "totalChunks": 73,
    "startPos": 19174,
    "endPos": 19522,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-62",
    "title": "AiNotes (第63段)",
    "content": "...整的学习周期\n2. Epoch 设置多少次合适？\n无定论： 次数少会导致欠拟合；\n次数多会导致过拟合；\n3. 什么是 Batch？\nBatch Size = 一次训练的样本数\n每一次参数的更新所需要损失函数并不是由一个数据获得的，而是由一批数据加权得到的\n4. Batch 的作用？\n效率：利用矩阵计算加速（相对于单个去训练）\n稳定性：平均每个数据样本的贡献，减少梯度的方差\n多大合适：看情况，太小会导致训练太久；太大会导致内存受不了\nReference\nepoch-vs-iterations-vs-batch-size\nGPT 尝试\n1. 代码尝试\n重构转换\n输入 js -> ts\n优化\n格式化代码\n创建\n创建插件（eslint）步骤：写测试用例 -> 输入 gpt -> 生成插件 -> 微调成型",
    "url": "/blog/AiNotes",
    "chunkIndex": 62,
    "totalChunks": 73,
    "startPos": 19522,
    "endPos": 19845,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-63",
    "title": "AiNotes (第64段)",
    "content": "...试用例 -> 输入 gpt -> 生成插件 -> 微调成型 问题：自动生成的代码会比较繁琐或者隐藏逻辑问题，也不会去利用第三方的包的能力\n目前方案：需要 developer 找到更便捷的方式再去投喂给 gpt 生成更加合理简洁的代码\nCNN 的简单理解\n网络越深，学习的知识越抽象：比如第一层hidden layer负责编码诸如点、线、边缘等浅层信息；第二层hidden layer编码简单点的纹理、形状等信息；第三层hidden layer编码诸如眼睛、鼻子等目标的形状...，然后逐层学习，不断地提取抽象的特征，一气呵成，最终学会了辨识花草树木、飞禽走兽等等。 - reference",
    "url": "/blog/AiNotes",
    "chunkIndex": 63,
    "totalChunks": 73,
    "startPos": 19845,
    "endPos": 20110,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-64",
    "title": "AiNotes (第65段)",
    "content": "...学会了辨识花草树木、飞禽走兽等等。 - reference 网络越宽，每一层学习的知识越丰富：增加网络的宽度意味着同一个hidden layer有着更多的神经元，每一个神经元代表一种颜色，一个方向，一种纹理，组合起来便可以学习到更多不同的颜色信息，各个不同的方向以及不同频率的条纹信息。\n一句话信息\n生成对抗网络（GAN） VS 变分自编码器（VAE）： GAN 倾向于生成逼真的合成样本，而 VAE 倾向于生成具有一定程度多样性的样本。如果期望生成特定目标样本，可以考虑 CGAN 跟 CVAE* GAN 基本原理及其应用",
    "url": "/blog/AiNotes",
    "chunkIndex": 64,
    "totalChunks": 73,
    "startPos": 20110,
    "endPos": 20343,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-65",
    "title": "AiNotes (第66段)",
    "content": "...以考虑 CGAN 跟 CVAE* GAN 基本原理及其应用 DALL-E uses Discrete Variational Autoencoder (dVAE) for this step. dVAE is a variant of traditional Variational Autoencoder (VAE) that operates in a discrete latent space. It is similar to VQ-VAE but uses distribution instead of nearest neighbor.",
    "url": "/blog/AiNotes",
    "chunkIndex": 65,
    "totalChunks": 73,
    "startPos": 20343,
    "endPos": 20590,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-66",
    "title": "AiNotes (第67段)",
    "content": "...instead of nearest neighbor. VIT - Google推出了VIT（Vision Transformer）：一个和Bert几乎一致，同时不添加任何卷积结构的图像分类模型。VIT在Transformer上的成功，证明了可以用统一的模型，来处理不同领域（语言/图像/视频）的任务，进而开启了多模态模型研究的新篇章。\nvit彻底赢了 CNN 么：transformer全局感受野，在大图片或者说找东西时效果好（类似近视眼，能够感受图像大轮廓）。cnn局部感受野，对细节处理较好（理解像素级别的问题，例如 医疗影像）。\n文摘 - 高手解决问题的方式从来都不是纠结问题本身，而是升维；升维成功，问题也就解决了",
    "url": "/blog/AiNotes",
    "chunkIndex": 66,
    "totalChunks": 73,
    "startPos": 20590,
    "endPos": 20875,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-67",
    "title": "AiNotes (第68段)",
    "content": "...从来都不是纠结问题本身，而是升维；升维成功，问题也就解决了 雷军2023演讲 - 如何快速学习：知识不全是线性的，大部分是网状的，知识点之间不一定有绝对的先后关系；前面内容看不懂，跳过去，并不影响学后面的；后面的学会了，有时候更容易看懂前面的。\nAGI 的一点理解\n机器学习训练了很多模型，而 LLM 只是其中之一；\nChatGPT 之所以跟 AGI 最接近，是因为语言模型的通用性；\n如果能够理解自然语言，那就可以实现所有文字能够描述的任务；\n其他 AI 任务，比如图片识别，则只能做到图片相似度能人物处理（推荐），无法拓展到相对通用的任务，除非日常交流能够通过表情包完成\ngpt 可能的研究方向\n建设高难度的综合任务评测数据集（LLM 的测试用例，越完备 -> 越强大）\n高质量数据工程（密集+多样性）：LLM 进化 = 更多高质量数据\n数据例子",
    "url": "/blog/AiNotes",
    "chunkIndex": 67,
    "totalChunks": 73,
    "startPos": 20875,
    "endPos": 21221,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-68",
    "title": "AiNotes (第69段)",
    "content": "...密集+多样性）：LLM 进化 = 更多高质量数据\n数据例子 密度极高的高质量数据：wiki\n高质量问答：quora，知乎\n高质量图片：\n思考\n高质量数据消耗完后 gpt 如何进化？\n能否自己创造知识自己消费（类似 alpha-go 自我对弈的进化）？\n如果 gpt 成长的资料来源于人类，那能否突破人类知识的边界？\n探索 LLM 模型的规模天花板：大模型大数据，能参与的玩家不多\n思考：是否会出现共建超大模型\n增强 LLM 的复杂推理能力\nLLM 纳入 NLP之外更多其它研究领域：多模态？\n如何突破符号领域？如果某个领域是非成文的，不能用符号记录表达，那么 GPT 是否就无能为力。比如，人类的很多心理活动、潜意识、灵感、顿悟等等，GPT 如何模拟生成。\n更易用的人和LLM的交互接口：听觉？",
    "url": "/blog/AiNotes",
    "chunkIndex": 68,
    "totalChunks": 73,
    "startPos": 21221,
    "endPos": 21539,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-69",
    "title": "AiNotes (第70段)",
    "content": "...PT 如何模拟生成。\n更易用的人和LLM的交互接口：听觉？ 超大LLM模型Transformer的稀疏化：相同算力下提高训练速度\n参考\n通向AGI之路：大型语言模型（LLM）技术精要\n关于 chatGPT 引发的人工智能思考 2023-3-1\n人跟AI的关系：淘汰还是互补？\n人有自主目的性（AI暂无），AI是实现目的的工具；\n提问跟回答能力，哪个更能生存下来？\n往后提出好问题能力的重要性将越来越超过回答问题能力\n教育\n投喂答案的教育模式需要变革 -> 把提问能力列入考核标准，更能培养出人机协作人才\n让人利用机器，而不是把人培养成机器\n文理分科这种教育模式急迫需要改变：chatGPT 需要文理结合，提好问题，同时认清答案\nchatGPT 衍生的未来职业？（更新 2023-3-13，参考）\n场景跟问题\n更精准提出需求，才能利用好 chatGPT",
    "url": "/blog/AiNotes",
    "chunkIndex": 69,
    "totalChunks": 73,
    "startPos": 21539,
    "endPos": 21885,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-70",
    "title": "AiNotes (第71段)",
    "content": "...）\n场景跟问题\n更精准提出需求，才能利用好 chatGPT 辅助 chatGPT 修正回答错误，同时又不影响模型输出的其他答案\n检测回答是否由机器生成\n如何避免 chatGPT 泄密，如何做隐私保护（目前可以 chatGPT 被催眠然后突破本身不泄密的限制）\nAI 训练，避免伦理问题\nAI 本身安全：解决提示注入（类似 网页的 xss ，SQL 注入等），越狱等安全问题\n知识产权重新定义：AI生成的东西到底算不算侵权？（例如之前的爬别人网站的数据作为自身的商业盈利依据，是否算侵权？）\n趋势预测\n动作（运动，游戏等数据）文件化：可以对整场羽毛球做文字标记序列化，然后输入 chatGPT，最后可以预测落点跟个人行为\n职业名？\n标注师：标记信息，投喂并训练 AI\n安全员：确保 AI 不被攻破\ngpt自己的回答",
    "url": "/blog/AiNotes",
    "chunkIndex": 70,
    "totalChunks": 73,
    "startPos": 21885,
    "endPos": 22212,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-71",
    "title": "AiNotes (第72段)",
    "content": "...训练 AI\n安全员：确保 AI 不被攻破\ngpt自己的回答 提示工程师：提示是一种指导GPT-4生成内容的文本或图像，通常包含一些特殊的符号或指令。提示工程师就是专门设计和优化提示的人员，他们需要了解GPT-4的内部机制和逻辑，以及不同领域和场景下用户的需求和偏好。提示工程师可以为各种应用场景提供高质量、高效率、高安全性的提示服务。\n内容审核员：虽然GPT-4具有强大的生成能力，但它也可能会产生一些不合适或有害的内容，如色情、暴力、歧视、谣言等。内容审核员就是负责检查和过滤GPT-4生成内容中是否存在这些问题，并及时删除或修改不良内容。内容审核员需要具备一定的专业知识和判断能力，以及良好的道德素养和责任心。",
    "url": "/blog/AiNotes",
    "chunkIndex": 71,
    "totalChunks": 73,
    "startPos": 22212,
    "endPos": 22490,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/AiNotes#chunk-72",
    "title": "AiNotes (第73段)",
    "content": "...具备一定的专业知识和判断能力，以及良好的道德素养和责任心。 内容运营师：内容运营师是利用GPT-4为各种平台和渠道提供优质内容服务的人员，他们需要根据目标受众和市场需求，选择合适的提示和参数来调用GPT-4生成相应类型和风格的内容，并进行编辑、优化和发布。内容运营师需要具备一定的创意思维和文案能力，以及对各种媒体平台和行业动态有一定了解。\n内容创作者：内容创作者是利用GPT-4辅助自己进行创作活动的人员，他们可以将自己想要表达或传达给用户",
    "url": "/blog/AiNotes",
    "chunkIndex": 72,
    "totalChunks": 73,
    "startPos": 22490,
    "endPos": 22681,
    "originalTitle": "AiNotes"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-0",
    "title": "DailyReflections",
    "content": "DailyReflections\n简介：个人随笔\n越来越亮的车灯\n更亮≠更安全，反而带来对向车辆致盲、错判距离等问题。\n“大灯地狱”反映了现代技术在缺乏系统性、共情性设计思维时，如何在不经意间制造新的不平等和风险。它提醒我们：技术理应为人服务，而不是让更多人付出代价。\n简单与难运动\n入门简单比入门难的运动的综合能力要求更强，上限更高，下限也更低？\n入门越容易的运动，形成金字塔的人数就越多，塔尖也就越尖锐；这不是因为运动本身更复杂，而是因为要在海量人中脱颖而出，你必须几乎全能。\n而入门困难的运动往往门槛高、筛选强、参与者少，所以虽然技术复杂、入门难，但上限可能反而不比前者高太多，整体竞争环境也较狭窄。\n精英过剩",
    "url": "/blog/DailyReflections",
    "chunkIndex": 0,
    "totalChunks": 30,
    "startPos": 0,
    "endPos": 309,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-1",
    "title": "DailyReflections (第2段)",
    "content": "...限可能反而不比前者高太多，整体竞争环境也较狭窄。\n精英过剩 大规模升学幻觉：教育制度制造了“精英感”，却没有足够社会位置承接它，造成大规模心理与经济落差。而真正推动社会剧变的往往不是“被抛弃的大众”，而是“未被接纳的精英”。\n当前的精英通道（小学→博士）本身就是“既得利益者”们走出来的一条路径，他们掌握资源与话语权，倾向于维护这条路径的正统性和地位，这就是一种典型的 “路径依赖” + “认知守旧” + “制度惯性”。当前体制内重要岗位（高校、政府、国企）几乎都是通过这条路选拔出来的；他们自然认为这条路径“最可靠”“最正规”；于是继续用考试、学历、资历、论文来选拔下一代 → 进一步固化。\n| 问题类型      | 描述                           |",
    "url": "/blog/DailyReflections",
    "chunkIndex": 1,
    "totalChunks": 30,
    "startPos": 309,
    "endPos": 621,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-2",
    "title": "DailyReflections (第3段)",
    "content": "...述                           | | --------- | ---------------------------- |\n| 🎓 教育膨胀   | 太多高学历者，但没有相应工作岗位匹配（例：博士送外卖）  |\n| 💼 职位竞争   | 精英岗位饱和，内部卷得更狠，小错误都可能被放大处理    |\n| 🧨 精英激进化  | 一部分被排除在“核心圈”之外的准精英，转向民粹、激进主义 |\n| 🧠 意识形态冲突 | 精英内部无法达成共识，派系斗争频繁            |\n| 📉 社会信任下降 | 普通人看到精英互撕，会对系统丧失信心           |\n| 🥊 政治极化   | 精英在政治、媒体、文化领域争夺控制权，导致撕裂加剧    |",
    "url": "/blog/DailyReflections",
    "chunkIndex": 2,
    "totalChunks": 30,
    "startPos": 621,
    "endPos": 936,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-3",
    "title": "DailyReflections (第4段)",
    "content": "...英在政治、媒体、文化领域争夺控制权，导致撕裂加剧    | 解决方案：解决精英过剩的根本，不是“筛掉谁”，而是“多造路” + “改观念” + “改分配”。\n控制精英供给端：合理设限、分流，例如：国内通过本科/职教分流，德国职业教育与学术教育双轨制\n扩大精英吸纳能力：拓展蛋糕，例如：新产业、新科技、新职业路径（如数字经济、绿色能源、人工智能领域），企业出海\nAI与职业：借助大模型/数据智能，精准引导不同背景学生找到适合自己的成长路径\nHow to Do Great Work\nPick the Right Problem 伟大的工作通常源自 重要且有趣的问题\nFind Problems, Don't Manufacture Them 发现问题，而不是制造问题",
    "url": "/blog/DailyReflections",
    "chunkIndex": 3,
    "totalChunks": 30,
    "startPos": 936,
    "endPos": 1238,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-4",
    "title": "DailyReflections (第5段)",
    "content": "...Manufacture Them 发现问题，而不是制造问题 Choose Your Field Wisely 选择你的领域，一些领域更容易做出突破，比如 新兴科技、未被充分研究的领域。\nDevelop Unique Insights 发展独特的见解\nGreat Work Comes from Accumulation 伟大的工作来自于积累\nSurround Yourself with the Right People 远离消极或抑制创造力的环境，找到支持自己思考和探索的圈子。\nIgnore Distractions, Focus on Your Work 伟大的工作需要长时间的专注，而不是被短期的流行趋势所驱动。\nEmbrace Uncertainty 拥抱不确定性，不要害怕失败。\n如何培养品味\nGood design is simple 简约",
    "url": "/blog/DailyReflections",
    "chunkIndex": 4,
    "totalChunks": 30,
    "startPos": 1238,
    "endPos": 1586,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-5",
    "title": "DailyReflections (第6段)",
    "content": "...培养品味\nGood design is simple 简约 Good design is timeless 追求永恒\nGood design solves the right problem 解决正确的问题\nGood design is suggestive 启发性\nGood design is often slightly funny. 有趣\nGood design is hard 困难\nGood design looks easy 看起来简单\nGood design uses symmetry 对称\nGood design resembles nature 模仿自然\nGood design is redesign 重构\nGood design is often strange 奇怪\nGood design happens in chunks.",
    "url": "/blog/DailyReflections",
    "chunkIndex": 5,
    "totalChunks": 30,
    "startPos": 1586,
    "endPos": 1936,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-6",
    "title": "DailyReflections (第7段)",
    "content": "...od design happens in chunks. 世界趋同\n比如 汽车颜色从五颜六色到黑灰；比如各个大模型，最终都支持到搜索跟推理以及多语言；再比如电影电视剧都开始拍续集；再比如各个编辑器都开始支持 agent 跟 tab 补全；再比如各个视频软件都开始搞推荐，同样功能的软件界面变的都一样；\n世界趋同的本质，是效率最大化与风险最小化的共同作用。所有行业都希望以最小的成本满足最多用户的需求，而市场、技术、文化、算法等因素一起推动了这种收敛。\n不过，这并不意味着创新不存在，而是创新往往发生在微小但关键的突破点，比如 iPhone 颠覆了手机界面、GPT 颠覆了搜索体验。未来，虽然大趋势是趋同，但局部突破仍然会带来周期性的变革。\n资本、AGI 与野心\nmRNA 与传统疫苗\n关键点：安全性、免疫效果、生产速度和稳定性",
    "url": "/blog/DailyReflections",
    "chunkIndex": 6,
    "totalChunks": 30,
    "startPos": 1936,
    "endPos": 2271,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-7",
    "title": "DailyReflections (第8段)",
    "content": "...A 与传统疫苗\n关键点：安全性、免疫效果、生产速度和稳定性 mRNA（信使RNA）是细胞内的遗传指令载体，它负责将DNA上的遗传信息传递给细胞的核糖体，指导蛋白质合成。\n流程：设计mRNA -> 生产并包裹mRNA -> 注射mRNA\n传统疫苗是利用灭活病毒、减毒病毒或重组蛋白等抗原物质，通过注射或口服等方式进入人体，激发免疫系统产生免疫反应。\n当前还不能完全取代传统疫苗，原因：\n细菌比病毒复杂，往往有多种抗原，mRNA疫苗很难涵盖所有关键抗原。\n一些疫苗（如鼻喷雾流感疫苗、口服脊灰疫苗）在黏膜部位诱导免疫，防止病毒进入体内，而mRNA疫苗主要在肌肉注射，难以产生强大的黏膜免疫。\nQRCode 的黑块限制\n1. 屏幕二维码的最小模块建议为 4像素 x 4像素。更大的会更容易被扫描识别\n2. 印刷二维码的最小模块建议为 0.4毫米 x 0.4毫米。",
    "url": "/blog/DailyReflections",
    "chunkIndex": 7,
    "totalChunks": 30,
    "startPos": 2271,
    "endPos": 2620,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-8",
    "title": "DailyReflections (第9段)",
    "content": "...印刷二维码的最小模块建议为 0.4毫米 x 0.4毫米。 vscode 括号着色\n\"准备悖论\"\n指的是，如果提前采取有效措施，就可以减轻某种未来的灾难，那么人们就会倾向于认为，这种灾难没有那么严重，不会造成太大损害，从而阻碍对这种灾难进行提前准备。\nhacknews 评分前十的讲座\nGeohash 原理\nGeohash 是一种用于地理位置编码的算法，它将地球上的经纬度转换为一个字符串。这个字符串表示一个矩形区域而不是一个点。Geohash 的核心是不断对经纬度进行 二分区域，并将结果编码为二进制，再转换为更简洁的 Base32 字符串。\n直观解释，把地球看作一个网格，每次增加一个字符（增加编码长度）就进一步细分网格。\n比如：\n9 表示一个大区域（经纬度粗分）。\n9q 表示更小的区域。\n9q8 表示更精确的区域。\n9q8yy 可精确到几米范围内。",
    "url": "/blog/DailyReflections",
    "chunkIndex": 8,
    "totalChunks": 30,
    "startPos": 2620,
    "endPos": 2969,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-9",
    "title": "DailyReflections (第10段)",
    "content": "...q8 表示更精确的区域。\n9q8yy 可精确到几米范围内。 **什么是 S2 编码？**\nS2 是一种地理空间索引系统，基于球面几何将地球表面划分为一系列分层的单元（称为 S2 Cells）。每个单元都有唯一的 ID，用来表示地球上的区域。与 Geohash 不同，S2 直接在球面上工作，避免了平面映射中的失真。\n**对比 Geohash**\n| 特性             | Geohash                   | S2 编码              |\n|------------------|---------------------------|----------------------|\n| 投影方式        | 平面投影                  | 球面投影            |",
    "url": "/blog/DailyReflections",
    "chunkIndex": 9,
    "totalChunks": 30,
    "startPos": 2969,
    "endPos": 3310,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-10",
    "title": "DailyReflections (第11段)",
    "content": "...| 球面投影            | | 单元形状        | 矩形                      | 近似正方形          |\n| 分层方式        | 字符编码（Base32）         | 整数 ID             |\n| 精度与效率      | 适合简单应用              | 更适合复杂查询与计算 |\nS2 在地图服务（如 Google Maps 和 Uber）中被广泛使用，适合处理高精度地理数据和邻近搜索场景。\n牛鞭效应（Bullwhip Effect）",
    "url": "/blog/DailyReflections",
    "chunkIndex": 10,
    "totalChunks": 30,
    "startPos": 3310,
    "endPos": 3557,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-11",
    "title": "DailyReflections (第12段)",
    "content": "...邻近搜索场景。\n牛鞭效应（Bullwhip Effect） 描述的是在供应链中，由于信息在各个环节间传递的不对称或延迟，小范围的需求波动会逐级放大，最终在上游（例如制造商或原材料供应商）形成更大的需求波动。这一现象形象地得名于牛鞭——手腕的小幅动作会在鞭梢引发巨大的波动。\n举例说明\n消费者需求：某商品原本每周需要 10 个，突然需求升至 15 个。\n零售商：为了应对需求增长及库存不足，订购 20 个。\n批发商：考虑到运输周期和订单积压，向制造商订购 30 个。\n制造商：预测未来可能会有更高的需求，于是向供应商订购 50 个。\n最终，上游供应商感受到的需求远高于实际需求的 15 个，形成了牛鞭效应。\n如果金钱统治世界，那么谁统治金钱？",
    "url": "/blog/DailyReflections",
    "chunkIndex": 11,
    "totalChunks": 30,
    "startPos": 3557,
    "endPos": 3848,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-12",
    "title": "DailyReflections (第13段)",
    "content": "...个，形成了牛鞭效应。\n如果金钱统治世界，那么谁统治金钱？ 答案是 那些有能力制造通货膨胀的人统治着金钱。他们首先借钱购买实物资产，通货膨胀之后，再用贬值的钱来还债。- hacker news\n解决团队分歧的四种方式\n方式一：我不同意，但一旦决策定了，我就会一起努力。\n亚马逊创始人贝佐斯说：\"当我跟一个主管反复讨论后，他不同意我的看法。虽然我不认为他正确，但我愿意陪他赌一把。我们认识几十年了，我觉得他可能比我更接近真相。其实我也不知道自己的决定是否正确，干脆照着下属的想法走。\"\n这样有几个好处：\n至少产生了一个大家同意的决策。\n事后不会互相埋怨。\n有利于形成真正的团队精神。\n如何评价世界是一个草台班子\n反映了决策层和执行层之间的脱节现象。决策层虽然有大局观，但在执行细节上往往不够深入；\n执行层尽管懂得如何完成任务，却缺乏对全局的理解。",
    "url": "/blog/DailyReflections",
    "chunkIndex": 12,
    "totalChunks": 30,
    "startPos": 3848,
    "endPos": 4191,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-13",
    "title": "DailyReflections (第14段)",
    "content": "...够深入；\n执行层尽管懂得如何完成任务，却缺乏对全局的理解。 信息传递的障碍加剧了这种脱节，导致决策无法得到有效执行，形成了一种低效的系统。\n悲观者正确，乐观者成功\n悲观者尝试的概率小，不太可能直面风险；但是乐观者会去尝试，有一定概率遭遇风险，但也有一定概率会成功。\n技术弱势群体\n未来的高科技社会，大多数人恐怕都是技术弱势群体，没有太多机会，技术优势集中在少数人手里。\n康威定律 \nAny organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization's communication structure. 软件系统的架构看起来与构建它的开发团队的组织结构非常相似。\n博客文摘部分",
    "url": "/blog/DailyReflections",
    "chunkIndex": 13,
    "totalChunks": 30,
    "startPos": 4191,
    "endPos": 4541,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-14",
    "title": "DailyReflections (第15段)",
    "content": "...看起来与构建它的开发团队的组织结构非常相似。\n博客文摘部分 ConwaysLaw\n维基百科通向哲学现象\n（Wikipedia's \"Getting to Philosophy\" phenomenon）。当你点击每篇文章的第一个非括号中的链接，并不断重复这个过程，大约90%以上的情况下最终会到达“哲学”这个条目。**维基百科的条目结构趋向于层次化的知识体系，通往更抽象的概念。这种体系有助于引导阅读者从具体到抽象进行理解**，因此最终会引导到像“哲学”这样探讨最为根本性问题的学科。\n崖山之后无中华",
    "url": "/blog/DailyReflections",
    "chunkIndex": 14,
    "totalChunks": 30,
    "startPos": 4541,
    "endPos": 4761,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-15",
    "title": "DailyReflections (第16段)",
    "content": "...到像“哲学”这样探讨最为根本性问题的学科。\n崖山之后无中华 “崖山之后无中华”可以理解为中华的“气质”在崖山之战后发生了变化。宋朝时期，中华文明的气质更多体现在对文化和科技的崇尚、对创新的追求以及相对开放的心态。而崖山之后的元、明、清三朝，文化与科技的发展逐渐走向保守和停滞，更加注重政权稳固和经济利益，创新动力不足，文化气质发生了显著的转变。\n卡钦斯基的警告 \n卡钦斯基：论工业社会及其未来\n视频学习胜过读书吗？\n人类学习效率最高的方式，不是\"读书 + 思考\"，而是\"观察 + 模仿\"\n大部分领域的入门方式，都是\"观察和模仿\"，所以视频学习更有效。 对于深入学习，文字和书籍的效果可能好于视频，因为入门以后再往上走，\"理解 + 思考\"的作用越来越大，\"观察 + 模仿\"的作用越来越小。\n雷军2024年度演讲：人生不能后退！",
    "url": "/blog/DailyReflections",
    "chunkIndex": 15,
    "totalChunks": 30,
    "startPos": 4761,
    "endPos": 5094,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-16",
    "title": "DailyReflections (第17段)",
    "content": "...仿\"的作用越来越小。\n雷军2024年度演讲：人生不能后退！ 雷军2024年度演讲：人生不能后退！\n无人驾驶汽车投放\n为了社会稳定，政府需要对无人驾驶出租车有所限制。\n投放策略建议 - 摘抄自阮一峰周刊\n（1）货运优于客运。货运的距离长，更艰苦，更适合无人驾驶。\n（2）公交车优于出租车。公交车本来就缺少司机，无人驾驶可以增加班次，有利于绿色出行。\n（3）郊区和农村优于城区，那里平时不容易叫车，更需要无人驾驶。\n（4）城区的无人驾驶出租车，政府收取管理费，使得运价不低于真人司机。多收的钱用于补贴出租车行业转型。\n关于认知 更改时间（2023-2-24）\n越来越感觉到认知能力才是事情发展的关键，认知是基础然后才是生成要素的聚集；太聚焦在解决问题层面，陷入到具体实现细节的可能不是一个好的开发\n**认知的排序以及问题的解决流程**\n1. 发现问题",
    "url": "/blog/DailyReflections",
    "chunkIndex": 16,
    "totalChunks": 30,
    "startPos": 5094,
    "endPos": 5438,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-17",
    "title": "DailyReflections (第18段)",
    "content": "...开发\n**认知的排序以及问题的解决流程**\n1. 发现问题 2. 定义问题\n3. 分解问题\n4. 问题排序\n5. 解决问题（可能是大部分人停留的阶段）\n基层干部需要**分解问题**能力，然后是其他生产要素的收集（安排优先级，找到合适的人，定一个完成时间等）\n重要核心岗位需要**发现问题**的能力，比起知道如何做，更需要找到值得去做的事情（方向不对，努力白费），然后才是技术介入，定义问题解决问题；\n随着 chatGPT 等人工智能的发展，提出发现一个好问题可能比单纯解决问题更能匹配人机协作的未来；（目前 AI 还只能在给定问题框架下寻找答案，还没有迹象表明 AI 的自主目的性，一切还都是服务于人投喂的目的）\n关于认知的例子:",
    "url": "/blog/DailyReflections",
    "chunkIndex": 17,
    "totalChunks": 30,
    "startPos": 5438,
    "endPos": 5724,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-18",
    "title": "DailyReflections (第19段)",
    "content": "...主目的性，一切还都是服务于人投喂的目的）\n关于认知的例子: 流媒体：看下netflix跟国内的爱优腾的区别，前者自研内容飞涨带着股价飞涨，后者还在天价争夺版权，亏损到现在，爱奇艺最近（2021年底）大裁员了\n技术界：前端大神Evanyou，产出了Vue，之后又诞生了vite，能在合适的时机出手带领一波技术潮流；除了技术强，核心可能在于领先同行的认知水平\n关于沟通\n1. 首先得把概念澄清\n划分概念边界（定义解决的问题类型，例如：vue-cli plugin可以定义成面向工程结构的开发；解释webpack plugin则是面向源码的转换开发）\n类比熟悉概念（例如：解释 vue-cli的plugin机制，就可以类比 webpack plugin机制）\n提纲挈领\n提纲挈领：比喻善于抓住问题的关键与要害；\n前端\n抓住核心可以事半功倍；比如：",
    "url": "/blog/DailyReflections",
    "chunkIndex": 18,
    "totalChunks": 30,
    "startPos": 5724,
    "endPos": 6065,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-19",
    "title": "DailyReflections (第20段)",
    "content": "...抓住问题的关键与要害；\n前端\n抓住核心可以事半功倍；比如： 1. 月经问题：Vue跟React的区别？核心在于Immutable跟Mutable这个理念，其他很多都是在此上的衍生问题\n2. Webpack跟Vite区别？核心在真正按需的理念\n关于自举\n编程里面有个概念叫：自举；\n>编程语言自己编译自己，重复这个过程可以让本身进化\n>>例如：辅助增添新的语言特征，新的特征必须要能用旧的版本来编译解析，也叫向后兼容；\n>>理论上编程语言可以通过自举来完成自身进化，不过更多只是体现在已有概念重组跟语法糖上，没法在底层上做大的改进\n>rust的出现的其中一个原因就是为了摒弃语言的历史包袱，实现一个真正意义的高级语言\n学习知识的过程也可以理解成“自举”\n>通过自身已知概念来解释新知识，将新知识逐步建立在旧知识体系之上，从而“学习到”新知识",
    "url": "/blog/DailyReflections",
    "chunkIndex": 19,
    "totalChunks": 30,
    "startPos": 6065,
    "endPos": 6405,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-20",
    "title": "DailyReflections (第21段)",
    "content": "...识，将新知识逐步建立在旧知识体系之上，从而“学习到”新知识 >>例如：小学算术是从简单1+1=2，再用个位解释灌输十位，用十位解释百位...再例如：学习编程，有C++基础学js语言会比有js基础再学C++简单\n在变化中寻找自举的底层动力，不要怕吭硬骨头，了解底层编程模型范式更能增加自举进化可能性\n关于快速学习\n通性：跟随该领域领军人物的动态\nWhy/What/How\n编程的世界\n熟悉一门新语言\n诞生的背景\n解决了哪些历史问题？\n为什么没有选择现有语言？\n应用场景\n以前的解决方案，选择这门语言的优势\n独有的特性并实践\n语法\n内存对齐策略\n判定相等\njavascript: 2个单独声明的对象不会相等，eg: let a ={name:1},b={name:1}; a!=b",
    "url": "/blog/DailyReflections",
    "chunkIndex": 20,
    "totalChunks": 30,
    "startPos": 6405,
    "endPos": 6714,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-21",
    "title": "DailyReflections (第22段)",
    "content": "...a ={name:1},b={name:1}; a!=b golang: var p1 = point{x: 1, y: 2}; var p2 = point{x: 1, y: 2}; p1==p2\n组合还是继承？\n新框架\n尝试造一个类似的轮子，基本能懂一半\n学科\n1. 从哪里划分出来？为什么被划分？\n2. 解决的独有问题\n3. 个人的应用\n关于新技术应用\n新技术的成熟度\n渐进式使用，先在dev应用\n分享，集思广益\n落地\n例子：应用@swc/core到系统考虑点，参考这里\n1. 框架自身的需要能做到和 babel 解耦；\n2. 自身使用的插件需要使用 swc plugin 再实现一遍；可能带来的副作用：\n    1. 对 bundle 体积的影响；\n    2. 转换后的代码是否存在兼容性问题；",
    "url": "/blog/DailyReflections",
    "chunkIndex": 21,
    "totalChunks": 30,
    "startPos": 6714,
    "endPos": 7038,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-22",
    "title": "DailyReflections (第23段)",
    "content": "...积的影响；\n    2. 转换后的代码是否存在兼容性问题； 3. 如何快速的将 babel 插件转换到 swc 插件；\n    4. swc 现有的能力是否满足从 babel 切换到 swc。\n关于动静结合\n编程语言层面\n动态语言（JIT+VM动态编译执行，例如js）；\n优点：动态下发，容易做热替换，热更新等；dev体验好\n缺点：production性能较差\n静态语言（AOT编译成二进制+Runtime，例如C）\n优点：production性能较好\n缺点：无法动态下发，没法热替换，dev需要等待编译完成\nflutter选在dart语言（动静结合）,dev下JIT，production阶段AOT；兼顾dev跟production\n性格\n好动的人\n优点：社交牛逼症\n缺点：沉下心来搞研究难\n喜静的人\n优点：能沉下心来琢磨事情\n缺点：社交困难",
    "url": "/blog/DailyReflections",
    "chunkIndex": 22,
    "totalChunks": 30,
    "startPos": 7038,
    "endPos": 7385,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-23",
    "title": "DailyReflections (第24段)",
    "content": "...研究难\n喜静的人\n优点：能沉下心来琢磨事情\n缺点：社交困难 做一个动静结合的人？既能沉下来搞研究，也能出去处理人际关系\n关于加班\n有意义、有价值和能成长的忙碌不会让人产生真正疲惫，反而是不断焕发新的激情；\n在错误的方向，复杂的人事上内耗会让人心力交瘁，即便准点下班也会心理疲惫；\n关于中间层\n一段话：所有的问题都能通过加一层中间层解决，如果不行，那就再加一层；\n中间层的好处是屏蔽细节，简化API，增大通用性，但是以损失性能为代价\n编程世界\n例子：\nN-API解决Node addon跟V8 API强绑定导致的升级困难；猜想大概率是做了一个 开发 Node Addon的通用API规范（底层可能还是通过封装V8实现，但是开发者不需要关心具体的V8 API是啥）",
    "url": "/blog/DailyReflections",
    "chunkIndex": 23,
    "totalChunks": 30,
    "startPos": 7385,
    "endPos": 7686,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-24",
    "title": "DailyReflections (第25段)",
    "content": "...封装V8实现，但是开发者不需要关心具体的V8 API是啥） Taro3 能做到框架独立（同时支持react/vue等框架语法），也是在编译中间加了一层编译IR，然后把IR再转换成对应的目标代码\nReact 能做到编写 APP，也是在代码编译中加了一层虚拟DOM中间层 IR（如果是直接编译到浏览器Dom就没跨端什么事了），可以进行不同平台的适配\nLLVM 做成了标准的编译中间层IR，方便无数的新生语言（eg：Rust）可以以 LLVM 作为目标来编译，而无需去适配不同的操作系统\nJsBridge原理连接了js世界跟Native世界，丰富了js的可能性，代价是JsBridge沟通的性能损失\n...\n生活世界\n如果一件事情处理不了，那就找人帮忙，如果还不行，那就再找一个人？\n各种网络平台也就是把自己做成一个中间层，方便人事的协同？\n关于补救方案",
    "url": "/blog/DailyReflections",
    "chunkIndex": 24,
    "totalChunks": 30,
    "startPos": 7686,
    "endPos": 8031,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-25",
    "title": "DailyReflections (第26段)",
    "content": "...也就是把自己做成一个中间层，方便人事的协同？\n关于补救方案 事物无时无刻都在向前发展，很多发展中的问题都是不可预测，所以基本没有一开始就设计出的完美的方案，于是补救方案就来了；当前的补救方案可能促进方案的成长\n编程\n当开发者跟Rust语言对Safe的场景认同不一致的时候，Rust决定把选择权交给开发，于是有了Unsafe；如果开发者正确，那可能是Rust进化的不错机会；例如：extern关键字协助创建外部函数接口（Foreign Function Interface， FFI），extern的函数就肯定是Unsafe的，因为rust没法进行静态检测其他语言的\n当开发者跟typescript对lint的场景认同不一致的时候，于是有了 \"//@ts-ignore\"；可能是TS进化的机会\n人类",
    "url": "/blog/DailyReflections",
    "chunkIndex": 25,
    "totalChunks": 30,
    "startPos": 8031,
    "endPos": 8350,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-26",
    "title": "DailyReflections (第27段)",
    "content": "...\"//@ts-ignore\"；可能是TS进化的机会\n人类 认知的补救方案，早期人类遇到无法解释的现象首先是发挥想象力，创造一个万能的神明；\n关于个人无法化解的场景，可能通过笑来化解；所以笑是避免大脑死机的补救方案？\n关于趋势\n事物的发展都有一定的规律，把握了正确规律可以事半功倍\n计算机相关\n语言的发展：更快、更安全、更容易掌握、特定问题的更好解决方案\nRust就是比C++更友好更安全的方向\nGo 就是来提供更好的服务并发方案\n关于js原型链\n有意思的现象\n关于GC\n手动\n方式：new/delete等手动方式\n语言：C++等\n优点：灵活\n缺点：忘记或者回收不当会导致内存泄漏风险\n自动 \n方式：引用计数，标记清扫，节点复制，新老生代转化组合等；周期性的暂停程序执行而进行GC工作\n典型的语言：js，go\n优点：编写简单",
    "url": "/blog/DailyReflections",
    "chunkIndex": 26,
    "totalChunks": 30,
    "startPos": 8350,
    "endPos": 8683,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-27",
    "title": "DailyReflections (第28段)",
    "content": "...执行而进行GC工作\n典型的语言：js，go\n优点：编写简单 缺点：GC频繁会导致程序执行性能受到影响\n无GC\n方式：所有权\n语言：Rust\n优点：性能高，安全\n缺点：学习曲线陡峭\n思考：实际有GC，只是效率高到不会妨碍到现有程序执行？\n摘要\n>Rust would know when the variable gets out of scope or its lifetime ends at compile time and thus insert the corresponding LLVM/assembly instructions to free the memory.\nReference\nwhat-does-rust-have-instead-of-a-garbage-collector\nReact 踩坑之路由动画",
    "url": "/blog/DailyReflections",
    "chunkIndex": 27,
    "totalChunks": 30,
    "startPos": 8683,
    "endPos": 9020,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-28",
    "title": "DailyReflections (第29段)",
    "content": "...rbage-collector\nReact 踩坑之路由动画 例子：react-router-dom 从版本 6 开始就废弃了Switch组件，用Routes做了替换，然而使用上跟Switch有差别？第三方库 react-router-transition 目前依赖peerDependency react-router-dom@5，也就是升级react-router-dom直接崩？又因为breaking change的差异大，导致 react-router-transition 没法简单就能跟随升级\n相关文档：[[Feature]: Compatibility layer that implements the v5 API ](https://github.com/remix-run/react-router/issues/8695)",
    "url": "/blog/DailyReflections",
    "chunkIndex": 28,
    "totalChunks": 30,
    "startPos": 9020,
    "endPos": 9363,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/DailyReflections#chunk-29",
    "title": "DailyReflections (第30段)",
    "content": "...run/react-router/issues/8695) 现状：现在找个解决方案费时费力，各种实践层出不穷，核心库的breaking change没经过周全的思考就去实施，然后就是一堆填坑的工作量；\n建议：React能否学习Vue把最佳实践维护起来，优势：可以做更周全稳定迭代，方便开发者找到最佳实践，提升工作效率；劣势：是啥？\n数据结构疑问\n数据结构之间的依赖关系：例如 golang map 依赖 hashmap ，hashmap依赖 数组 + 链表\n***个人拙见，酌情观看***",
    "url": "/blog/DailyReflections",
    "chunkIndex": 29,
    "totalChunks": 30,
    "startPos": 9363,
    "endPos": 9577,
    "originalTitle": "DailyReflections"
  },
  {
    "chunkId": "/blog/Introduction#chunk-0",
    "title": "Introduction",
    "content": "If you're not sure which to read, try these\nTech Notes\nDaily Reflections\nAI Notes\nAI Related\nBlog\nhttps://www.anthropic.com/research#overview\nhttps://openai.com/research/index/\nhttps://www.microsoft.com/en-us/research/blog/\nhttps://ai.meta.com/blog/\nhttps://deepmind.google/discover/blog/",
    "url": "/blog/Introduction",
    "chunkIndex": 0,
    "totalChunks": 1,
    "startPos": 0,
    "endPos": 288,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-0",
    "title": "TechNotes",
    "content": "TechNotes\n简介：个人技术思考与总结\nMCP SSE 的缺陷\n当前 MCP 基于的 sse 无状态通信还是有缺陷，会导致客户端多次访问丢失 session（多个 pod 负载均衡的时候很容易出现），还得往 websocket 方向演进\n曾经前端热替换（HMR）有过类似的演变\n为什么 mac 不再使用 CUDA？\n核心原因：符合 Apple 的封闭生态技术路线，转向 Metal 让 Apple 能更好地优化自己的硬件与软件系统，而不依赖外部技术。\n为什么 jest 需要 watchman？\n原因：因为 jest 需要监听文件变化，而 watchman 是文件系统监听工具，更适合大型项目（所以 watchman 得崩溃可能会导致 jest 无法正常工作）",
    "url": "/blog/TechNotes",
    "chunkIndex": 0,
    "totalChunks": 28,
    "startPos": 0,
    "endPos": 334,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-1",
    "title": "TechNotes (第2段)",
    "content": "...atchman 得崩溃可能会导致 jest 无法正常工作） watchman 的启动 ：在第一次 run jest 时，会启动 watchman 持续监听文件变化\nwatch 范围：历史启动过 jest 的目录都会纳入到 watchman 的监听范围，在 MAC 的活动监视器找到 watchman 打开的文件或者窗口看到\n为什么 git 有了分支还需要 tag？\n分支：一个指向提交的可变指针，随着你在分支上提交新的更改，分支会自动向前移动。这意味着分支是动态的、可变的，它们通常代表开发进度，例如 master、develop、feature/xyz 等分支名。\n标签：一个指向特定提交的不可变的指针。标签通常用于标记代码的特定状态，比如一个版本发布（v1.0.0），而这个标签一旦打上，它就永久指向那个特定的提交，不会随时间变化。",
    "url": "/blog/TechNotes",
    "chunkIndex": 1,
    "totalChunks": 28,
    "startPos": 334,
    "endPos": 673,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-2",
    "title": "TechNotes (第3段)",
    "content": "...标签一旦打上，它就永久指向那个特定的提交，不会随时间变化。 Trace ID 三段 代表啥？\ne9e976fde12bc6745f1c51fa80652d01:000000788c34c719:0000000000000000\n第一段全局唯一 Trace ID\n第二段：spanId\n第三段：parentSpanId\n图像相似度\npixelmatch 图片相似度\n简介：具有准确的抗锯齿像素检测（通过色差阈值不一定是差异，还可能是锯齿）和感知色差度量（YIQ ）。 \nY 是最重要的信息，因为黑白电视只依赖亮度。\nI（橙蓝对比）次重要，它对人眼的视觉感知贡献较大。\nQ（紫绿对比）的重要性较低，因此可以被更大程度地压缩。\n为啥有用\n因为人眼对颜色的感知是非线性的，对不同颜色分量的敏感度不同。",
    "url": "/blog/TechNotes",
    "chunkIndex": 2,
    "totalChunks": 28,
    "startPos": 673,
    "endPos": 990,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-3",
    "title": "TechNotes (第4段)",
    "content": "...为人眼对颜色的感知是非线性的，对不同颜色分量的敏感度不同。 即使两个像素在 RGB 空间中看似差异较大，通过 YIQ 空间测量后可能反映出的感知差异较小，从而避免错误地标记为显著不同。\n将 RGB 颜色转换为 YIQ 后，可以根据人眼感知的差异调整颜色分量的权重。比较两张图片时，可以更加准确地反映视觉上的差异，而不是单纯的数值差异。\n场景：专注于精确检测像素差异，常用于回归测试、差异图生成等场景，优先考虑性能。\n结构相似性指标（structural similarity index，SSIM index）\n简介：是一种用以衡量两张数字图像相似程度的指标。当两张图像其中一张为无失真图像，另一张为失真后的图像，二者的结构相似性可以看成是失真图像的图像质量衡量指标。\n为啥有用",
    "url": "/blog/TechNotes",
    "chunkIndex": 3,
    "totalChunks": 28,
    "startPos": 990,
    "endPos": 1300,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-4",
    "title": "TechNotes (第5段)",
    "content": "...结构相似性可以看成是失真图像的图像质量衡量指标。\n为啥有用 结构相似性的基本观念为自然图像是高度结构化的，亦即在自然图像中相邻像素之间有很强的关系性，而这样的关系性承载了场景中物体的结构信息。\n人类视觉系统在观看图像时已经很习惯抽取这样的结构性信息。\n场景：专注于结构相似性，常用于图像质量评估、图像压缩、图像增强等场景，优先考虑准确性。\n识别深度伪造\n英特尔公司宣布了一个叫做 FakeCatcher 的软件，号称可以查出某个视频是否为深度伪造，准确度高达96%。\n它的原理是识别视频人物皮肤的静脉血液流动。如果是真人，血液时刻在体内循环，皮肤上的静脉就会有周期性的深浅变化，深度伪造的人就没有。\n大数据已死？\n大数据作为单一问题就不存在了，变成了海量存储和大型计算两个问题。\n博客本周话题\n尤雨溪解读2022 Web前端生态趋势",
    "url": "/blog/TechNotes",
    "chunkIndex": 4,
    "totalChunks": 28,
    "startPos": 1300,
    "endPos": 1637,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-5",
    "title": "TechNotes (第6段)",
    "content": "...题。\n博客本周话题\n尤雨溪解读2022 Web前端生态趋势 和 Svelte相比，Vue的 Reactivity Transform 和 Solid -labels 都属于统一模型，也就是他不受限于组件上下文，它可以在组建内使用，也可以在组建外使用，优势就是有利于长期的重构和复用\n尤雨溪解读2022 Web前端生态趋势\nE2E 框架原理\npuppeteer,playwright 基于浏览器调试协议；偏底层，功能更丰富，但是跨浏览器一致性有限；\n例如：playwright 跟 chrome 的交互是基于 chrome devtools 协议；\n猜想：能够使用 playwright 实现的能力（例如 UI 的录制回放），也能直接开发对应的浏览器插件实现？\nselenium 基于 webdriver API；跨浏览器一致性，功能有限\nCAP 定理",
    "url": "/blog/TechNotes",
    "chunkIndex": 5,
    "totalChunks": 28,
    "startPos": 1637,
    "endPos": 1983,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-6",
    "title": "TechNotes (第7段)",
    "content": "...river API；跨浏览器一致性，功能有限\nCAP 定理 数据一致（Consistency）、高可用（Availability）、数据分区（Partition tolerance）\nCAP 定理的核心观点是，在设计和运行分布式系统时，需要根据实际应用场景的需求，做出选择和权衡。例如，\n如果一个系统必须保证数据的实时一致性，比如银行系统，那么它可能需要在网络分区时牺牲一部分可用性。\n而如果系统更注重用户体验和服务的不间断性，如社交网络，可能会在网络分区时选择保持高可用性，同时允许暂时的数据不一致。\n数据存储于可视化\nPrometheus + Grafana\nElasticsearch + Kibana\nelasticsearch vs 数据库\nes 侧重于搜索（倒排索引，水平可扩展性更强），数据库侧重于存储（事务，一致性，复杂的关系模型） \n内存对齐",
    "url": "/blog/TechNotes",
    "chunkIndex": 6,
    "totalChunks": 28,
    "startPos": 1983,
    "endPos": 2334,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-7",
    "title": "TechNotes (第8段)",
    "content": "...据库侧重于存储（事务，一致性，复杂的关系模型） \n内存对齐 空间换时间？\n优势：对齐可以加快 CPU 访问速度\n劣势：会浪费空间\n符号表 2023-3-6\n1. wiki\n符号表是一种用于语言翻译器（例如编译器和解释器）中的数据结构。在符号表中，程序源代码中的每个标识符都和它的声明或使用信息绑定在一起，比如其数据类型、作用域以及内存地址。\n2. Example\nSymbol_table#Example\nGo 编译器默认编译出来的程序会带有符号表和调试信息，一般来说 release 版本可以去除调试信息以减小二进制体积。\nABI（Application binary interface）： 约定数据在二进制流上的排列，还有 calling convention 等方式便于不同语种交互",
    "url": "/blog/TechNotes",
    "chunkIndex": 7,
    "totalChunks": 28,
    "startPos": 2334,
    "endPos": 2650,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-8",
    "title": "TechNotes (第9段)",
    "content": "...alling convention 等方式便于不同语种交互 low-level, hardware-dependent  vs API（high-level, hardware-independent，human readable format）\n3. 思考\n有点类似 js 的 source-map？\n风控引擎优化 2023-3-2\n1. 什么是风控？\ninput：风控参数，参数权重，参数组合判定逻辑\noutput：reject/pass\n2. 为什么需要优化？\n风控的判定效率越高，对下游真实业务的阻塞也就越小\n3. 如何做？\n参数获取：参数的获取可能渠道获取（redis/kafka/db 等）\n并行\n参数筛选排序拉取：根据业务数据使用权重，推迟小概率使用的参数拉取\n逻辑组合\n时序调整（调整逻辑执行先后顺序）\n剪枝（编译阶段无效判定逻辑消除）",
    "url": "/blog/TechNotes",
    "chunkIndex": 8,
    "totalChunks": 28,
    "startPos": 2650,
    "endPos": 2997,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-9",
    "title": "TechNotes (第10段)",
    "content": "...（调整逻辑执行先后顺序）\n剪枝（编译阶段无效判定逻辑消除） 扩容机制 2023-3-2\n需要处理好扩容跟收缩\n1. 栈空间（或者堆空间）策略\n分段机制\n旧秩序的延续\n保留旧有数据空间，申请新空间存放溢出数据，通过链表连接各片段\n连续机制\n新秩序替换旧秩序\n触发扩容会申请更大的空间（2倍？类似 golang 切片的动态扩容机制），把旧空间数据搬到新空间，并释放掉旧空间\n优化：延迟归还给操作系统，自己管理内存的伸缩，例如：golang 的 goroutine go内存管理\n2. 服务能力\n横向：拓展更多集群服务\n流量降低时会触发收缩\n纵向：提升单体服务能力\nAOP（面向切面编程） 2023-3-1\n解释：运行时动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程。\n例子：js 的装饰器",
    "url": "/blog/TechNotes",
    "chunkIndex": 9,
    "totalChunks": 28,
    "startPos": 2997,
    "endPos": 3322,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-10",
    "title": "TechNotes (第11段)",
    "content": "...位置上的编程思想就是面向切面的编程。\n例子：js 的装饰器 场景：使用 AOP 将其从核心关注点中分离出来（实际是对执行过程进行代理重写）\nNode.js 日志log\n埋点、数据上报\n性能分析、统计函数执行时间\n给ajax请求动态添加参数、动态改变函数参数\n分离表单请求和验证\n防抖与节流...\n遭遇：golang 垃圾回收 三色标记法与读写屏障\n摘要：AOP其实只是OOP的补充而已。OOP从横向上区分出一个个的类来，而AOP则从纵向上向对象中加入特定的代码。有了AOP，OOP变得立体了。什么是面向切面编程 AOP？\n逃逸分析\n解释：在编译程序优化理论中，逃逸分析是一种确定指针动态范围的方法——分析在程序的哪些地方可以访问到指针。它涉及到指针分析和形状分析。",
    "url": "/blog/TechNotes",
    "chunkIndex": 10,
    "totalChunks": 28,
    "startPos": 3322,
    "endPos": 3625,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-11",
    "title": "TechNotes (第12段)",
    "content": "...程序的哪些地方可以访问到指针。它涉及到指针分析和形状分析。 遭遇：在了解 golang reflect 的过程 “用于获取接口值 reflect.Value 的函数 reflect.ValueOf 实现也非常简单，在该函数中我们先调用了 reflect.escapes 保证当前值**逃逸到堆上**，然后通过 reflect.unpackEface 从接口中获取 reflect.Value 结构体；”\n逃逸基础\n不同于jvm的运行时逃逸分析，golang的逃逸分析是在编译期完成的。\nGolang的逃逸分析只针对指针。一个值引用变量如果没有被取址，那么它永远不可能逃逸。\nC 或者 C++ 是手动分配到栈或者堆上，后面是否会加上运行时逃逸分析\n功能\n逃逸分析辅助编译器优化编译结果",
    "url": "/blog/TechNotes",
    "chunkIndex": 11,
    "totalChunks": 28,
    "startPos": 3625,
    "endPos": 3937,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-12",
    "title": "TechNotes (第13段)",
    "content": "...会加上运行时逃逸分析\n功能\n逃逸分析辅助编译器优化编译结果 将堆分配转化为栈分配。如果某个对象在子程序中被分配，并且指向该对象的指针永远不会逃逸，该对象就可以在分配在栈上，而不是在堆上。在有垃圾收集的语言中，这种优化可以降低垃圾收集器运行的频率。\n编译器优化的场景\nReference\ngolang 逃逸分析详解\ngolang 反射原理\n文章精读之设计原则/模式\n设计原则：SOLID原则\nSingle Responsibility Principle 单一原则；\n一种Class只负责一类事情\nOpen/Closed Principle 开闭原则；\n允许在不改变已有代码前提下添加新功能\nLiskov Substitution Principle 里氏替换原则；\n不要从可实例化的父类中继承（方法），而是要使用基于抽象类和接口的继承。",
    "url": "/blog/TechNotes",
    "chunkIndex": 12,
    "totalChunks": 28,
    "startPos": 3937,
    "endPos": 4276,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-13",
    "title": "TechNotes (第14段)",
    "content": "...化的父类中继承（方法），而是要使用基于抽象类和接口的继承。 Interface Segregation Principle 接口隔离原则；\nClients should not be forced to depend upon interfaces that they do not use. 对于非必须的参数做可选配置，精简接口，简化使用\nDependency Inversion Principle 依赖反转原则\nHigh-level modules should not depend on low-level modules.",
    "url": "/blog/TechNotes",
    "chunkIndex": 13,
    "totalChunks": 28,
    "startPos": 4276,
    "endPos": 4515,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-14",
    "title": "TechNotes (第15段)",
    "content": "...depend on low-level modules. Both should depend on abstractions.Abstractions should not depend upon details. Details should depend on abstractions.\n降低耦合，方便重构跟扩展\n设计模式\nCreational Patterns\nFatory Method\nSingleTon\nBehavioral Patterns\nStrategy\nObserver\nIterator\nStructural Patterns\nAdapter\nDecorator\nProxy\n设计原则 vs 设计模式\n简洁理解：设计模式（语言相关）是对设计原则（语言独立）的实现\n长文理解",
    "url": "/blog/TechNotes",
    "chunkIndex": 14,
    "totalChunks": 28,
    "startPos": 4515,
    "endPos": 4836,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-15",
    "title": "TechNotes (第16段)",
    "content": "...计模式（语言相关）是对设计原则（语言独立）的实现\n长文理解 Design principles provide high level guidelines to design better software applications. They do not provide implementation guidelines and are not bound to any programming language.",
    "url": "/blog/TechNotes",
    "chunkIndex": 15,
    "totalChunks": 28,
    "startPos": 4836,
    "endPos": 5017,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-16",
    "title": "TechNotes (第17段)",
    "content": "...to any programming language. Design Pattern provides low-level solutions related to implementation, of commonly occurring object-oriented problems. In other words, design pattern suggests a specific implementation for the specific object-oriented programming problem.\nReference\nhttps://github.com/ryanmcdermott/clean-code-javascript#solid",
    "url": "/blog/TechNotes",
    "chunkIndex": 16,
    "totalChunks": 28,
    "startPos": 5017,
    "endPos": 5327,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-17",
    "title": "TechNotes (第18段)",
    "content": "...t/clean-code-javascript#solid https://www.tutorialsteacher.com/articles/difference-between-design-principle-and-design-pattern\nhttps://github.com/sohamkamani/javascript-design-patterns-for-humans#behavioral-design-patterns\nhttps://github.com/lpxxn/rust-design-pattern\n关于继承\n谈到继承就会说到“类”，“类”封装的是数据，是对同一类数据实体以及其处理方法的抽象。\n目的：\n    1. 代码复用",
    "url": "/blog/TechNotes",
    "chunkIndex": 17,
    "totalChunks": 28,
    "startPos": 5327,
    "endPos": 5629,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-18",
    "title": "TechNotes (第19段)",
    "content": "...实体以及其处理方法的抽象。\n目的：\n    1. 代码复用 2. 多态（同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果。实现方式：覆盖，重载；某种程度也算代码复用？）\n覆盖：指子类重新定义父类方法，例如js的prototype\n重载：多个同名但参数不同的方法，例如 Rust 函数模板\n继承方式：\n    1. 正统：C++,java\n    2. 模拟：js原型链\n    3. 无：Rust trait 组合实现多态\n        思考：Rust 的编程建模模式更像是组合（Composition） 而不是继承（Inheritance）？有点类似 Vue3 选择 Composition-API 代替 Class-Option？\n多态图解：!多态\n图来源\nReference\n为什么Rust没有继承？",
    "url": "/blog/TechNotes",
    "chunkIndex": 18,
    "totalChunks": 28,
    "startPos": 5629,
    "endPos": 5965,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-19",
    "title": "TechNotes (第20段)",
    "content": "...多态\n图来源\nReference\n为什么Rust没有继承？ https://www.runoob.com/rust/rust-object.html\n关于面向对象\n解释：面向对象的编程语言通常实现了数据的封装与继承并能基于数据调用方法。\n有：js一切都是对象\n无：Rust 不是面向对象的编程语言，但这些功能都得以实现。\nReact状态管理\nRedux\n通过props注入 dispatch/state，规避了 useContext 方案可能导致的重复渲染\nMobx （有点类似createContext + useContext + reactivity）\n特征：Mobx + React 类似等于 Vue\ncreateContext + useContext + useReducer",
    "url": "/blog/TechNotes",
    "chunkIndex": 19,
    "totalChunks": 28,
    "startPos": 5965,
    "endPos": 6280,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-20",
    "title": "TechNotes (第21段)",
    "content": "...ext + useContext + useReducer 坑：createContext 返回的 Provider 中 value变化会触发所有子组件重复渲染\n关联思考：这种方案适用于小型的状态管理？\nTodo：了解重复渲染的运转机制\n优化：对渲染做 useMemo\n文章精读之前端框架设计\n组件类型\n纯展示型的组件，数据进，DOM出，直观明了\n接入型组件，在React场景下的container component，这种组件会跟数据层的service打交道，会包含一些跟服务器或者说数据源打交道的逻辑，container会把数据向下*传递给展示型组件\n交互型组件，典型的例子是对于表单组件的封装和加强，大部分的组件库都是以交互型组件为主，比如说Element UI，特点是有比较复杂的交互逻辑，但是是比较通用的逻辑，强调组件的复用",
    "url": "/blog/TechNotes",
    "chunkIndex": 20,
    "totalChunks": 28,
    "startPos": 6280,
    "endPos": 6618,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-21",
    "title": "TechNotes (第22段)",
    "content": "...有比较复杂的交互逻辑，但是是比较通用的逻辑，强调组件的复用 功能型组件，以Vue的应用场景举例，路由的router-view组件、transition组件，本身并不渲染任何内容，是一个逻辑型的东西，作为一种扩展或者是抽象机制存在\n状态管理\n如何管理将事件源映射到状态变化的过程，如何将这个映射的过程从视图组件中剥离出来，如何组织这一部分代码来提高可维护性，是状态管理要解决的本质问题\nCSS方案\ncss modules\ncss-in-js\n构建工具\n解决的问题\n任务的自动化\n开发体验和效率（新的语言功能，语法糖，hot reload 等等）\n部署相关的需求\n编译时优化\nReference\nEvanyou 聊聊前端框架\nCSS Animation,Transition 原理\nGPU比较擅长于：\n绘制位图到屏幕\n重复的绘制同一个位图",
    "url": "/blog/TechNotes",
    "chunkIndex": 21,
    "totalChunks": 28,
    "startPos": 6618,
    "endPos": 6956,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-22",
    "title": "TechNotes (第23段)",
    "content": "...GPU比较擅长于：\n绘制位图到屏幕\n重复的绘制同一个位图 在不同的位置，以不同的旋转角度，或者不同的缩放大小来绘制同一个位图。\nGPU相对慢的地方：\n将位图加载到显存里。\n例子：\n总结\n选择独立性比较强的CSS属性有助于改善动画效果：transform，opacity，filter （依赖于过滤器的复杂度和浏览器）\n拓展：渲染线程分为 主线程 (main thread) 和 合成线程 (compositor thread)\nReference\nhttps://www.jb51.net/css/348357.html\nVue运行时错误处理\nVue源码里面lifeCycle/watch/directive/transition等的callback/hook等一般会被封装执行\n封装执行要素：  \nfn: Function,",
    "url": "/blog/TechNotes",
    "chunkIndex": 22,
    "totalChunks": 28,
    "startPos": 6956,
    "endPos": 7291,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-23",
    "title": "TechNotes (第24段)",
    "content": "...被封装执行\n封装执行要素：  \nfn: Function, instance: ComponentInternalInstance | null,\ntype: ErrorTypes,\n错误分类：LifecycleHooks | ErrorCodes（其他函数执行点：callback + hook等）\n同步错误处理：尝试函数运行处理同步错误，并搜集返回值\n异步错误处理：根据返回值是否Promise来处理异步错误\nReference\n@vue/runtime-core/errorHandling\n插件对比（Vue vs React）\n插件\n1. Vue插件\n2. React插件\n // 使用地方：一般需要对组件做二次封装进行connect，然后可以useDispatch，**类似Vue inject？**\n插件的插件（Vuex vs Redux）",
    "url": "/blog/TechNotes",
    "chunkIndex": 23,
    "totalChunks": 28,
    "startPos": 7291,
    "endPos": 7638,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-24",
    "title": "TechNotes (第25段)",
    "content": "...nject？**\n插件的插件（Vuex vs Redux） 1. Vuex插件\n// 插件案例\nvuex-persistedstate通过对mutation的拦截，对模块paths进行精准持久化\n2. Redux 中间件\n// 复杂案例\nredux-persist\n插件的插件的插件\n1. redux-persist的插件，或者称为 Transforms\n例子\n总结\nVue的mutable 比 React的immutable对数据的状态的操作来的直接，导致在状态处理插件模式也会不同；vuex（直接mutation改变数据）整体上比redux（通过dispatch action，走整个reducer流程返回新的state）更加直接，导致插件模式上vuex直接劫持mutation比redux劫持reducer来的更加简单\nReference",
    "url": "/blog/TechNotes",
    "chunkIndex": 24,
    "totalChunks": 28,
    "startPos": 7638,
    "endPos": 7981,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-25",
    "title": "TechNotes (第26段)",
    "content": "...edux劫持reducer来的更加简单\nReference https://vuex.vuejs.org/guide/plugins.html\nhttps://redux.js.org/understanding/history-and-design/middleware\nhttps://v2.vuejs.org/v2/guide/plugins.html?redirect=true\n模拟LRU的数据结构（Set vs Array）\nSet会自动追踪插入的先后顺序\n1. Set结构\n2. Array结构\nORM 模块组成\nORM\nORM\nEngine (open db, connect dialect and db_path)\nSession(prepare for next operation,  open/close DB)\nDialect",
    "url": "/blog/TechNotes",
    "chunkIndex": 25,
    "totalChunks": 28,
    "startPos": 7981,
    "endPos": 8330,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-26",
    "title": "TechNotes (第27段)",
    "content": "...ion,  open/close DB)\nDialect dialect : db and dialect container\nsqlite3 : language type <- map -> db column type\nmysql ...\nSchema (Parse a struct to a Schema instance)\n静态语言（例如 golang）：type struct（Modal） <- 反射 -> Table Fields \n动态语言（例如 js）：手动 Table Fields 创建 -> Table Fields\nClause (SQL Builder)\ngenerator: keyword sql string(vars) generation",
    "url": "/blog/TechNotes",
    "chunkIndex": 26,
    "totalChunks": 28,
    "startPos": 8330,
    "endPos": 8642,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/TechNotes#chunk-27",
    "title": "TechNotes (第28段)",
    "content": "...d sql string(vars) generation clause : depend on generator, set/build final sql string\nSession ( SQL Execution )\nraw: raw sql execution\ntable: table operation\nrecord: ORM Open API (Find/Select/Update/Delete/Where/Limit ...) ,depend on Clause/clause & table & raw\nhooks: ORM Open API hook\ntransaction: Atomicity/Consistency/Isolation/Durability\nmigration",
    "url": "/blog/TechNotes",
    "chunkIndex": 27,
    "totalChunks": 28,
    "startPos": 8642,
    "endPos": 8965,
    "originalTitle": "TechNotes"
  },
  {
    "chunkId": "/blog/AI 的关键是语料#chunk-0",
    "title": "AI 的关键是语料",
    "content": "AI 的关键是语料\n观点：模型行为不是由架构、超参数或优化器选择决定的。它是由你的**数据集决定**的。其他一切只是有效地将计算交付给逼近该数据集的手段。\n如果模型的架构、功能、参数，作用是有限的，真正决定性的因素是训练模型的语料。那当发布了一个大模型的时候，也许重点应该放在告诉大家模型用什么语料训练模型。（模型完美，但是语料垃圾，一样不行；反之，模型很平常，但是语料足够，那可能也不错。）\nReference\nhttps://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/\nAI 的关键是语料",
    "url": "/blog/AI 的关键是语料",
    "chunkIndex": 0,
    "totalChunks": 1,
    "startPos": 0,
    "endPos": 282,
    "originalTitle": "AI 的关键是语料"
  },
  {
    "chunkId": "/blog/AI 阻碍新技术传播#chunk-0",
    "title": "AI 阻碍新技术传播",
    "content": "AI 阻碍新技术传播?\n推导：\n如果大家都使用大模型解决技术问题，而大模型又是基于已有数据（旧技术）训练，新技术的应用会落后，没人使用，会导致网上有关新技术的信息很少，导致 AI 缺乏新技术的训练数据，那新技术就很难被普及？\n模型训练出来的模型进一步偏向于旧技术\n这实际上描述了一个 **技术固化陷阱**（Technology Lock-in by AI），或者说 **反馈闭环导致新技术传播困难**。  \n**2. AI 的主流推荐导致“路径依赖”，新技术难以突破**  \n人们依赖 AI 解决方案，而 AI 由于训练数据的局限，往往推荐过去更常见的解决方案。  \n这会导致“**路径依赖效应**”：旧技术持续强化，新技术的应用受限，甚至可能被埋没。",
    "url": "/blog/AI 阻碍新技术传播",
    "chunkIndex": 0,
    "totalChunks": 6,
    "startPos": 0,
    "endPos": 329,
    "originalTitle": "AI 阻碍新技术传播"
  },
  {
    "chunkId": "/blog/AI 阻碍新技术传播#chunk-1",
    "title": "AI 阻碍新技术传播 (第2段)",
    "content": "...”：旧技术持续强化，新技术的应用受限，甚至可能被埋没。 结果是，**即使新技术更优越，也很难被广泛采用**，因为 AI 生成的技术建议大多不会主动推荐它。  \n🔹 **类比**：类似 VHS 战胜 Betamax、QWERTY 键盘取代更高效的 Dvorak 键盘，新技术可能因为“先发优势”不足而被埋没，即使技术上更优越。  \n---\n**3. AI 生成内容影响搜索引擎，进一步降低新技术的可见度**  \n以前，新技术依赖于搜索引擎和技术论坛传播，比如 Google 搜索、Stack Overflow、GitHub 等。  \n现在，AI 生成的内容越来越主导搜索结果，而这些内容大部分基于旧技术。  \n这导致 **新技术的信息被 AI 生成的旧技术信息淹没**，进一步降低了新技术的传播速度。  \n🔹 **现实案例**：",
    "url": "/blog/AI 阻碍新技术传播",
    "chunkIndex": 1,
    "totalChunks": 6,
    "startPos": 329,
    "endPos": 667,
    "originalTitle": "AI 阻碍新技术传播"
  },
  {
    "chunkId": "/blog/AI 阻碍新技术传播#chunk-2",
    "title": "AI 阻碍新技术传播 (第3段)",
    "content": "...一步降低了新技术的传播速度。  \n🔹 **现实案例**： GitHub Copilot 生成的代码通常基于最流行的开源代码，而不是最新的技术方案。\nAI 生成的技术博客往往基于过去已有的文章，而不是基于新研究的前沿进展。\n---\n**4. 缺少真实应用，AI 无法有效训练，形成“冷启动难题”**  \nAI 依赖 **大量数据** 进行训练，但新技术在早期阶段的数据量本就很少，导致 AI **无法有效学习**。  \n由于 AI 不推荐新技术，开发者使用新技术的更少，进一步导致网上缺少相关数据，AI 更无法训练，形成 **恶性循环**。  \n结果是：**新技术因缺少数据无法进入 AI 生态，而 AI 生态又让新技术难以获得数据**，最终造成“冷启动困境”。",
    "url": "/blog/AI 阻碍新技术传播",
    "chunkIndex": 2,
    "totalChunks": 6,
    "startPos": 667,
    "endPos": 971,
    "originalTitle": "AI 阻碍新技术传播"
  },
  {
    "chunkId": "/blog/AI 阻碍新技术传播#chunk-3",
    "title": "AI 阻碍新技术传播 (第4段)",
    "content": "...态又让新技术难以获得数据**，最终造成“冷启动困境”。 🔹 **类比**：新社交媒体平台常常遇到冷启动问题——没有用户 → 没有内容 → 没人愿意加入。而 AI 主导的信息流可能让新技术面临类似的问题。  \n---\n**5. 可能的破解方式**  \n1. **人为干预 AI 训练数据** —— 让 AI 更主动学习新技术，而不是仅仅依赖已有的大数据。  \n2. **推广“非 AI 依赖型”学习方式** —— 鼓励开发者主动学习新技术，而不是完全依赖 AI 推荐。  \n3. **增加新技术的曝光渠道** —— 比如加强 AI 对 arXiv、Hacker News、Reddit 技术讨论等信息的关注，而不仅仅是 Stack Overflow 这种“过去经验导向”的平台。",
    "url": "/blog/AI 阻碍新技术传播",
    "chunkIndex": 3,
    "totalChunks": 6,
    "startPos": 971,
    "endPos": 1285,
    "originalTitle": "AI 阻碍新技术传播"
  },
  {
    "chunkId": "/blog/AI 阻碍新技术传播#chunk-4",
    "title": "AI 阻碍新技术传播 (第5段)",
    "content": "...ack Overflow 这种“过去经验导向”的平台。 4. **实时更新数据**：搜索引擎、论坛、GitHub 代码库都是 AI 训练数据的重要来源，未来 AI 可能会更依赖实时数据+用户贡献，而不是仅依赖历史数据。\n5. **AI 增强搜索能力**：未来的大模型可能会更强地结合搜索引擎（如 Perplexity AI、Bing Chat），这样即使 AI 训练数据较旧，也能搜索最新技术文档。\n6. **企业推广**：企业在新技术推广时，往往会提供 API 文档、示例代码、技术博客（如 OpenAI、Meta、Google），AI 也可以从这些官方资源中学习。\n---\n**总结**\n推导揭示了 AI 可能导致的 **技术固化陷阱**，核心逻辑是：",
    "url": "/blog/AI 阻碍新技术传播",
    "chunkIndex": 4,
    "totalChunks": 6,
    "startPos": 1285,
    "endPos": 1588,
    "originalTitle": "AI 阻碍新技术传播"
  },
  {
    "chunkId": "/blog/AI 阻碍新技术传播#chunk-5",
    "title": "AI 阻碍新技术传播 (第6段)",
    "content": "...AI 可能导致的 **技术固化陷阱**，核心逻辑是： AI 依赖历史数据训练 → 倾向推荐旧技术 → 新技术曝光不足 → 新技术被采用的更少 → AI 训练数据缺失 → AI 继续推荐旧技术，形成闭环。  \n这种情况如果不加以引导，确实可能导致新技术的普及变慢，甚至在某些情况下 **让落后的技术长期占据主流**。  \n参考\nAI 是阻碍技术传播的元凶\nGPT",
    "url": "/blog/AI 阻碍新技术传播",
    "chunkIndex": 5,
    "totalChunks": 6,
    "startPos": 1588,
    "endPos": 1741,
    "originalTitle": "AI 阻碍新技术传播"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-0",
    "title": "ControlNet 与 LoRA 插件",
    "content": "ControlNet 与 LoRA 插件\nControlNet 和 LoRA 并不是完全相同的东西，尽管它们都与神经网络和图像生成有关。\nControlNet：\n作用：用于控制 AI 图像生成。\n特点：允许用户对生成的图像进行精细的控制。\n应用：在计算机视觉、艺术设计、虚拟现实等领域中非常有用。\n示例：用户可以上传线稿，让 AI 帮助填色渲染、控制人物姿态等。\nLoRA：\n作用：用于大模型参数高效微调。\n特点：通过降维和升维来模拟参数的更新量，从而减少训练成本。\n应用：在参数量较大的模型微调中表现优异。\n| 项目   | LoRA                     | ControlNet       |",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 310,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-1",
    "title": "ControlNet 与 LoRA 插件 (第2段)",
    "content": "...| ControlNet       | | ---- | ------------------------ | ---------------- |\n| 改动方式 | 插两个矩阵                    | 复制 UNet + 多组横向连接 |\n| 训练开销 | 很小                       | 较大（副网络）          |\n| 适用领域 | 通用模型（NLP, CV, Diffusion） | 主要是扩散图像模型        |\n| 控制能力 | 弱（用于微调）                  | 强（结构直接控制）        |\nControlNet\nControlNet 是一个神经网络架构，用于控制 Stable Diffusion（SD）模型并扩展其输入条件。\n作用",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 310,
    "endPos": 657,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-2",
    "title": "ControlNet 与 LoRA 插件 (第3段)",
    "content": "...e Diffusion（SD）模型并扩展其输入条件。\n作用 可控性提升：ControlNet 允许创作者通过添加额外的控制条件来引导 SD 模型生成图像，从而提高 AI 图像生成的可控性。\n多样性：它支持多种输入条件，如 Canny 边缘、语义分割图、关键点、涂鸦等，拓展了 SD 的能力边界。\n原理\n假设你有原始的 Stable Diffusion 的 UNet，它是一个 U 形结构：\n🧩（1）复制主模型的 UNet，作为 一个副网络（control branch）\n这个副网络跟主 UNet 结构相同，但只接收你给的“控制图”（比如姿势图、边缘图）；\n它不生成图像，只是提取控制图中的结构、线索信息；\n类似“助手分析线稿图”。\n🧩（2）每一层 feature，都用横向连接（hint）加回主 UNet\n主 UNet 本来从 latent 中恢复图像；",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 657,
    "endPos": 1008,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-3",
    "title": "ControlNet 与 LoRA 插件 (第4段)",
    "content": "...UNet\n主 UNet 本来从 latent 中恢复图像； ControlNet 的副网络在每一层都加一组“控制信号”，告诉主干：“你这里应该照着这个姿势画”、“这个边缘要保留”。\nControlNet 论文解析\nLoRA（Low-Rank Adaptation）低秩适应\nLoRA 是一种用于大模型参数高效微调的方法。\n原理\n理解 LoRA（Low-Rank Adaptation，低秩适配）最核心的一点是：\n**它不是压缩模型本身，而是用“压缩的方式”来训练出新的能力。**\n📦 用体感更强的类比说明\n🎨 类比一：画师画风迁移\n你是一个超强画师（大模型 ），你会画油画。\n现在有人想让你画动漫风。你完全可以重新训练自己，改掉所有油画技巧（Fine-tune 整个模型），但那很痛苦也成本高。\nLoRA 的方式是：",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 1008,
    "endPos": 1339,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-4",
    "title": "ControlNet 与 LoRA 插件 (第5段)",
    "content": "...e 整个模型），但那很痛苦也成本高。\nLoRA 的方式是： 给你加上一个轻量的“风格滤镜”组件（低秩矩阵），专门调整你的输出风格。你本人不变，只训练这小滤镜。\n所以：\n原始技能保留（冻结原模型）；\n新技能通过极少的参数就能学到（只训练 A 和 B）；\n切换风格（加载不同 LoRA 参数）非常快。\n---\n⚙️ 类比二：机械臂微调\n你有一只机械臂（神经网络）用来装配零件，它动作稳定精准（预训练模型）。\n现在工厂来了一个新型号的零件，动作需要调整，但你不想换掉整只机械臂（太贵）。\nLoRA 的做法是：\n给机械臂的某个关节加两个弹簧和一个滑轨（低秩 A 和 B），专门用来微调动作。这样改动小，效果好。\n---\n🧠 LoRA 是不是压缩模型？\n不完全是。",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1339,
    "endPos": 1638,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-5",
    "title": "ControlNet 与 LoRA 插件 (第6段)",
    "content": "...好。\n---\n🧠 LoRA 是不是压缩模型？\n不完全是。 | 方法            | 是否压缩模型？ | 是否可快速迁移？              | 参数更新量        |\n| ------------- | ------- | --------------------- | ------------ |\n| 全参数 Fine-tune | ❌       | ❌                     | 全量更新         |\n| LoRA          | ✅（更新量少） | ✅（可快速切换 LoRA adapter） | 非常少（< 1% 参数） |\n| 模型剪枝、蒸馏       | ✅       | ❌（需重新训练）              | 固定           |",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1638,
    "endPos": 1973,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/ControlNet 与 LoRA 插件#chunk-6",
    "title": "ControlNet 与 LoRA 插件 (第7段)",
    "content": "...| 固定           | ✅ **LoRA 是一种“参数高效训练”方法，也可以视为是一种训练阶段的“压缩”**。\nReference\nGPT",
    "url": "/blog/ControlNet 与 LoRA 插件",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1973,
    "endPos": 2030,
    "originalTitle": "ControlNet 与 LoRA 插件"
  },
  {
    "chunkId": "/blog/Ego 推理#chunk-0",
    "title": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破",
    "content": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破\n核心概念\n**字面含义**：\"ego\" = 自我，Ego Reasoning = 从自我视角出发的有限推理\n**本质**：基于\"我知道、相信、感受到\"的信息进行推理，而非从全知视角推理\n认知科学层面：Theory of Mind 的前置阶段\n三个递进层次\n| 推理类型 | 定义 | 示例 |\n|---------|------|------|\n| **Ego Reasoning** | 我认为 X | 小孩 A 看到玩具被藏，回答\"玩具在盒子里\" |\n| **ToM Reasoning** | 我认为你认为 X | 小孩 A 理解 B 没看到，回答\"B 会以为在桌上\" |",
    "url": "/blog/Ego 推理",
    "chunkIndex": 0,
    "totalChunks": 6,
    "startPos": 0,
    "endPos": 324,
    "originalTitle": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破"
  },
  {
    "chunkId": "/blog/Ego 推理#chunk-1",
    "title": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破 (第2段)",
    "content": "...小孩 A 理解 B 没看到，回答\"B 会以为在桌上\" | | **Meta Reasoning** | 我思考我如何思考 X | 反思自己的推理过程 |\n限制\n无法预测他人行为（缺乏心智建模）\n在博弈、协作、对话中表现\"自以为是\"\n存在 ego-centric bias（自我中心偏差）\nAI 应用层面\n当前 LLM 的推理特征\n**✅ 确实具有 Ego Reasoning 特征：**\n有限视角：只基于可见上下文推理\n无真实信念状态：模式匹配而非真实\"相信\"\n自我中心知识库：依赖训练数据的统计投影\n**🎯 但被训练出\"模拟 ToM\"能力：**\n用户意图建模：推断用户可能不知道什么\n知识状态推断：判断是否需要解释概念\n视角切换：在不同场景下考虑不同视角\n架构对比\n如何突破现有模式\n技术层面的可能路径\n1️⃣ 持久化信念状态追踪",
    "url": "/blog/Ego 推理",
    "chunkIndex": 1,
    "totalChunks": 6,
    "startPos": 324,
    "endPos": 663,
    "originalTitle": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破"
  },
  {
    "chunkId": "/blog/Ego 推理#chunk-2",
    "title": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破 (第3段)",
    "content": "...破现有模式\n技术层面的可能路径\n1️⃣ 持久化信念状态追踪 **技术实现：** Memory Networks、Bayesian Belief Networks、Multi-agent RL\n2️⃣ 反事实推理能力\n**关键能力**：因果推理、反事实生成、意图推断\n**技术路径**：Causal Language Models、Structured World Models、Intent Recognition Networks\n3️⃣ 自我模型与他人模型的显式分离\n4️⃣ 交互式信念校准\n主动探测用户知识边界\n根据反馈动态调整用户模型\n**技术**：Active Learning、RLHF、Dialogue State Tracking\n认知层面的核心能力\n| 能力 | 描述 | 价值 |\n|------|------|------|",
    "url": "/blog/Ego 推理",
    "chunkIndex": 2,
    "totalChunks": 6,
    "startPos": 663,
    "endPos": 1007,
    "originalTitle": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破"
  },
  {
    "chunkId": "/blog/Ego 推理#chunk-3",
    "title": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破 (第4段)",
    "content": "...| 价值 |\n|------|------|------| | **元认知** | 我知道我不知道什么 | 明确知识边界 |\n| **情感与动机理解** | 理解用户为什么问这个问题 | 深层意图推理 |\n| **社会推理** | 理解社会情境中的规范和期望 | 情境适配能力 |\n哲学层面的根本困境\n**问题 1：无真实\"自我\"**\n**问题 2：训练范式限制**\n**问题 3：中文房间悖论**\n表现得像理解 ≠ 真正理解？功能主义 vs 意识主义\n现实主义路线图\n短期（1-3年）：增强的模拟 ToM\n多轮对话信念追踪\n显式知识状态建模\n更好的反事实推理\n主动知识探测\n中期（3-10年）：嵌入式认知架构\n持久化记忆和自我模型\n显式的 ego/other 分离架构\n强化学习 + 社会互动学习\n多模态信念建模\n长期（10年+）：？？？",
    "url": "/blog/Ego 推理",
    "chunkIndex": 3,
    "totalChunks": 6,
    "startPos": 1007,
    "endPos": 1348,
    "originalTitle": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破"
  },
  {
    "chunkId": "/blog/Ego 推理#chunk-4",
    "title": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破 (第5段)",
    "content": "...+ 社会互动学习\n多模态信念建模\n长期（10年+）：？？？ 是否需要\"意识\"才能有真正的 ToM？\n是否需要\"情感\"才能真正理解他人？\nAI 的 ToM 可能就是不同的物种\n实践层面的改进\n对当前 AI 助手来说，可以做到：\n1. **更谦逊**：\"我基于 X 推测你可能想..., 对吗？\"\n2. **更主动探测**：\"你对这个概念熟悉吗？\"\n3. **更显式的推理**：\"我注意到你提到了 X，所以我推测你可能关心 Y\"\n4. **承认限制**：\"这个情境我可能理解得不准，因为我缺乏真实的社会经验\"\n5. **主动更新**：根据反馈动态调整用户模型\n关键洞察\n**Ego Reasoning 是所有高级推理的基础**，但其局限在于\"无法跳出自己的视角\"。\n当前 LLM 的突破路径不是追求\"真正的 ToM\"，而是追求\"足够好的 ToM 近似\"——",
    "url": "/blog/Ego 推理",
    "chunkIndex": 4,
    "totalChunks": 6,
    "startPos": 1348,
    "endPos": 1695,
    "originalTitle": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破"
  },
  {
    "chunkId": "/blog/Ego 推理#chunk-5",
    "title": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破 (第6段)",
    "content": "...\"真正的 ToM\"，而是追求\"足够好的 ToM 近似\"—— 就像飞机不需要像鸟一样飞，但能达到飞的目的。\n个人思考：理解 AI 推理的本质边界，有助于我们更好地设计人机协作模式，在 AI 擅长的地方发挥其优势，在 AI 局限的地方保持人类的主导和校验。\n---",
    "url": "/blog/Ego 推理",
    "chunkIndex": 5,
    "totalChunks": 6,
    "startPos": 1695,
    "endPos": 1795,
    "originalTitle": "Ego Reasoning（自我推理）：AI 认知能力的边界与突破"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-0",
    "title": "GPT与开发-TDD",
    "content": "GPT 是什么？\nGPT 是“Generative Pre-trained Transformer”的缩写，即生成式预训练变换模型，是一种语言模型，可以执行非常复杂的任务，如回答问题、生成文章和代码，或者翻译文章内容等。\n实质：文字接龙（bert 是完形填空）\n如何训练：\nPre-trained （无监督学习）\n自动学习各种资料，熟悉各种语义关系\n好处：学习资料丰富，成本相对低\n劣势：学的杂，不成体系，不好为人所用\n模板规范（监督学习）\n条件：优质范例 \n目标：矫正成符合人类习惯的回答\n例如：有害内容过滤，回答问题并给出原因等；）；\n附加能力：in-context learning 能力（语境内学习）\n使用过程中评分反馈（强化学习）\n目标：提升创意能力",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 0,
    "totalChunks": 11,
    "startPos": 0,
    "endPos": 331,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-1",
    "title": "GPT与开发-TDD (第2段)",
    "content": "...学习）\n使用过程中评分反馈（强化学习）\n目标：提升创意能力 GPT 与编码 - TDD（Test-Driven Development）\n改变需求开发流程\nGPT 辅助前：需求 -> 代码编写 -> test-case\nGPT 辅助后：\n1. 需求 -> test-case -> 代码生成 -> test-case补充生成\n2. 需求 -> GPT方式描述 -> 代码生成 -> test-case 生成\n例子\n需求描述\n实现一个fn 函数，接受一个数字作为参数，并返回一个数字作为结果。\nfn 函数需要满足以下条件\n当参数为 0 时，返回 0\n当参数为 1 时，返回 1\n**对应测试用例**\n问：生成 fn 函数满足以下测试用例： \n答：我可以尝试生成一个 fn 函数满足你的测试用例。请看我的代码：\n需求变化\n当参数为 2 时，也返回 1",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 1,
    "totalChunks": 11,
    "startPos": 331,
    "endPos": 675,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-2",
    "title": "GPT与开发-TDD (第3段)",
    "content": "...例。请看我的代码：\n需求变化\n当参数为 2 时，也返回 1 目标：改变测试用例，输出抽象度更高的代码\n结果：推导出 fibonaci\n问：生成 fn 函数满足以下测试用例： \n答：fn 是一个函数的参数，它表示一个回调函数，也就是在 fn 函数内部执行的函数1。在 JavaScript 中，函数可以作为参数传递给另一个函数，也可以作为另一个函数的返回值2。这种函数称为高阶函数1。在您的测试用例中，fn 函数接受一个数字作为参数，并返回一个数字作为结果。要满足测试用例，fn 函数需要满足以下条件：\n当参数为 0 时，返回 0\n当参数为 1 或 2 时，返回 1\n当参数大于 2 时，返回前两项的和\n这样的函数其实就是斐波那契数列的定义。所以，一个可能的 fn 函数如下：\n概念：拟合 -> 泛化\n>拟合的目的是学习数据背后的规律，对新的数据进行预测或分析",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 2,
    "totalChunks": 11,
    "startPos": 675,
    "endPos": 1025,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-3",
    "title": "GPT与开发-TDD (第4段)",
    "content": "...>拟合的目的是学习数据背后的规律，对新的数据进行预测或分析 >泛化能力反映了模型有没有对客观世界做真实的刻画，还是发生了过拟合或欠拟合；\n>>欠拟合（拟合结果无法满足旧的案例，例如：fn(2)!=1）\n>>过拟合（拟合结果无法满足新案例，如果需求增加到 n=3，结果也要为 1）\n>泛化例子：",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 3,
    "totalChunks": 11,
    "startPos": 1025,
    "endPos": 1142,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-4",
    "title": "GPT与开发-TDD (第5段)",
    "content": "...例，如果需求增加到 n=3，结果也要为 1）\n>泛化例子： 一个泛化能力的例子是高中生每天各种做题，五年高考三年模拟一遍遍的刷，为的什么，当然是想高考能有个好成绩。 高考试题一般是新题，谁也没做过，平时的刷题就是为了掌握试题的规律，能够举一反三、学以致用，这样面对新题时也能从容应对。 这种规律的掌握便是泛化能力，有的同学很聪明，考上名校，很大程度上是该同学的泛化能力好。 考试成绩差的同学，有这三种可能：一、泛化能力弱，做了很多题，始终掌握不了规律，不管遇到老题新题都不会做；二、泛化能力弱，做了很多题，只会死记硬背，一到考试看到新题就蒙了；三、完全不做题，考试全靠瞎蒙。",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 4,
    "totalChunks": 11,
    "startPos": 1142,
    "endPos": 1400,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-5",
    "title": "GPT与开发-TDD (第6段)",
    "content": "...背，一到考试看到新题就蒙了；三、完全不做题，考试全靠瞎蒙。 单语言模型到多语言模型的泛化能力；多语言模型可以利用不同语言之间的共性和联系，学习到更一般的规律和知识，从而在新的语言或任务上表现更好。例如，一个多语言的机器翻译模型，可以在不同的语言对之间进行翻译，而不需要为每一种语言对单独训练一个模型。这样可以节省资源，提高效率，也可以增强模型的鲁棒性和适应性。\n假设我们有一个机器学习模型，它的任务是根据一张照片判断是猫还是狗。我们用一些猫和狗的照片来训练这个模型，然后用一些没有见过的猫和狗的照片来测试它。如果这个模型在测试集上的准确率很高，那么我们可以说它的泛化能力很好，因为它可以对新的数据做出正确的判断。如果这个模型在测试集上的准确率很低，那么我们可以说它的泛化能力很差，因为它不能适应新的数据。\n挑战：泛化能力让 知识的可解释性、可控性 难度增加",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 5,
    "totalChunks": 11,
    "startPos": 1400,
    "endPos": 1749,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-6",
    "title": "GPT与开发-TDD (第7段)",
    "content": "...数据。\n挑战：泛化能力让 知识的可解释性、可控性 难度增加 代码优化\n问：你能不能给我一个更高效的 fn 函数？\n答：有一些方法可以提高 fn 函数的效率，比如：\n使用循环而不是递归，避免重复计算相同的值\n使用数组或对象缓存已经计算过的值，避免重复计算相同的值\n使用数学公式直接计算第 n 项的值，避免计算所有前面的值\n例如，使用数组缓存的方法可以这样写：\n概念：CoT（Chain-of Thought）思维链\nCoT：是一系列中间步骤，用来说明如何从输入得到输出，提高推理的准确性和可解释性。\n>基本思想：通过给LLM一个包含一些输入输出对以及每个输出对应的推理链的前缀，让LLM在生成输出的同时，也生成相应的推理链。这样可以让LLM更好地理解任务要求，避免一些错误或不一致的输出，提高推理的准确性和可解释性。\n>例子：",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 6,
    "totalChunks": 11,
    "startPos": 1749,
    "endPos": 2082,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-7",
    "title": "GPT与开发-TDD (第8段)",
    "content": "...错误或不一致的输出，提高推理的准确性和可解释性。\n>例子： 算术： 如果你有12个苹果，你吃了3个，你还剩多少个？ -> 9个 推理链：12 - 3 = 9\n在展示样例后面加上一个测试样例，比如：\n>>如果你有8个香蕉，你给了朋友4个，你还剩多少个？\n>>模型就会根据前缀中的展示样例和测试样例，来生成一个输出和一个推理链，比如：\n>>如果你有8个香蕉，你给了朋友4个，你还剩多少个？ -> 4个 推理链：8 - 4 = 4\n代码重构\n问：请仿照 function fn(t:boolean){ return true} 重构 fn 函数\n答：根据您的要求，我尝试重构 fn 函数如下：\n用例增强\n问：麻烦给这个函数提供一个完整的测试用例\n答：根据网上的信息，要给一个函数提供一个完整的测试用例，需要考虑以下几个方面：\n测试函数的输入和输出是否符合预期",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 7,
    "totalChunks": 11,
    "startPos": 2082,
    "endPos": 2429,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-8",
    "title": "GPT与开发-TDD (第9段)",
    "content": "...，需要考虑以下几个方面：\n测试函数的输入和输出是否符合预期 测试函数的边界条件和异常情况是否正确处理\n测试函数的内部逻辑是否正确执行\n测试函数的性能和效率是否达标\n例如，使用 Jest 框架，可以给 fn 函数写以下测试用例：\n一点思考\n机遇：GPT 在模式化需求中赋能明显\n风险：Prompt 注意数据隐私（例如：提的 GPT Prompt 涉及到隐私信息）\n观念：发现问题 > 定义问题 > 分解问题 > 解决问题\n开放性思考\n信息跟知识的区别？\n记忆跟学习的区别？\n例子1：学会了王者农药的某个英雄？这里的学会指的是什么？是对技能或者各种套路的熟练背诵还是在对线中各种秀？\n例子2：说一个人学会了羽毛球？这里的学会指的是什么？是对羽毛球各种动作跟对线策略的记忆，还是再实际对线中嘎嘎杀？\n学一个英雄的方式：",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 8,
    "totalChunks": 11,
    "startPos": 2429,
    "endPos": 2756,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-9",
    "title": "GPT与开发-TDD (第10段)",
    "content": "...线策略的记忆，还是再实际对线中嘎嘎杀？\n学一个英雄的方式： 方案1： 从英雄技能描述或者教程开始（信息，记忆，机械记忆，指令记忆，抽象）-> 实践；\n方案2：从对线的体感认识开始（知识，学习，理解记忆，归纳学习，实践），随着对线次数跟对线英雄样本变多，会出现对这个英雄超越常人的理解（主播经常说道的，超越一般人理解） -> 看描述跟教程矫正操作（回到抽象，监督学习）；\nGPT 进化前提：更丰富更高质量的资料样本（可能是局限）；更多的测评数据；更多的实践运用（例如 chatGPT），强化学习？\n丰富：更多的训练资料\n质量：资料的质量决定了 GPT 的进化水平，例如 wiki,quora 等高质量数据平台\n强化学习：理论结合实际\n  ...\n其他角度：记忆是学习的一种手段。记忆的目标是重现（有限，可知），学习的目标是泛化（无限，未知）\n一些资料",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 9,
    "totalChunks": 11,
    "startPos": 2756,
    "endPos": 3101,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPT与开发-TDD#chunk-10",
    "title": "GPT与开发-TDD (第11段)",
    "content": "...现（有限，可知），学习的目标是泛化（无限，未知）\n一些资料 GPT-4论文精读【论文精读·53】\n通向AGI之路：大型语言模型（LLM）技术精要\nMaximizing the Potential of LLMs: A Guide to Prompt Engineering\nLarge language model - Wikipedia\nChatGPT - Wikipedia",
    "url": "/blog/GPT与开发-TDD",
    "chunkIndex": 10,
    "totalChunks": 11,
    "startPos": 3101,
    "endPos": 3260,
    "originalTitle": "GPT与开发-TDD"
  },
  {
    "chunkId": "/blog/GPipe#chunk-0",
    "title": "GPipe",
    "content": "GPipe\nGPipe是一种用于大规模神经网络模型并行化的方法，它通过流水线并行（Pipeline Parallelism）将模型分割成多个阶段，并在不同的设备（如GPU）上进行计算，从而加速训练过程。梯度累积在GPipe中的应用可以帮助解决由于模型分割带来的批量大小限制问题。\n梯度累积\n梯度累积（Gradient Accumulation）是一种在深度学习中用来处理小批量（mini-batch）训练的问题的技术。它的主要作用是在显存有限的情况下，通过累积多个小批量的数据梯度，模拟更大批量的训练效果。这样可以利用较小的显存来进行更大批量的训练，进而提高模型的性能和收敛速度。\n简单例子说明梯度累积",
    "url": "/blog/GPipe",
    "chunkIndex": 0,
    "totalChunks": 6,
    "startPos": 0,
    "endPos": 302,
    "originalTitle": "GPipe"
  },
  {
    "chunkId": "/blog/GPipe#chunk-1",
    "title": "GPipe (第2段)",
    "content": "...训练，进而提高模型的性能和收敛速度。\n简单例子说明梯度累积 假设我们正在训练一个简单的神经网络，但由于显存限制，我们只能使用非常小的批量（比如 batch size = 2）。然而，我们希望通过梯度累积来模拟较大的批量（比如 batch size = 6）的训练效果。\n没有梯度累积\n假设我们有一个数据集，包含6个样本。我们用 batch size = 2 进行训练，每次更新参数时，只考虑这2个样本的梯度。\n1. **第一步：**\n输入：样本1和样本2\n计算损失\n计算梯度\n更新模型参数\n2. **第二步：**\n输入：样本3和样本4\n计算损失\n计算梯度\n更新模型参数\n3. **第三步：**\n输入：样本5和样本6\n计算损失\n计算梯度\n更新模型参数\n每一步都进行一次模型参数更新。\n有梯度累积",
    "url": "/blog/GPipe",
    "chunkIndex": 1,
    "totalChunks": 6,
    "startPos": 302,
    "endPos": 619,
    "originalTitle": "GPipe"
  },
  {
    "chunkId": "/blog/GPipe#chunk-2",
    "title": "GPipe (第3段)",
    "content": "...更新模型参数\n每一步都进行一次模型参数更新。\n有梯度累积 现在，我们使用梯度累积，将6个样本的数据梯度累积后再进行一次模型参数更新。\n1. **第一步：**\n输入：样本1和样本2\n计算损失\n计算梯度\n累积梯度（梯度存储，不更新参数）\n2. **第二步：**\n输入：样本3和样本4\n计算损失\n计算梯度\n累积梯度（梯度存储，不更新参数）\n3. **第三步：**\n输入：样本5和样本6\n计算损失\n计算梯度\n累积梯度（梯度存储）\n4. **更新模型参数：**\n使用累积的梯度进行参数更新\n在这整个过程中，我们只在第三步之后，使用累积的梯度更新了一次模型参数。这个效果相当于我们使用 batch size = 6 进行了一次训练。\n代码示例\n以下是一个使用 PyTorch 的简单代码示例，演示如何实现梯度累积：",
    "url": "/blog/GPipe",
    "chunkIndex": 2,
    "totalChunks": 6,
    "startPos": 619,
    "endPos": 942,
    "originalTitle": "GPipe"
  },
  {
    "chunkId": "/blog/GPipe#chunk-3",
    "title": "GPipe (第4段)",
    "content": "...用 PyTorch 的简单代码示例，演示如何实现梯度累积： 在这个例子中，我们通过设置  来控制梯度累积的次数。每次计算梯度后并不立即更新参数，而是累积起来，直到达到指定的次数才进行参数更新。这样，我们就可以用较小的 batch size 模拟较大 batch size 的训练效果，有效利用显存并提升模型性能。\n总结\n梯度累积是一种在深度学习中处理小批量训练限制的有效技术。通过累积多个小批量的数据梯度，再进行一次模型参数更新，可以模拟更大批量的训练效果，从而在显存受限的情况下提高模型的性能和收敛速度。这种方法特别适用于显存有限但希望利用大批量训练优势的情况。\nGPipe中的梯度累积",
    "url": "/blog/GPipe",
    "chunkIndex": 3,
    "totalChunks": 6,
    "startPos": 942,
    "endPos": 1207,
    "originalTitle": "GPipe"
  },
  {
    "chunkId": "/blog/GPipe#chunk-4",
    "title": "GPipe (第5段)",
    "content": "...限但希望利用大批量训练优势的情况。\nGPipe中的梯度累积 GPipe的主要思想是将模型分割成多个“段”（段落），每个段落在一个独立的设备上进行计算。数据通过这些段落进行前向传播和反向传播。在这种设置中，如果每个设备上只能处理小批量数据，梯度累积可以有效帮助模拟更大批量的训练。\nGPipe如何工作\n1. **模型分割**：\n将模型分割成多个连续的段（例如，4个段），并将每个段分配到不同的设备（例如，4个GPU）。\n2. **流水线并行**：\n输入批量数据分成多个微批次（micro-batch），例如一个大批量分成8个微批次。\n微批次通过流水线在不同的设备上依次进行前向传播和反向传播。\n3. **梯度累积**：\n每个微批次的梯度在反向传播时进行计算并累积。\n累积多个微批次的梯度后进行一次权重更新。\n示例",
    "url": "/blog/GPipe",
    "chunkIndex": 4,
    "totalChunks": 6,
    "startPos": 1207,
    "endPos": 1533,
    "originalTitle": "GPipe"
  },
  {
    "chunkId": "/blog/GPipe#chunk-5",
    "title": "GPipe (第6段)",
    "content": "...算并累积。\n累积多个微批次的梯度后进行一次权重更新。\n示例 假设我们有一个分成4个段的模型，在4个GPU上运行，并且批量大小为32。我们可以将这个批量分成8个微批次，每个微批次大小为4。使用梯度累积，我们可以在每个GPU上累积4个微批次的梯度，然后再进行一次参数更新。\nGPipe中的梯度累积代码示例\n以下是一个简化的伪代码示例，演示GPipe中如何进行梯度累积：\n总结\n梯度累积在GPipe中被应用来解决由于模型分割带来的批量大小限制问题。通过累积多个微批次的梯度并一次性更新模型参数，可以在使用小批量训练的情况下模拟更大批量的训练效果。这不仅有助于更有效地利用显存资源，还可以提高训练的稳定性和模型的性能。",
    "url": "/blog/GPipe",
    "chunkIndex": 5,
    "totalChunks": 6,
    "startPos": 1533,
    "endPos": 1808,
    "originalTitle": "GPipe"
  },
  {
    "chunkId": "/blog/LLM 智能来源#chunk-0",
    "title": "LLM的智能来源：核心概念与扩展",
    "content": "LLM的智能来源：核心概念与扩展\n**核心三要素：**\n**压缩（Compression）**: 大语言模型（LLM）通过训练将海量数据中的语言模式、统计规律和世界知识“压缩”并内化到其参数中。其**泛化能力**和**抽象能力**都是这种高效压缩的直接体现。\n**组合（Composition）**: LLM 能够将学到的语言元素和概念重新组合，生成连贯、有意义的新文本。这种能力是其语言生成和创造性表达的基础。\n**回顾（Retrospection）**: 模型利用注意力机制在生成每个词时“回顾”并关注输入或已生成序列中的关键部分。**上下文理解**是这种“回顾”能力的核心应用。\n---\n**难以完全被概括的扩展概念：**",
    "url": "/blog/LLM 智能来源",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 315,
    "originalTitle": "LLM的智能来源：核心概念与扩展"
  },
  {
    "chunkId": "/blog/LLM 智能来源#chunk-1",
    "title": "LLM的智能来源：核心概念与扩展 (第2段)",
    "content": "...力的核心应用。\n---\n**难以完全被概括的扩展概念：** **涌现能力（Emergence）**: 这是指模型规模达到一定程度后，**非线性地、意外地**展现出的新能力，它不是三个核心要素的简单叠加，而是其复杂交互的宏观结果。\n**推理（Reasoning）**: 尽管推理依赖于压缩、组合和回顾，但它是一个更高级别的认知任务，是这三者在**特定逻辑步骤**中的**复杂应用**。\n**归纳偏置（Inductive Bias）**: 这是模型**架构层面**的固有属性，它**塑造了**压缩、组合和回顾这三个过程的运作方式，而不是它们本身。",
    "url": "/blog/LLM 智能来源",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 315,
    "endPos": 557,
    "originalTitle": "LLM的智能来源：核心概念与扩展"
  },
  {
    "chunkId": "/blog/LLM 智能来源#chunk-2",
    "title": "LLM的智能来源：核心概念与扩展 (第3段)",
    "content": "...**压缩、组合和回顾这三个过程的运作方式，而不是它们本身。 简而言之，可以将 **compression**、**composition** 和 **retrospection** 视为LLM智能的**基础机制**，而其他概念（如泛化、抽象、推理、涌现）则是这些机制在不同维度上的**表现、结果或前提**。",
    "url": "/blog/LLM 智能来源",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 557,
    "endPos": 680,
    "originalTitle": "LLM的智能来源：核心概念与扩展"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-0",
    "title": "NAS-RL",
    "content": "NAS-RL\n全称 Neural Architecture Search（神经架构搜索），是一种自动化搜索最佳神经网络架构的方法。\n传统上，设计一个好的神经网络架构需要专家反复试验和直觉，而 NAS 通过自动化这一过程，NAS 通常使用一种称为「控制器」的模型来进行这些序列决策。这个控制器可能是一个 RNN 或者其他序列模型，它负责在每个步骤做出选择，根据先前的选择历史来决定下一层的类型。控制器通过不断地在搜索空间中探索并优化决策序列，最终找到一个在性能上最优的网络架构。\n核心思想：将网络架构设计问题转换为一个序列决策问题\nNAS 可以理解成深度学习模型的深度学习模型？",
    "url": "/blog/NAS-RL",
    "chunkIndex": 0,
    "totalChunks": 10,
    "startPos": 0,
    "endPos": 289,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-1",
    "title": "NAS-RL (第2段)",
    "content": "...列决策问题\nNAS 可以理解成深度学习模型的深度学习模型？ 可以；它用一个深度学习模型（控制器）不断地生成和优化另一个用于实际任务的深度学习模型（目标模型）的架构。这种方法不仅减少了人工干预，还能发现潜在的、更优的神经网络架构。\n类似于元学习（Meta-Learning）的一种思路，在元学习中，我们学习如何更好地进行学习。在 NAS 中，我们学习如何设计更好的深度学习模型。两者都体现了自我改进和自动化优化的理念。\n控制器的原理？为什么通常是 RNN？\n通常，RNN 被用作控制器是因为其在处理序列数据方面的优势。下面我们详细解释一下控制器的原理以及为什么 RNN 通常被选择用作控制器。\n控制器的原理\n1. **生成架构**：\n控制器模型通过生成一系列离散的决策来定义目标模型的架构。每个决策对应一个具体的架构组件（如选择层的类型、大小、连接方式等）。",
    "url": "/blog/NAS-RL",
    "chunkIndex": 1,
    "totalChunks": 10,
    "startPos": 289,
    "endPos": 638,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-2",
    "title": "NAS-RL (第3段)",
    "content": "...应一个具体的架构组件（如选择层的类型、大小、连接方式等）。 控制器的输出是一个序列，这个序列描述了目标模型的结构。例如，控制器可能输出一个这样的序列：Conv(64, 3x3) -> MaxPool(2x2) -> Dense(128)。\n2. **序列决策**：\n控制器在每一步生成一个决策，这个决策依赖于之前所生成的决策。这个过程自然而然地适合用处理序列数据的模型来实现，因为序列中的每个元素（即每个决策）都与前面的决策有关联。\n3. **优化过程**：\n生成架构后，对对应的目标模型进行训练，并在验证集上评估其性能。\n将评估结果作为反馈给控制器，调整控制器的权重，使其倾向于生成性能更好的架构。这通常通过强化学习（Reinforcement Learning）或进化算法（Evolutionary Algorithms）来实现。\n为什么通常是 RNN？",
    "url": "/blog/NAS-RL",
    "chunkIndex": 2,
    "totalChunks": 10,
    "startPos": 638,
    "endPos": 988,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-3",
    "title": "NAS-RL (第4段)",
    "content": "...y Algorithms）来实现。\n为什么通常是 RNN？ 使用 RNN 是因为其在处理和生成序列数据方面的特点和优势。以下是详细原因：\n1. **序列数据处理能力**：\nRNN 的设计使得其擅长处理序列数据，即可以根据前一步的输出影响下一步的输入，捕捉序列中的依赖关系。\n在 NAS 中，网络结构是一个序列化的决策过程。例如，选择层的类型（卷积层、全连接层等）、层的参数（如滤波器数量、核大小等）、层与层之间的连接等，这些决策需要逐步生成，每一步都依赖于前面的决策。\n2. **记忆和状态保持**：\nRNN 能够保留之前步骤的状态信息，这是通过其隐藏状态实现的。在架构生成过程中，每个决策都是基于前面所有决策的综合结果。\n这种记忆能力在生成复杂的神经网络架构时特别有用，因为每一层的配置可能依赖于之前层的配置。\n3. **灵活性**：",
    "url": "/blog/NAS-RL",
    "chunkIndex": 3,
    "totalChunks": 10,
    "startPos": 988,
    "endPos": 1327,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-4",
    "title": "NAS-RL (第5段)",
    "content": "...一层的配置可能依赖于之前层的配置。\n3. **灵活性**： RNN 可以很自然地扩展到生成变长序列，这对于生成不定长的神经网络架构非常重要。\n控制器可以学习到在何时停止生成新的层，从而生成不同长度的架构。\n控制器 - RNN 的工作流程示例\n1. **初始化**：\n控制器 RNN 初始化隐藏状态和开始令牌，准备生成第一个决策。\n2. **生成第一个决策**：\n根据当前隐藏状态和输入令牌（开始令牌），RNN 生成第一个决策，例如选择一个卷积层 Conv(64, 3x3)。\n3. **更新状态并生成后续决策**：\nRNN 将当前决策作为输入，并更新隐藏状态，生成下一个决策，例如选择一个最大池化层 MaxPool(2x2)。\n4. **重复**：\n重复以上步骤，直到生成完整的神经网络架构。\n5. **输出架构**：",
    "url": "/blog/NAS-RL",
    "chunkIndex": 4,
    "totalChunks": 10,
    "startPos": 1327,
    "endPos": 1657,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-5",
    "title": "NAS-RL (第6段)",
    "content": "...骤，直到生成完整的神经网络架构。\n5. **输出架构**： 控制器输出整个序列，表示生成的神经网络架构。\n6. **训练并评估目标模型**：\n用该架构训练目标模型，并在验证集上评估其性能。\n7. **反馈**：\n将评估结果作为奖励（或惩罚），反馈给控制器 RNN，调整其权重，以优化架构生成策略。\n其他替代方法\n虽然 RNN 是常用的控制器模型，但也有其他方法可以用来实现控制器的功能：\n1. **注意力机制（Attention Mechanism）**：\n使用 Transformer 等基于注意力机制的模型提升生成速度和性能。\n2. **强化学习（Reinforcement Learning）**：\n利用强化学习中的 Q-learning 或者 Actor-Critic 方法来替代 RNN 生成架构决策。",
    "url": "/blog/NAS-RL",
    "chunkIndex": 5,
    "totalChunks": 10,
    "startPos": 1657,
    "endPos": 1984,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-6",
    "title": "NAS-RL (第7段)",
    "content": "...ctor-Critic 方法来替代 RNN 生成架构决策。 3. **进化算法（Evolutionary Algorithms）**：\n使用基因算法（Genetic Algorithm）等进化算法通过变异、交叉等操作生成和优化架构。\n总结\n使用 RNN 作为控制器模型的方式使得 NAS 能够处理复杂的结构生成任务并捕捉到生成过程中序列决策的依赖关系。它的序列处理能力和状态保留特性，使其成为生成神经网络架构的理想选择。当然，随着技术的进步，也出现了其他替代方法，可以根据实际需求选择合适的控制器模型。\n解决评估时间过长？\n在神经网络架构搜索（NAS）中，由于控制器生成的模型数量可能非常庞大，这会导致训练和评估整体耗时漫长。以下几种方法可以有效缓解这个问题：\n1. 使用代理任务",
    "url": "/blog/NAS-RL",
    "chunkIndex": 6,
    "totalChunks": 10,
    "startPos": 1984,
    "endPos": 2295,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-7",
    "title": "NAS-RL (第8段)",
    "content": "...长。以下几种方法可以有效缓解这个问题：\n1. 使用代理任务 **代理任务**是一种缩短每次训练和评估时间的方法，通过对一个简化但相关性强的子任务进行优化，以推测完整任务上的性能。\n**缩小数据集**：对一个更小的数据集进行训练和验证，尽快获得性能的反馈。\n**缩小模型规模**：使用简化的模型（如较少的参数和层）以减少每次训练时间。\n**早停法**：监测模型的验证集性能，在检测到过拟合趋势时立即中止训练。\n2. 并行搜索\n**并行搜索**利用分布式计算资源同时评估多个候选模型的大规模并行能力。例如：\n**分布式计算**：用多个计算节点同时进行训练和评估，充分利用计算资源。\n**多GPU训练**：在多GPU平台上进行并行训练，通过同步或者异步评估减少总体时间。\n3. 基于权重分享的方法\n（迁移学习）",
    "url": "/blog/NAS-RL",
    "chunkIndex": 7,
    "totalChunks": 10,
    "startPos": 2295,
    "endPos": 2618,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-8",
    "title": "NAS-RL (第9段)",
    "content": "...评估减少总体时间。\n3. 基于权重分享的方法\n（迁移学习） **基于权重分享的方法**（例如 One-shot NAS 和NASNet）通过共享部分权重，不需要每个架构分别训练。\n**One-shot模型**：所有候选架构共享一个超大模型中的参数，通过不同路径选择进行训练和评估，只需训练一次。\n**权重继承**：在不同候选架构之间传递和共享权重，无需完全从头开始训练每个模型。\n4. 强化学习和进化算法优化\n利用强化学习和进化算法进一步优化架构生成和选择的效率。\n**强化学习**：优化控制器生成决策的策略，使其更快找到高质量的架构。这可以减小搜索空间，提高搜索效率。\n**进化算法**：通过选择、交叉、变异等操作，确保每代评估的架构具有更高的潜力。\n5. 代理模型（Performance Predictors）",
    "url": "/blog/NAS-RL",
    "chunkIndex": 8,
    "totalChunks": 10,
    "startPos": 2618,
    "endPos": 2947,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/NAS-RL#chunk-9",
    "title": "NAS-RL (第10段)",
    "content": "...代理模型（Performance Predictors） **代理模型**（例如元学习）可以用来预测未训练架构的性能，从而减少实际训练的次数。\n**性能预测器**：训练代理模型，根据当前架构的一些特征快速估计其性能，以替代或减少实际训练。\n**元学习**：基于以前的训练结果，学习更好的模型搜索策略，提高样本效率。\n更先进的“NAS”\nDARTS",
    "url": "/blog/NAS-RL",
    "chunkIndex": 9,
    "totalChunks": 10,
    "startPos": 2947,
    "endPos": 3091,
    "originalTitle": "NAS-RL"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-0",
    "title": "UNet",
    "content": "UNet\nUNet是像素级分类，输出的则是每个像素点的类别，常常用在生物医学图像上，而该任务中图片数据往往较少。(卷积神经网络一般输出的结果是整个图像的类标签。)\nUNet采用全卷积神经网络\n左边网络为特征提取网络：使用conv和pooling\n右边网络为特征融合网络：使用上采样产生的特征图与左侧特征图进行concatenate操作。原因",
    "url": "/blog/UNet 模型",
    "chunkIndex": 0,
    "totalChunks": 10,
    "startPos": 0,
    "endPos": 171,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-1",
    "title": "UNet (第2段)",
    "content": "...生的特征图与左侧特征图进行concatenate操作。原因 1. **特征融合**：U-Net的设计采用了跳过连接（skip connection），将编码阶段（收缩路径）的特征图与解码阶段（扩展路径）对应层级的特征图进行拼接。这种操作的目的是为了融合不同分辨率层级的特征信息，既包括高级语义特征（在解码阶段通过上采样获得的低分辨率、高级别的特征），也包括低级细节特征（在编码阶段直接从输入图像中提取的高分辨率、低级别特征）。\n  2. **细节恢复**：在图像分割中，细节是非常重要的。U-Net的编码阶段会不可避免地丢失一些局部细节信息，因为卷积和池化操作会降低空间分辨率。通过将编码阶段的特征与解码阶段的特征合并，模型能够重新利用这些细节信息，帮助更精确地定位边界和恢复图像的详细结构。",
    "url": "/blog/UNet 模型",
    "chunkIndex": 1,
    "totalChunks": 10,
    "startPos": 171,
    "endPos": 490,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-2",
    "title": "UNet (第3段)",
    "content": "...用这些细节信息，帮助更精确地定位边界和恢复图像的详细结构。 3. **上下文信息**：解码阶段的上采样逐步恢复图像的空间分辨率，但这些上采样的特征可能缺乏必要的上下文信息来正确地分割图像。通过concatenate操作，模型在每次上采样后将之前阶段的特征图引入到当前层级，通过这种方式整合了高层次的上下文信息。\n  4. **改善梯度流**：跳过连接不仅有助于在网络中融合不同层次的特征，还有助于改善梯度在网络中的流动，这对于训练深度网络至关重要。这样的网络设计减少了训练中的梯度消失问题，并有助于网络的更深层次训练。\n  5. **训练稳定性**：通过重新引入编码阶段的特征，可以稳定网络的训练过程，加速收敛，并提高模型对噪声和其他训练不稳定因素的鲁棒性。\n名词解释\n图像高低级别特征",
    "url": "/blog/UNet 模型",
    "chunkIndex": 2,
    "totalChunks": 10,
    "startPos": 490,
    "endPos": 806,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-3",
    "title": "UNet (第4段)",
    "content": "...和其他训练不稳定因素的鲁棒性。\n名词解释\n图像高低级别特征 **低级别的特征**：在网络的较早阶段（也就是靠近输入层）提取的特征被称为\"低级别\"的特征。这些特征通常与原始图像密切相关，捕捉到的是图像中的基础信息，比如边缘、角点、颜色和纹理等。在高分辨率的图像中，这些特征能够提供详细的空间和结构信息。\n**高级别的特征**：在网络的较深阶段（也就是更靠近输出层）提取的特征被称为\"高级别\"的特征。这些特征表达的内容更为抽象，有更高的语义含义，比如识别出整个物体、情感、场景等结构性和语义性强的信息。因为通过多次池化或卷积操作，这些特征的空间维度(分辨率)通常比原始输入要小，但它们能够表示的信息更为全局和高级。",
    "url": "/blog/UNet 模型",
    "chunkIndex": 3,
    "totalChunks": 10,
    "startPos": 806,
    "endPos": 1082,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-4",
    "title": "UNet (第5段)",
    "content": "...)通常比原始输入要小，但它们能够表示的信息更为全局和高级。 举个例子，假设我们使用一个深度学习模型处理图像中的猫。低级别的特征可能会捕捉到猫的边缘、毛发的纹理、眼睛的颜色等信息；而高级别的特征可能已经能够捕捉到整个猫的形状，或者猫的情绪（悠闲、警觉等）。\nDiceLoss\n**Dice Loss** 是一种用于图像分割任务的损失函数，旨在应对正负样本强烈不平衡的场景。让我来详细解释一下。\n**Dice Coefficient**（Dice系数）是Dice Loss的基础。它是一种用于评估两个样本相似性的度量函数，取值范围在0到1之间，值越大表示越相似。Dice Coefficient定义如下：\n  $$ \\text{Dice} = \\frac{2|X \\cap Y|}{|X| + |Y|} $$",
    "url": "/blog/UNet 模型",
    "chunkIndex": 4,
    "totalChunks": 10,
    "startPos": 1082,
    "endPos": 1405,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-5",
    "title": "UNet (第6段)",
    "content": "...ac{2|X \\cap Y|}{|X| + |Y|} $$ 其中，$|X \\cap Y|$表示样本X和Y之间的交集，$|X|$和$|Y|$分别表示X和Y的元素个数。分子乘以2是为了保证分母重复计算后取值范围在[0, 1]之间。\n  dice_loss = 1 - dice_coefficient，所以优化目标是缩小 dice_loss 的值。\n召回率\n**召回率**（Recall）是一种用于评估分类模型性能的指标，特别是在二元或多分类中，常常用于检测模型找到相关实例的能力。在目标检测或信息检索中，召回率也很重要。\n具体来说，召回率定义如下：\n$$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n其中：",
    "url": "/blog/UNet 模型",
    "chunkIndex": 5,
    "totalChunks": 10,
    "startPos": 1405,
    "endPos": 1696,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-6",
    "title": "UNet (第7段)",
    "content": "...} = \\frac{TP}{TP + FN} $$\n其中： **TP**（True Positive，真正例（真阳））：被正确预测的正例，即该数据的真实值为正例，预测值也为正例的情况。\n**FN**（False Negative，假阴性）：被错误预测的反例，即该数据的真实值为正例，但被错误预测成了反例的情况。\n召回率衡量了模型正确识别为正类的实例（真正类）占所有实际正类实例的比例。在某些场景下，召回率比准确率更重要，例如医学诊断中，我们更关心是否漏诊（即FN 阳的被诊断为阴性）。\n问题\n为什么最后 U-Net 的损失是交叉熵跟 dice_loss 组成？\n  在U-Net这样的图像分割模型中，通常将交叉熵损失（Cross-Entropy Loss）和Dice损失（Dice Loss）结合使用，原因主要有以下几点：",
    "url": "/blog/UNet 模型",
    "chunkIndex": 6,
    "totalChunks": 10,
    "startPos": 1696,
    "endPos": 2028,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-7",
    "title": "UNet (第8段)",
    "content": "...e损失（Dice Loss）结合使用，原因主要有以下几点： 1. **类不平衡（Class Imbalance）**：在医学图像分割等任务中，目标区域（感兴趣的区域，如肿瘤）往往比背景（其余部分）要小得多，这导致了类别之间的不平衡，简单的交叉熵损失函数可能会导致模型偏向于多数类。因此，需要一个比单一的交叉熵损失更能够处理类不平衡的损失函数。\n  2. **Dice系数的特性**：Dice系数是一个衡量两个样本间相似度的统计量，它的值介于0到1之间，当值为1时表明预测和真实标签之间完全一致。它在图像分割任务中极其有用，因为它直接量化了预测和真实标签之间的重叠区域。这种度量对于捕获边缘区域尤其重要，正如分割任务中常常遇到的。",
    "url": "/blog/UNet 模型",
    "chunkIndex": 7,
    "totalChunks": 10,
    "startPos": 2028,
    "endPos": 2315,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-8",
    "title": "UNet (第9段)",
    "content": "...种度量对于捕获边缘区域尤其重要，正如分割任务中常常遇到的。 3. **交叉熵和Dice损失结合的优势**：交叉熵损失关注于像素级别上的分类准确性，每个像素点分类的正确与否都会影响到损失。而Dice损失关注预测区域与真实区域的重叠度。这两种损失在目标函数中的结合使得模型可以在整体（全局分割准确性）和局部（特别是小区域或边缘的分割）方面进行优化。\n  4. **梯度行为**：交叉熵损失和Dice损失对梯度的贡献也有所不同。交叉熵对于接近决策边界的样本会产生较大的梯度，这有助于确保学习进程。而Dice损失，则可以在模型对某些类别的预测很自信时，仍然提供一定的梯度，因而有助于学习过程中对不平衡数据的校正。",
    "url": "/blog/UNet 模型",
    "chunkIndex": 8,
    "totalChunks": 10,
    "startPos": 2315,
    "endPos": 2590,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/UNet 模型#chunk-9",
    "title": "UNet (第10段)",
    "content": "...然提供一定的梯度，因而有助于学习过程中对不平衡数据的校正。 5. **性能提升**：实验表明，仅使用交叉熵或Dice损失的模型性能通常不如两者结合使用。通过融合这两种损失函数，模型可以同时从各自的优点中受益。\nUNet 跟 SAM 的区别？\nSAM 模型介绍\nReference\nUNet详解\nUNet image\nmodel source code\ngpt",
    "url": "/blog/UNet 模型",
    "chunkIndex": 9,
    "totalChunks": 10,
    "startPos": 2590,
    "endPos": 2741,
    "originalTitle": "UNet"
  },
  {
    "chunkId": "/blog/VAE#chunk-0",
    "title": "VAE",
    "content": "重参数技巧\nVAE（变分自编码器）的重参数化技巧是一种使得模型能够通过梯度下降来训练的关键技术。要理解这个技巧涉及的关键数学知识，以下是几个重要的方面：\n1. 变分推断（Variational Inference）\n变分推断是一种近似后验分布的方法。它将难以处理的后验分布 $ p(z|x) $ 近似为一个易处理的分布 $ q(z|x) $。在 VAE 中，我们选择 $ q(z|x) $ 为一个高斯分布：\n$ q(z|x) = \\mathcal{N}(z; \\mu(x), \\sigma^2(x)) $\n其中，均值 $ \\mu(x) $ 和方差 $ \\sigma^2(x) $ 都是从输入数据 $ x $ 生成的。\n2. 证据下界（Evidence Lower Bound, ELBO）",
    "url": "/blog/VAE",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 345,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/VAE#chunk-1",
    "title": "VAE (第2段)",
    "content": "...界（Evidence Lower Bound, ELBO） 训练 VAE 的目标是最大化数据的边际对数似然 $ \\log p(x) $。由于直接计算这个对数似然很困难，我们引入了证据下界（ELBO）：\n$ \\log p(x) \\geq \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - D_{KL}(q(z|x) \\parallel p(z)) $\n其中，\n$ \\mathbb{E}_{q(z|x)}[\\log p(x|z)] $ 是重建损失，表示在潜变量 $ z $ 上的重构误差的期望。\n$ D_{KL}(q(z|x) \\parallel p(z)) $ 是 Kullback-Leibler (KL) 散度，表示近似后验分布和先验分布之间的差异。\n3. 重参数化技巧（Reparameterization Trick）",
    "url": "/blog/VAE",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 345,
    "endPos": 688,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/VAE#chunk-2",
    "title": "VAE (第3段)",
    "content": "...化技巧（Reparameterization Trick） 为了能够通过梯度下降法优化 ELBO，我们需要对随机变量 $ z $ 进行梯度计算。直接对 $ z $ 采样会导致梯度无法传播。重参数化技巧通过引入一个独立于参数的噪声变量 $ \\epsilon $ 来解决这个问题。\n假设 $ z $ 是从高斯分布中采样的：\n$ z \\sim \\mathcal{N}(\\mu, \\sigma^2) $\n我们可以将 $ z $ 重参数化为：\n$ z = \\mu + \\sigma \\cdot \\epsilon $\n其中，$ \\epsilon \\sim \\mathcal{N}(0, I) $ 是一个标准正态分布的噪声。通过这种重参数化，$ \\mu $ 和 $ \\sigma $ 的梯度可以通过 $ \\epsilon $ 来传播，从而使得模型可以使用梯度下降法进行训练。",
    "url": "/blog/VAE",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 688,
    "endPos": 1039,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/VAE#chunk-3",
    "title": "VAE (第4段)",
    "content": "...on $ 来传播，从而使得模型可以使用梯度下降法进行训练。 关键数学知识总结\n1. **概率论和统计学**：\n高斯分布及其性质\nKullback-Leibler 散度\n2. **变分推断**：\n近似后验分布的选择和优化\n3. **优化方法**：\n证据下界（ELBO）的推导和优化\n重参数化技巧确保梯度的可传播性\n隐空间连续性和完整性\n在变分自编码器（Variational Autoencoder, VAE）的上下文中，连续性和完整性是两个重要的概念，关系到生成模型的质量和性能。\n连续性（Continuity）",
    "url": "/blog/VAE",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 1039,
    "endPos": 1266,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/VAE#chunk-4",
    "title": "VAE (第5段)",
    "content": "...系到生成模型的质量和性能。\n连续性（Continuity） 连续性指的是在潜在空间（latent space）中，两个相邻的点对应的生成数据在数据空间中也是相似的。这意味着，潜在空间中的小的变化会导致生成的数据空间中的小的变化。换句话说，如果我们在潜在空间中进行连续的插值操作（interpolation），生成的数据也应该表现出平滑的变化。\n完整性（Completeness）\n完整性指的是潜在空间中的每一个点都能够解码为合理的生成样本，即潜在空间中的所有区域都对应于数据空间中的有效数据。这样，我们可以确保通过VAE生成的样本是多样的，覆盖了训练数据的全部分布。\n编码为分布而非点",
    "url": "/blog/VAE",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1266,
    "endPos": 1529,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/VAE#chunk-5",
    "title": "VAE (第6段)",
    "content": "...样本是多样的，覆盖了训练数据的全部分布。\n编码为分布而非点 VAE通过将输入数据编码为高斯分布的参数（均值和方差），而不是一个单一的点，从而引入了随机性和正则化。这个过程涉及到在潜在空间中采样，并且通过KL散度（Kullback-Leibler divergence）正则化，使得编码的分布接近标准正态分布（通常是零均值和单位方差）。\n确保连续性和完整性\n1. **连续性**：由于潜在空间中的点是通过高斯分布采样得到的，这些点的分布是连续的。VAE通过在潜在空间中采样，然后解码为数据空间中的样本，确保了潜在空间的连续性。即使是相邻的潜在空间点，也会解码为相似的数据空间点。",
    "url": "/blog/VAE",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1529,
    "endPos": 1788,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/VAE#chunk-6",
    "title": "VAE (第7段)",
    "content": "...续性。即使是相邻的潜在空间点，也会解码为相似的数据空间点。 2. **完整性**：通过KL散度正则化，VAE鼓励潜在空间的分布接近标准正态分布，这样可以确保潜在空间的每个区域都能生成有效的数据样本。即使潜在空间中的任意点也能解码为合理的数据，从而保证了潜在空间的完整性。\n简而言之，VAE将输入编码为分布（而不是点）通过正则化和采样技术，确保了潜在空间的连续性和完整性，从而使得生成的样本更加多样化且平滑。",
    "url": "/blog/VAE",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1788,
    "endPos": 1961,
    "originalTitle": "VAE"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-0",
    "title": "t-SNE 算法",
    "content": "t-SNE 算法\n一种用于数据可视化的降维技术，特别适用于高维数据的**可视化**。\n通过将高维数据映射到二维或三维空间，t-SNE 可以展示数据的聚类结构和分布情况。通过 SNE 算法（容易拥挤）改进（联合概率分布替换条件概率分布解决分布计算对称问题，并引入 t 分布）。\n原理",
    "url": "/blog/t-SNE",
    "chunkIndex": 0,
    "totalChunks": 11,
    "startPos": 0,
    "endPos": 141,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-1",
    "title": "t-SNE 算法 (第2段)",
    "content": "...件概率分布解决分布计算对称问题，并引入 t 分布）。\n原理 t-SNE算法的目标是将高维数据映射到低维空间（通常是二维或三维），同时尽可能保持数据点之间的相似度。为了实现这一目标，t-SNE构建了两个概率分布：一个是高维空间中的相似度分布P，另一个是低维空间中的相似度分布Q。然后，算法通过最小化这两个分布之间的Kullback-Leibler散度（KL散度）来优化低维嵌入。在低维空间中，t-SNE使用t分布来定义数据点之间的相似度，这有助于解决“拥挤问题”，使得数据点在低维空间中能够更均匀地分布。\nt-SNE 中的 't'",
    "url": "/blog/t-SNE",
    "chunkIndex": 1,
    "totalChunks": 11,
    "startPos": 141,
    "endPos": 376,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-2",
    "title": "t-SNE 算法 (第3段)",
    "content": "...点在低维空间中能够更均匀地分布。\nt-SNE 中的 't' “t”指的是t分布（或称学生t分布、柯西分布）。t-SNE是一种专为高维数据可视化设计的降维技术，其核心原理在于，首先在高维空间中利用高斯分布来定义数据点之间的相似度，而在低维空间中则采用t分布来定义相似度。这两种分布的选择有助于算法在低维空间中保持高维空间的数据结构。\nt 分布的重尾特性使得：\n远距离点之间的排斥力增大\n近距离点之间的吸引力减小\n更容易形成簇\n簇间距离更明显\n自由度\n单样本 t 检验：如果我们用一个样本估计总体均值，样本量为 n，则自由度通常是 n−1。这是因为我们计算样本的均值时用了一个数值，使得只有 n−1 个数据点可以自由变化。",
    "url": "/blog/t-SNE",
    "chunkIndex": 2,
    "totalChunks": 11,
    "startPos": 376,
    "endPos": 656,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-3",
    "title": "t-SNE 算法 (第4段)",
    "content": "...值时用了一个数值，使得只有 n−1 个数据点可以自由变化。 自由度影响统计分布的形状，特别是小样本情况下。例如，在 t 分布中，自由度越小，分布的尾部越厚，因为小样本的估计不确定性更大。随着自由度增加，t 分布逐渐接近正态分布。\n自由度还决定了假设检验的临界值和置信区间的宽度——自由度越小，检验标准会更加严格，置信区间也会变宽。\n正态分布\nX 轴：表示随机变量的取值，反映取值的大小。\nY 轴：表示每个取值的相对概率密度（并非直接的概率）。\n应用\n基因科学\n细胞分类：将单细胞基因表达数据降维，通过 t-SNE 在 2D 或 3D 中展示，使得具有相似基因表达模式的细胞群靠近，可以区分不同细胞类型。\n疾病分群：在基因组数据中，t-SNE 可帮助发现不同患者样本的模式差异，例如将癌症样本聚类在一起，展示亚型或分子特征。",
    "url": "/blog/t-SNE",
    "chunkIndex": 3,
    "totalChunks": 11,
    "startPos": 656,
    "endPos": 988,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-4",
    "title": "t-SNE 算法 (第5段)",
    "content": "...的模式差异，例如将癌症样本聚类在一起，展示亚型或分子特征。 基因特征分析：t-SNE 可以用于探索基因间的相似性或特征模式，帮助识别在特定条件下具有相似表达的基因簇。\ncomputer security：t-SNE 可以用于流量日志分析\n异常检测：在网络流量、登录记录、或文件访问等高维数据中，t-SNE 可以将数据降维，帮助识别异常模式或异常点，从而检测可能的入侵或恶意活动。\n恶意软件分类：将恶意软件样本的特征（如行为特征或静态特征）降维，通过可视化识别相似的恶意软件家族，帮助分析不同种类的威胁。\n用户行为分析：将用户访问数据或活动日志降维，显示正常和异常行为群体，帮助识别潜在的账户接管或欺诈行为。\n自然语言处理",
    "url": "/blog/t-SNE",
    "chunkIndex": 4,
    "totalChunks": 11,
    "startPos": 988,
    "endPos": 1269,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-5",
    "title": "t-SNE 算法 (第6段)",
    "content": "...行为群体，帮助识别潜在的账户接管或欺诈行为。\n自然语言处理 词嵌入可视化：通过 t-SNE 将高维词嵌入（如 Word2Vec 或 BERT 的嵌入）降维为 2D 或 3D，可以直观显示词语之间的相似性和聚类，比如“国王”与“王后”靠近，或“苹果”与“橙子”形成同一类。\n文档聚类：对句子或文档的嵌入进行降维，将主题相似的文档或句子分组，从而帮助发现相似的文本类别（如新闻主题或情感相似度）。\n情感分析：将带有情感标签的句子降维，查看正向、负向情感句子在图中的分布情况，验证模型效果。\nK-means 与 t-SNE 的区别\nK-means 是一种聚类算法，用于将数据点分组为 K 个簇，每个簇的中心是簇内数据点的平均值。\nt-SNE 是一种降维算法，用于将高维数据映射到低维空间，同时保持数据点之间的局部结构。",
    "url": "/blog/t-SNE",
    "chunkIndex": 5,
    "totalChunks": 11,
    "startPos": 1269,
    "endPos": 1596,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-6",
    "title": "t-SNE 算法 (第7段)",
    "content": "...于将高维数据映射到低维空间，同时保持数据点之间的局部结构。 t-SNE 更倾向于可视化数据之间的相似性，而 K-means 更倾向于数据之间的聚类。\n疑问\n为什么说线性降维更好的保留了全局结构，而非线性降维更好的保留了局部结构？\n>线性降维（如 PCA）保留全局结构，因为它基于数据的主成分，将整个数据集的方差最大化，以保持所有数据点的整体关系。在这种方法中，高维空间中的全局方向和差异在低维空间中得到最大保留。\n非线性降维（如 t-SNE）更注重保留局部结构。它侧重于保持相似数据点之间的局部关系，而不在意全局距离。这样可以在低维空间中更清晰地显示数据的局部聚集模式，适合复杂、非线性分布的数据可视化。\n形似性跟聚类的区别？\n不同目标",
    "url": "/blog/t-SNE",
    "chunkIndex": 6,
    "totalChunks": 11,
    "startPos": 1596,
    "endPos": 1885,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-7",
    "title": "t-SNE 算法 (第8段)",
    "content": "...、非线性分布的数据可视化。\n形似性跟聚类的区别？\n不同目标 * t-SNE：主要用于可视化数据的相似性，通过降维将数据点的相似关系展示在二维或三维空间中。它并不定义“组”，而是让相似的数据点在空间中靠近，适合查看**数据的分布形态**。 \n* K-means：是一种聚类算法，直接将数据分成多个聚类组。它的目标是最小化组内的差异，而不是追求可视化的相似性关系。\n因此，t-SNE 强调“展示相似性”，K-means 强调“形成类别”。\nt-SNE 跟 PCA 的区别\nPCA 是一种线性降维算法，通过线性变换将数据映射到低维空间，同时保留数据的主要特征。\nt-SNE 是一种非线性降维算法，通过计算数据点之间的相似度，将数据点映射到低维空间，并保持数据点之间的局部结构。",
    "url": "/blog/t-SNE",
    "chunkIndex": 7,
    "totalChunks": 11,
    "startPos": 1885,
    "endPos": 2191,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-8",
    "title": "t-SNE 算法 (第9段)",
    "content": "...似度，将数据点映射到低维空间，并保持数据点之间的局部结构。 因此，t-SNE 可以更好地保留数据的局部结构，而 PCA 则更倾向于保留数据的全局结构。\n疑问\n线性跟非线性降维区别？\n线性降维：假设数据在高维空间中呈现直线或平面分布，通过找到数据的主成分（如 PCA）将数据投影到更低维的空间。它适用于线性分布的数据，能够保留整体结构。\n非线性降维：假设数据位于弯曲的流形上，数据可能具有复杂的局部结构。方法如 t-SNE 和 Isomap 会保留数据的局部相似性，适合处理复杂、非线性关系的数据，更适合可视化和聚类。\nt-SNE 与 VAE\n隐空间都是基于流形空间建模\n不同点",
    "url": "/blog/t-SNE",
    "chunkIndex": 8,
    "totalChunks": 11,
    "startPos": 2191,
    "endPos": 2450,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-9",
    "title": "t-SNE 算法 (第10段)",
    "content": "...t-SNE 与 VAE\n隐空间都是基于流形空间建模\n不同点 VAE 的隐空间：通常具有一定的连续性和结构化性质。例如，VAE 的隐空间可以连续变化（KL 散度用于正则化隐空间的分布，使得隐空间的分布尽可能接近一个标准正态分布（通常是高斯分布）。正则化的目的是使隐空间连续且平滑），解码器可以将隐空间中相邻的点映射成相似的数据。对隐空间进行插值可以生成新的样本。\nt-SNE 的映射空间：因为 t-SNE 注重局部结构，其结果比较**离散**，且映射空间中的距离和高维空间中的距离不具有线性对应关系，因此无法用来生成数据。t-SNE 的低维空间只在视觉上保留局部关系，而无法生成数据或保持样本连续性。\n流形空间\n特征\n数据的非线性结构\n流形更适合保留局部结构\n应用 - 生成模型",
    "url": "/blog/t-SNE",
    "chunkIndex": 9,
    "totalChunks": 11,
    "startPos": 2450,
    "endPos": 2759,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/t-SNE#chunk-10",
    "title": "t-SNE 算法 (第11段)",
    "content": "...据的非线性结构\n流形更适合保留局部结构\n应用 - 生成模型 隐空间的流形结构能够在生成过程中保持样本的平滑性和连贯性，从而生成自然的样本。（VAE，GAN）\n如果隐空间是流形而不是简单的平面空间，则模型可以在隐空间中“移动”来生成具有渐变特征的样本。例如，生成不同姿态的图像或生成具有不同风格的文本。\n参考\n解释的很清晰 t-SNE 算法详解\n包含 code 演示 t-SNE 实践\ngpt",
    "url": "/blog/t-SNE",
    "chunkIndex": 10,
    "totalChunks": 11,
    "startPos": 2759,
    "endPos": 2924,
    "originalTitle": "t-SNE 算法"
  },
  {
    "chunkId": "/blog/the bitter lesson#chunk-0",
    "title": "《The Bitter Lesson》",
    "content": "《The Bitter Lesson》 \n\"The Bitter Lesson\"是一篇由计算机科学家理查德·萨顿（Richard Sutton）撰写的论文。它提出了一个重要的观点，即在人工智能和机器学习的发展过程中，最重要的教训是利用计算资源和数据量的增长。\n文章的几个观念\n传统的人工智能方法受限：在过去的几十年中，人们在构建人工智能系统中主要依赖于手动设计的规则和特定的专家知识。然而，这种方法面临着挑战，因为设计和实现这些规则往往非常复杂，且需要大量的专业领域知识。\n利用计算资源和数据量的增长优势：随着计算资源和数据量的增长，我们可以采用更简单且更通用的方法来构建人工智能系统。这种方法通过大规模的数据和计算能力来训练机器学习模型，使其根据数据自动地学习规律和特征。",
    "url": "/blog/the bitter lesson",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 338,
    "originalTitle": "《The Bitter Lesson》"
  },
  {
    "chunkId": "/blog/the bitter lesson#chunk-1",
    "title": "《The Bitter Lesson》 (第2段)",
    "content": "...能力来训练机器学习模型，使其根据数据自动地学习规律和特征。 从神经网络的再兴中得出教训：神经网络的成功复兴是一种不同的方法论，它充分利用了计算资源和数据量的增长。通过使用更大和更深的神经网络，以及大规模训练数据，神经网络能够实现各种复杂的任务，包括图像识别、自然语言处理等。\n简单通用的方法更具优势：在发展人工智能和机器学习方法时，应该倾向于更简单而通用的方法。这些方法具有更好的扩展性和适应性，可以从更少的先验知识和人工规则中进行学习，使系统能够在更广泛的任务和环境中表现出色。\n总的来说，\"The Bitter Lesson\"表达了一种重要的观点，即在人工智能和机器学习领域中，随着计算资源和数据量的增长，通过利用更简单且更通用的方法，让机器从数据中自动学习更多的规律和特征，可能会比依赖于手动设计的复杂规则更具优势。\n几个例子论证",
    "url": "/blog/the bitter lesson",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 338,
    "endPos": 677,
    "originalTitle": "《The Bitter Lesson》"
  },
  {
    "chunkId": "/blog/the bitter lesson#chunk-2",
    "title": "《The Bitter Lesson》 (第3段)",
    "content": "...，可能会比依赖于手动设计的复杂规则更具优势。\n几个例子论证 象棋和围棋：这两种棋类游戏都是人工智能研究的经典领域，也是大规模计算的一般方法取得突破性进展的领域。例如，AlphaGo 和 AlphaZero 都是基于深度神经网络和强化学习的系统，它们可以通过自我对弈来提高自己的水平，而**不需要人类的先验知识**。这些系统在与人类顶尖棋手的对决中，展示了超越人类的水平。\n图像识别：这是人工智能研究的另一个重要领域，也是大规模计算的一般方法取得显著进步的领域。例如，Midjourney V5 是一种能够根据文本描述生成高质量图像的系统，它是基于深度生成对抗网络 (GAN) 的技术，它可以从大量的图像数据中学习图像的特征和分布，而**不需要人类的领域知识**。这种系统在图像创作和图像编辑等任务中，展示了惊人的创造力和灵活性。",
    "url": "/blog/the bitter lesson",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 677,
    "endPos": 1012,
    "originalTitle": "《The Bitter Lesson》"
  },
  {
    "chunkId": "/blog/the bitter lesson#chunk-3",
    "title": "《The Bitter Lesson》 (第4段)",
    "content": "...在图像创作和图像编辑等任务中，展示了惊人的创造力和灵活性。 SAM 模型比 UNet 更加通用，SAM 采用了一种提示型的训练方法（UNet 是监督学习），通过提示来生成分割掩码，使其具有**更强大的零样本泛化能力**。\nChatGPT：这是一种基于 GPT-4 的语言模型，它可以根据上下文理解和生成类似人类的文本，它也是基于大规模计算的一般方法的一个例子，它可以从海量的文本数据中学习语言的规律和知识，而**不需要人类的规则或语法**。这种系统在对话、写作、翻译等任务中，展示了流畅的语言能力和广泛的知识面。\n通用性的局限性\n**忽略了问题的特殊性和复杂性**，导致无法找到最优的或最合适的解决方案。例如，一些通用的机器学习算法可能无法适应一些特定的数据分布或任务需求，需要进行定制化的改进或设计。",
    "url": "/blog/the bitter lesson",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 1012,
    "endPos": 1334,
    "originalTitle": "《The Bitter Lesson》"
  },
  {
    "chunkId": "/blog/the bitter lesson#chunk-4",
    "title": "《The Bitter Lesson》 (第5段)",
    "content": "...一些特定的数据分布或任务需求，需要进行定制化的改进或设计。 例子：使用通用的神经网络来识别手写数字时，可能会遇到一些噪声、模糊或变形的数字，这些数字可能与训练数据集中的数字有很大的差异，导致识别的准确率下降。\n**需要大量的计算资源和数据**，导致效率低下或成本高昂。例如，一些通用的深度学习模型可能需要数百万甚至数十亿的参数，需要大规模的硬件设备和数据集来训练和部署。\n**安全性或可靠性的风险**，导致不可预测的或不可控制的后果。例如，一些通用的人工智能系统可能会受到对抗攻击或数据污染的影响，导致输出错误的或有害的结果 。\n原文\nthe bitter lesson",
    "url": "/blog/the bitter lesson",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1334,
    "endPos": 1589,
    "originalTitle": "《The Bitter Lesson》"
  },
  {
    "chunkId": "/blog/一个无监督学习的理论#chunk-0",
    "title": "Reference",
    "content": "早在 2023 年 10 月 3 日，Ilya 曾在伯克利大学做过一次演讲，题为《一个无监督学习的理论》（A Theory of Unsupervised Learning）。由于内容艰涩，知晓者寥寥，而它却是人工智能史上最重要的时刻之一，注定将载入史册。「安全智能」的背后，Ilya 究竟看到了什么？\n观点\n监督学习：低训练误差+大训练集，就能确保模型的泛化能力\n**Hoeffding 不等式**，其主要含义是：当训练误差足够低，且训练样本数远大于「模型自由度」（可以理解为模型的规模）时，测试误差也能保证足够低；\n宏观上和理论上，**万能近似定理**（Universal Approaximation Theorem）早已论证了深层神经网络可以逼近任意函数。",
    "url": "/blog/一个无监督学习的理论",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 333,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/一个无监督学习的理论#chunk-1",
    "title": "Reference (第2段)",
    "content": "...Theorem）早已论证了深层神经网络可以逼近任意函数。 模型规模一定要小于数据规模，否则，它根本就不用做真正的「压缩」或抽象，不去找规律，它就全部死记硬背了。我们知道死记硬背的模型，没有泛化能力。\n无监督学习的本质是分布匹配，是一种规律性的模式匹配\n只要两种语言原生数据足够丰富，一种语言的输入作为条件就能几乎唯一地确定另一种语言的翻译等价物，就是所谓「压缩」理论\n无监督学习其实就是在寻找最优的数据压缩方法\n一个好的无监督学习算法，应该能找到数据的最简洁表示（即 **K 氏复杂度**），同时又能最大限度地利用这种表示来完成下游任务\n从条件建模到联合建模",
    "url": "/blog/一个无监督学习的理论",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 333,
    "endPos": 584,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/一个无监督学习的理论#chunk-2",
    "title": "Reference (第3段)",
    "content": "...最大限度地利用这种表示来完成下游任务\n从条件建模到联合建模 与其像监督学习那样将 X 和 Y 视为条件与结果，不如将它们视为一个整体，在一个巨大的模型里面一起进行压缩。也就是说，我们要寻找一个联合的 **K 氏复杂度 K(X,Y)**，即同时压缩 X 和 Y 的最短程序长度，这就是我们的无监督学习出来的预训练大模型（LLM）。\n无监督学习的新范式，它将传统的独立建模（如英语模型、汉语模型；再如，语言模型、视觉模型，等等）提升到了大一统的关联建模的高度。在这个范式下，无监督学习的目标不再是单纯地压缩单一群体的数据，而是寻找数据之间的联系。\n压缩的对象是数据集，而不是数据点，这一点非常重要，这其实是形式压缩与内容压缩的分水岭。*形式压缩只是一个机械过程，产生不了智能。只有内容压缩才能成就人工智能。*",
    "url": "/blog/一个无监督学习的理论",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 584,
    "endPos": 907,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/一个无监督学习的理论#chunk-3",
    "title": "Reference (第4段)",
    "content": "...个机械过程，产生不了智能。只有内容压缩才能成就人工智能。* 个体对象转变为群体对象的时候，形式的压缩就自然转化为内容的压缩。这是因为*群体虽然是个体组成的，但为群体压缩，如同是为群体「画像」，勾勒的是群体的统计性形象，它看上去可能是个个体，但它不是原数据中的任何一个特定的个体复制，否则就不是模型，而是记忆库了。*\n大模型压缩的本意就是要找出数据集的特征和规律性。大模型 GPT4 生成的文字，我们可能似曾相读；大模型 Suno 生成的音乐，我们可能似曾相闻；大模型 Sora 生成的视频，我们可能似曾相见；大模型 MJ 生成的图片，我们可能似曾相识。\n这种跨模式、跨模态的学习，才是通用人工智能的高级形态。\nReference\n「安全智能」的背后，Ilya 究竟看到了什么？\nSITUATIONAL AWARENESS: The Decade Ahead",
    "url": "/blog/一个无监督学习的理论",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 907,
    "endPos": 1255,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-0",
    "title": "原始分布（比如均匀分布）",
    "content": "理论\n中心极限定理（Central Limit Theorem, CLT）是概率论和统计学中的一个重要定理。它描述了当独立随机变量的数量足够大时，这些变量的平均值的分布趋向于正态分布的性质。具体来说，中心极限定理指出：\n如果 $ X_1, X_2, \\ldots, X_n $ 是一组独立同分布的随机变量，每个随机变量的期望值为 $ \\mu $，方差为 $ \\sigma^2 $，那么当 $ n $ 趋于无穷大时，这组随机变量的标准化和的分布将趋近于标准正态分布，即均值为 0，方差为 1 的正态分布。\n用公式表示为：\n$frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{d} \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n}) $",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 0,
    "totalChunks": 10,
    "startPos": 0,
    "endPos": 346,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-1",
    "title": "原始分布（比如均匀分布） (第2段)",
    "content": "...N}(\\mu, \\frac{\\sigma^2}{n}) $ 当 $ n $ 足够大时，中心极限定理可以简化为：\n$frac{\\sum_{i=1}^{n} (X_i - \\mu)}{\\sigma\\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0, 1) $\n这里，符号 $ \\xrightarrow{d} $ 表示趋向于分布。\n中心极限定理的意义\n1. **普遍适用性**：中心极限定理适用于许多类型的独立同分布随机变量，不论这些变量的原始分布是什么。当样本量足够大时，它们的平均值分布总是会接近正态分布。\n2. **统计推断基础**：中心极限定理是许多统计推断方法的基础，例如置信区间和假设检验。由于样本均值的分布趋向于正态分布，我们可以使用正态分布的性质来进行统计分析和推断。",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 1,
    "totalChunks": 10,
    "startPos": 346,
    "endPos": 670,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-2",
    "title": "原始分布（比如均匀分布） (第3段)",
    "content": "...正态分布，我们可以使用正态分布的性质来进行统计分析和推断。 3. **实用性**：在实际应用中，中心极限定理帮助我们理解为什么许多自然现象和测量数据呈现正态分布。例如，人的身高、考试成绩和测量误差等都可以用正态分布来近似描述。\n形象例子\n假设我们有一个袋子，里面有很多个硬币。每个硬币掷一次的结果都是独立的，且都是公平的（每个硬币掷出正面或反面的概率都是 0.5）。我们不断掷硬币，并记录每次掷出正面的次数。尽管每次单独掷出的结果（正面或反面）不一定是正态分布的，但如果我们掷很多次，并计算总的正面次数的均值，这个均值会趋向于正态分布。\n实际应用\n中心极限定理（Central Limit Theorem, CLT）在统计学和各种实际应用中起着重要作用。以下是几个实际应用场景：\n1. 质量控制",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 2,
    "totalChunks": 10,
    "startPos": 670,
    "endPos": 988,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-3",
    "title": "原始分布（比如均匀分布） (第4段)",
    "content": "...用中起着重要作用。以下是几个实际应用场景：\n1. 质量控制 在制造业中，质量控制是一个重要的环节。假设我们在生产线上制造螺栓，并且每个螺栓的长度是一个随机变量。虽然每个单独螺栓的长度可能不遵循正态分布，但通过测量大量螺栓的长度并计算其平均值，我们可以假设这些平均值将趋近于正态分布。\n应用示例：\n**计算均值和标准差**：假设每小时我们测量 100 个螺栓的长度，并记录每小时的平均长度。根据中心极限定理，这些平均长度的分布将接近于正态分布。\n**设定控制图**：利用正态分布的性质，我们可以设定上下控制限来监控生产过程。如果某一小时的平均长度落在**控制限**之外，则表示生产过程中可能存在问题，需要检查和调整。\n2. 假设检验\n假设检验是统计学中用于判断一个样本是否来自某个特定分布的重要工具。中心极限定理为假设检验提供了理论基础。\n应用示例：",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 3,
    "totalChunks": 10,
    "startPos": 988,
    "endPos": 1333,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-4",
    "title": "原始分布（比如均匀分布） (第5段)",
    "content": "...要工具。中心极限定理为假设检验提供了理论基础。\n应用示例： **样本均值的检验**：假设我们要检验某种药物对血压的影响。我们从总体中抽取一个样本，并计算样本的平均血压。如果样本量足够大，根据中心极限定理，样本均值的分布将接近正态分布。\n**计算 p 值**：利用正态分布的性质，我们可以计算样本均值与总体均值之间的差异的 p 值，以确定该差异是否具有统计显著性。\n3. 金融分析\n在金融领域，许多投资回报率的分布可以通过中心极限定理来近似描述。尽管单个股票的日收益率可能不遵循正态分布，但大量股票的平均收益率可以近似为正态分布。\n应用示例：\n**投资组合分析**：假设一个投资组合包含大量股票。根据中心极限定理，这些股票的平均日收益率将接近正态分布。这使得我们可以使用正态分布的性质来分析投资组合的风险和收益。",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 4,
    "totalChunks": 10,
    "startPos": 1333,
    "endPos": 1659,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-5",
    "title": "原始分布（比如均匀分布） (第6段)",
    "content": "...使得我们可以使用正态分布的性质来分析投资组合的风险和收益。 **VaR（在险价值）计算**：利用正态分布的性质，我们可以计算投资组合在一定置信水平下的最大可能损失，即 VaR。\n4. 民意调查\n民意调查是统计学中常见的应用，通常用于了解公众对某个问题的态度或意见。尽管单个受访者的回答可能不遵循正态分布，但大量受访者的平均回答将接近正态分布。\n应用示例：\n**估计总体比例**：假设我们想知道某个城市中有多少人支持某个政策。我们可以抽取一个样本进行调查，并计算样本中支持该政策的比例。根据中心极限定理，这个样本比例的分布将接近正态分布。\n**设定置信区间**：利用正态分布的性质，我们可以为样本比例设定置信区间，从而估计总体中支持该政策的比例。\n定理证明\n中心极限定理的简单证明\n思路",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 5,
    "totalChunks": 10,
    "startPos": 1659,
    "endPos": 1972,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-6",
    "title": "原始分布（比如均匀分布） (第7段)",
    "content": "...支持该政策的比例。\n定理证明\n中心极限定理的简单证明\n思路 我们要证明的是，对于一组独立同分布的随机变量，当样本大小 $n$ 足够大时，样本均值 $\\bar{X}$ 的分布可以近似为正态分布。\n假设我们有 $n$ 个独立同分布的随机变量 $X_1, X_2, \\ldots, X_n$，每个随机变量的期望 $\\mathbb{E}[X_i] = \\mu$ 和方差 $\\text{Var}(X_i) = \\sigma^2$。\n首先，我们定义标准化的样本均值（标准化是为了使得均值为 0 ，方差为 1）：\n$ Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\frac{1}{n} \\sum_{i=1}^n X_i - \\mu}{\\sigma / \\sqrt{n}} $",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 6,
    "totalChunks": 10,
    "startPos": 1972,
    "endPos": 2303,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-7",
    "title": "原始分布（比如均匀分布） (第8段)",
    "content": "...i - \\mu}{\\sigma / \\sqrt{n}} $ 我们的目标是证明 $Z$ 服从标准正态分布 $N(0, 1)$ 当 $n$ 充分大时。\n证明步骤\n1. **构建标准化随机变量**:\n   定义 $Z_n$ 为：\n   $ Z_n = \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n \\frac{X_i - \\mu}{\\sigma} = \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n \\frac{X_i - \\mu}{\\sigma} $\n   其中，每一个 $\\frac{X_i - \\mu}{\\sigma}$ 都是独立同分布的标准化随机变量，期望为 0，方差为 1。\n2. **应用莫夫•格里亚版大数定理**:",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 7,
    "totalChunks": 10,
    "startPos": 2303,
    "endPos": 2602,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-8",
    "title": "原始分布（比如均匀分布） (第9段)",
    "content": "...，方差为 1。\n2. **应用莫夫•格里亚版大数定理**: 由于 $\\frac{X_i - \\mu}{\\sigma}$ 是独立同分布的，期望为 0 方差为 1 的随机变量，根据**狄莫佛-拉普拉斯极限定理**（这是中心极限定理的原型之一）：\n   当 $n$ 足够大时，$\\frac{1}{\\sqrt{n}} \\sum_{i=1}^n \\frac{X_i - \\mu}{\\sigma}$ 会趋近于标准正态分布 $N(0,1)$。\n3. **结合两步**:\n   因此， $Z_n = \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n \\frac{X_i - \\mu}{\\sigma}$ 逼近 $N(0,1)$。\n4. **回到原问题**:\n   回溯到我们实际要证明的 $Z$ ：",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 8,
    "totalChunks": 10,
    "startPos": 2602,
    "endPos": 2923,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/中心极限定理（CLT）#chunk-9",
    "title": "原始分布（比如均匀分布） (第10段)",
    "content": "...回到原问题**:\n   回溯到我们实际要证明的 $Z$ ： $ Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} $\n   根据上述结果，$Z_n \\approx N(0, 1)$，所以 $Z$ 也趋近于标准正态分布 $N(0, 1)$。\n更直观的理解\n一种更直观的理解方法是通过模拟来观察样本均值分布的行为：\n通过上述模拟，你会看到样本均值的分布逐渐接近正态分布。\n总结\n中心极限定理的简化证明依赖于一个关键思想：通过标准化操作把一组独立同分布的随机变量和它们的均值转换成一个标准正态分布。这是通过数学推导和极限理论来证明的，但直观上可以通过大量样本均值的分布来观察和确认。这种定理在统计推断和应用中具有广泛的重要性，因为它为我们提供了从样本推断总体性质的有力工具。",
    "url": "/blog/中心极限定理（CLT）",
    "chunkIndex": 9,
    "totalChunks": 10,
    "startPos": 2923,
    "endPos": 3249,
    "originalTitle": "原始分布（比如均匀分布）"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-0",
    "title": "卷积与全连接网络",
    "content": "卷积与全连接网络\n卷积核（有参数）：扩充通道数目，提取特征；例如：输入 3维，期望输出 9维，则卷积核需要 9 个，并且每个维度为 k*k*3(对应输入维度)\n池化层（无参数）：用于二维，降低空间维度（不改变通道数），并不参与特征提取；例如 2x2 池化窗口，则能将每个通道降维到 w/2 x h/2\n为什么有了全连接却又诞生了卷积\n参数共享：\n卷积网络通过卷积操作利用参数共享的机制，这意味着在处理图像时，同一个卷积核（滤波器）会应用在整个图像上。这种方法大大减少了模型的参数数量，使得卷积网络在处理图像等高维数据时更加高效。\n局部连接：",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 0,
    "totalChunks": 11,
    "startPos": 0,
    "endPos": 271,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-1",
    "title": "卷积与全连接网络 (第2段)",
    "content": "...，使得卷积网络在处理图像等高维数据时更加高效。\n局部连接： 卷积层的神经元仅与输入数据的一个局部区域相连接，这与全连接层的每个神经元连接到输入数据的所有元素形成鲜明对比。局部连接使得卷积网络能够捕捉到输入数据中的局部特征，这在图像识别等任务中非常有用。\n空间层次结构：\nCNNs 通过多个卷积层和池化层（pooling layers）的堆叠，能够自然地学习输入数据的空间层次结构。在这种架构中，底层卷积层可能专注于学习边缘或纹理等低级特征，而高层卷积层则能够组合这些低级特征来识别更复杂的模式。\n减少过拟合：\n由于卷积网络通常有更少的参数和内置的正则化效果（如参数共享和池化），它们在处理复杂图像任务时比全连接网络更不容易过拟合。\n适用于图像数据：",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 1,
    "totalChunks": 11,
    "startPos": 271,
    "endPos": 566,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-2",
    "title": "卷积与全连接网络 (第3段)",
    "content": "...杂图像任务时比全连接网络更不容易过拟合。\n适用于图像数据： 图像数据具有很强的空间结构特征，卷积网络能够有效地利用这一点。在图像数据中，相邻的像素通常相关性较高，而远离的像素相关性较低。卷积网络通过卷积层直接对这种空间结构进行建模，而全连接网络则没有这种直接的建模能力。\n平移不变性：\n卷积网络具有一定程度的平移不变性，这意味着即使图像中的对象发生了平移，卷积网络仍然能够识别出来。这是因为同一个卷积核在整个图像上滑动，学习到的特征对于图像中的不同位置是一致的。\n总结来说，虽然全连接网络在某些任务中表现良好，特别是输入数据的维度较低或者没有明显的空间结构时，但在处理图像这样的高维空间数据时，卷积网络由于其结构上的优势，通常能够提供更好的性能。\n卷积比全连接能减少过拟合原因\n参数越少，越不容易过拟合\n卷积的参数共享使得训练模型参数更少",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 2,
    "totalChunks": 11,
    "startPos": 566,
    "endPos": 906,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-3",
    "title": "卷积与全连接网络 (第4段)",
    "content": "...数越少，越不容易过拟合\n卷积的参数共享使得训练模型参数更少 卷积下采样（池化），减少了特征图的尺寸，有助于降低模型复杂度\n越抽象，越不容易过拟合：卷积空间局部性使得识别训练过程更加抽象\n想象一下，你在做一个拼图游戏。全连接网络就像是你没有任何线索，只能靠猜来拼接每一块拼图。而卷积网络则像是给了你一些提示：哪些拼图块可能属于天空、哪些可能是树木等等。\n在全连接网络中，每个输入信息点都要与每个输出点相连，这就像是拼图中的每一块都要试着与其他所有块相匹配来找到正确位置，这不仅耗时而且容易出错。如果你只有少量的拼图块（也就是数据），你可能会发现一些看似合适的匹配方式，但实际上它们并不是正确的大图景的一部分。这就是过拟合，即你的网络太过于适应你手头上的这些数据，而无法泛化到新的数据上。",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 3,
    "totalChunks": 11,
    "startPos": 906,
    "endPos": 1219,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-4",
    "title": "卷积与全连接网络 (第5段)",
    "content": "...网络太过于适应你手头上的这些数据，而无法泛化到新的数据上。 卷积网络通过关注局部特征来减少这种风险。它就像是在告诉你：“不用看所有的拼图块，只看这一小块就好。”比如说，它可能只关注一块小区域内的拼图，这样就减少了错误匹配的机会。由于它只需要学习局部特征而不是整个图像的复杂模式，所以它需要的线索（也就是参数）就少得多。\n简而言之，卷积网络通过专注于图片中的小部分（局部特征）并在整个图片中重复使用这些信息，减少了需要学习的内容量，从而减少了过拟合的风险。这就像是利用同样的线索来解决拼图的不同部分，而不是每个部分都重新来过。\n卷积的参数共享\n想象一下你用一个橡皮图章在一张纸上盖印。无论你在纸上的哪个位置盖印，图章的图案都是相同的。这就是参数共享的基本概念。",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 4,
    "totalChunks": 11,
    "startPos": 1219,
    "endPos": 1519,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-5",
    "title": "卷积与全连接网络 (第6段)",
    "content": "...位置盖印，图章的图案都是相同的。这就是参数共享的基本概念。 在卷积神经网络中，一个“橡皮图章”就是一个卷积核（或者叫滤波器）。这个卷积核包含了一些参数，它在输入数据（比如一张图片）上移动，每次移动都会应用相同的参数来检测特定的特征，比如边缘或者角落。这样，不管这些特征出现在图片的哪个位置，卷积核都能用相同的方式来识别它们。\n如果不使用参数共享，那么每个位置的特征都需要一个独立的“图章”，这会导致需要很多很多的图章（参数）。但有了参数共享，你只需要一个图章就可以检测整张图片的相同特征，这大大减少了所需的参数数量。\n*PS: 卷积的参数量级: C_in * C_out * Kernel_size（卷积核） * Kernel_size + C_out（偏置）*\n卷积跟全连接网络的结合",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 5,
    "totalChunks": 11,
    "startPos": 1519,
    "endPos": 1833,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-6",
    "title": "卷积与全连接网络 (第7段)",
    "content": "...size + C_out（偏置）*\n卷积跟全连接网络的结合 图像分类：图像分类是指将输入的图像分配到预定义的类别中，如猫、狗、飞机等。图像分类的常用模型是卷积神经网络（CNN），它由多个卷积层、池化层和全连接层组成。卷积层和池化层负责提取图像的局部特征，而全连接层负责将这些特征整合成最终的分类结果\nVIT 是什么\nVIT - Google推出了VIT（Vision Transformer）：一个和Bert几乎一致，同时不添加任何卷积结构的图像分类模型。VIT在Transformer上的成功，证明了可以用统一的模型，来处理不同领域（语言/图像/视频）的任务，进而开启了多模态模型研究的新篇章。\nVIT vs CNN\nVIT 彻底赢了 CNN 么：\ntransformer全局感受野，在大图片或者说找东西时效果好（类似近视眼，能够感受图像大轮廓）。",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 6,
    "totalChunks": 11,
    "startPos": 1833,
    "endPos": 2179,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-7",
    "title": "卷积与全连接网络 (第8段)",
    "content": "...片或者说找东西时效果好（类似近视眼，能够感受图像大轮廓）。 注意力机制的缺点：抓重点信息，忽略不重要的信息，数据少的时候，注意力机制效果不如bilstm，bilstm序列短（比如验证码的长度？）的时候效果也比注意力机制好\ncnn局部感受野，对细节处理较好（理解像素级别的问题，例如 医疗影像）。\n几个疑问\n1. 如何理解 self-attention（transformer）更像low-pass filter，而conv（CNN）反而更高频一点？\nself-attention机制通过计算输入序列中每个元素之间的相似度，来建立全局的依赖关系。这样，self-attention可以有效地捕捉图像或视频中的全局信息，但也会导致特征图变得过于平滑，丢失一些细节信息。因此，self-attention可以看作是一个低通滤波器，它只保留低频信息，而过滤掉高频信息。",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 7,
    "totalChunks": 11,
    "startPos": 2179,
    "endPos": 2530,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-8",
    "title": "卷积与全连接网络 (第9段)",
    "content": "...看作是一个低通滤波器，它只保留低频信息，而过滤掉高频信息。 卷积操作则是通过在图像或视频上滑动一个小的窗口，来提取局部的特征。这样，卷积可以有效地捕捉图像或视频中的细节、纹理、边缘等高频信息，但也会忽略一些全局的信息\n2. 如何从数学上对比两个神经网络的相似度？\n通过对神经网络进行特征向量编码进行相似度对比？特征向量如何反映神经网络对输入数据的变换和抽象？",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 8,
    "totalChunks": 11,
    "startPos": 2530,
    "endPos": 2680,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-9",
    "title": "卷积与全连接网络 (第10段)",
    "content": "...似度对比？特征向量如何反映神经网络对输入数据的变换和抽象？ 通过定义 CKA (Centered Kernel Alignment) 指标比较不同网络结构中的特征相似度：当在不同模型架构的层对之间绘制CKA相似度矩阵时，可以观察到ViT具有相对均匀的层相似度结构。相比之下，ResNet 模型在相似性结构上显示出明显的层级差异，较低层和较高层之间的相似度分数较小。这些结果说明，ViT 在整个模型中具有高度相似的表征，而 ResNet 模型在较低层和较高层之间的表征相似性要低得多。\n其他概念",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 9,
    "totalChunks": 11,
    "startPos": 2680,
    "endPos": 2897,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/卷积与全连接网络#chunk-10",
    "title": "卷积与全连接网络 (第11段)",
    "content": "...模型在较低层和较高层之间的表征相似性要低得多。\n其他概念 卷积层与卷积核：一个包含 64 个 3x3 的卷积核的卷积层（卷积核作用于 3 个 in_channels，然后叠加成为 out_channel）：self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\nReference\nGPT4\nhttps://easyai.tech/ai-definition/cnn/",
    "url": "/blog/卷积与全连接网络",
    "chunkIndex": 10,
    "totalChunks": 11,
    "startPos": 2897,
    "endPos": 3105,
    "originalTitle": "卷积与全连接网络"
  },
  {
    "chunkId": "/blog/基本的矩阵运算#chunk-0",
    "title": "旋转矩阵的证明",
    "content": "旋转矩阵的证明\n为什么向量旋转可以使用旋转矩阵来表示。\n证明：\n让我们考虑一个点P，坐标为 (x, y)。我们希望将点P绕原点逆时针旋转θ角，计算旋转后的坐标 (x', y')。\n在旋转之前，点P的位置可以用极坐标表示为：\n其中 r 是点P到原点的距离（即向量的长度），α 是从x轴到向量[ x, y ]的角度。\n当我们把点P逆时针旋转θ角度后，向量的长度不变，但角度变为 α + θ。所以，旋转后点的新坐标 (x', y') 用极坐标表示是：\n使用三角恒等式，cos(α + θ) 和 sin(α + θ) 可以表示为：\n因此我们可以将坐标写为：\n由于 x = r cosα 和 y = r sinα，代入上面的等式中，我们得到：\n现在，我们将这个变换表示为矩阵形式：",
    "url": "/blog/基本的矩阵运算",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 336,
    "originalTitle": "旋转矩阵的证明"
  },
  {
    "chunkId": "/blog/基本的矩阵运算#chunk-1",
    "title": "旋转矩阵的证明 (第2段)",
    "content": "...的等式中，我们得到：\n现在，我们将这个变换表示为矩阵形式： 结果就是点P在逆时针旋转θ度之后的坐标 (x', y') 可以通过原坐标 (x, y) 与旋转矩阵相乘得到。\n（使用了基本的三角恒等式和极坐标的转换。）\n向量与角度的关系\n重心坐标计算公式\n计算点的重心坐标通常涉及到解一个线性方程组。对于三角形 \\( ABC \\) 中的点 \\( P \\)，其重心坐标 $(\\lambda_1, \\lambda_2, \\lambda_3)$ 可以通过以下步骤计算得出：\n1. **确定三角形顶点的坐标**：\n假设三角形 \\( ABC \\) 的顶点坐标分别为 \\( A(x_1, y_1) \\)，\\( B(x_2, y_2) \\)，\\( C(x_3, y_3) \\)。\n2. **计算面积**：",
    "url": "/blog/基本的矩阵运算",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 336,
    "endPos": 649,
    "originalTitle": "旋转矩阵的证明"
  },
  {
    "chunkId": "/blog/基本的矩阵运算#chunk-2",
    "title": "旋转矩阵的证明 (第3段)",
    "content": "...C(x_3, y_3) \\)。\n2. **计算面积**： 使用叉乘计算三角形 \\( ABC \\) 的面积 \\( S_{ABC} \\)。\n计算点 \\( P \\) 与三角形顶点形成的子三角形的面积，例如 \\( S_{PBC} \\)，\\( S_{PCA} \\)，\\( S_{PAB} \\)。\n3. **利用面积比求解重心坐标**：\n重心坐标 \\( $\\lambda_1$ \\)，\\( $\\lambda_2$ \\)，\\( $\\lambda_3$ \\) 分别等于点 \\( P \\) 对应的子三角形面积与三角形 \\( ABC \\) 面积的比例。例如：\n     $$ \\lambda_1 = \\frac{S_{PBC}}{S_{ABC}} $$\n     $$ \\lambda_2 = \\frac{S_{PCA}}{S_{ABC}} $$",
    "url": "/blog/基本的矩阵运算",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 649,
    "endPos": 984,
    "originalTitle": "旋转矩阵的证明"
  },
  {
    "chunkId": "/blog/基本的矩阵运算#chunk-3",
    "title": "旋转矩阵的证明 (第4段)",
    "content": "...= \\frac{S_{PCA}}{S_{ABC}} $$ $$ \\lambda_3 = \\frac{S_{PAB}}{S_{ABC}} $$\n4. **确保重心坐标之和为1**：\n验证 \\( $\\lambda_1 + \\lambda_2 + \\lambda_3$ = 1 \\)。\nReference：重心坐标",
    "url": "/blog/基本的矩阵运算",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 984,
    "endPos": 1114,
    "originalTitle": "旋转矩阵的证明"
  },
  {
    "chunkId": "/blog/指针网络#chunk-0",
    "title": "指针网络",
    "content": "指针网络\nPointer Network（指针网络）是一种特殊类型的神经网络，它在输出中直接指向输入序列中的位置，而不是通常的固定大小的词汇表。这种结构特别适合于那些输出序列依赖于输入序列中元素位置的问题，例如排序问题。\n例子\n旅行推销员问题（TSP）\n经典的旅行推销员问题（TSP）。在这个问题中，给定一组城市，任务是找出穿过所有城市一次、且总旅行距离最短的路线。\n在传统的神经网络中，你需要预定义所有可能的路线，然后让模型选择。但这几乎是不可能的，因为可能的路线数量随城市数量的增加呈现组合爆炸。",
    "url": "/blog/指针网络",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 251,
    "originalTitle": "指针网络"
  },
  {
    "chunkId": "/blog/指针网络#chunk-1",
    "title": "指针网络 (第2段)",
    "content": "...不可能的，因为可能的路线数量随城市数量的增加呈现组合爆炸。 这就是指针网络派上用场的地方。Pointer Network通过观察所有的城市（输入序列），然后输出一个序列，该序列是城市的索引，指明了应当访问城市的顺序。其关键在于网络的每一个输出元素都是根据上下文来直接指向输入序列中的某个位置。\n指针网络工作的简化步骤：\n1. 输入序列编码： 使用RNN/LSTM/Transformer等编码输入序列（城市的坐标）。\n2. 注意力机制： 训练一个注意力模型，可对输入序列中的不同部分分配不同的权重。\n3. 输出序列解码： 利用注意力权重，生成指向输入序列中元素位置的输出序列（对城市访问的顺序索引）。\n通过这种方式，指针网络可以有效地处理那些其输出是输入序列的排序或重组的任务，既提高了任务的处理速度，又避免了不切实际的输出空间设计。\n不切实际的输出",
    "url": "/blog/指针网络",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 251,
    "endPos": 597,
    "originalTitle": "指针网络"
  },
  {
    "chunkId": "/blog/指针网络#chunk-2",
    "title": "指针网络 (第3段)",
    "content": "...处理速度，又避免了不切实际的输出空间设计。\n不切实际的输出 \"不切实际的输出空间设计\"这个短语通常指的是在某些机器学习任务中，如果我们试图预定义所有可能的输出，会遇到输出空间巨大到难以处理的问题。\n常规神经网络和固定输出空间\n许多机器学习任务，特别是在自然语言处理中，有一个固定且有限的输出空间。例如，在一个语言模型中，我们可能有一个由所有单词组成的词汇表，模型在给定上下文时预测下一个单词。这个单词列表是预定义的，尽管其可能包含成千上万的单词，它仍然是固定的。\n指针网络和动态输出空间\n与固定输出空间不同，某些任务涉及的输出空间随输入动态变化。以排序问题为例，假设我们有一个包含10个不同整数的列表，并希望网络输出它们升序排列的结果。输出的每一个位置应该是指向输入列表中某个元素的指针。如果我们尝试像处理固定词汇表一样处理这个问题，我们会遇到几个问题：",
    "url": "/blog/指针网络",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 597,
    "endPos": 945,
    "originalTitle": "指针网络"
  },
  {
    "chunkId": "/blog/指针网络#chunk-3",
    "title": "指针网络 (第4段)",
    "content": "...尝试像处理固定词汇表一样处理这个问题，我们会遇到几个问题： **组合爆炸**：随着输入列表的大小增加，可能的排序结果（输出空间）是阶乘级增长的（例如，10个数有10!种排列方式），远超常规词汇表的大小。\n**输出依赖于输入**：每个不同的输入列表会有一个不同的、特定的排序结果。因此，我们无法预先定义一个能够覆盖所有可能输入的排序结果的静态词汇表。\n**效率低下**：预定义所有可能的排列会导致巨大的输出空间，使得模型不仅训练效率低，而且在执行时需要大量的计算资源。\n解决方案",
    "url": "/blog/指针网络",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 945,
    "endPos": 1154,
    "originalTitle": "指针网络"
  },
  {
    "chunkId": "/blog/指针网络#chunk-4",
    "title": "指针网络 (第5段)",
    "content": "...不仅训练效率低，而且在执行时需要大量的计算资源。\n解决方案 这就是为什么我们说在这种情况下进行\"不切实际的输出空间设计\"是不合理的。作为解决方案，指针网络提出了使用指针的概念。它不是在一个固定的词汇表中选择输出，而是生成指向输入序列中各个元素位置的索引。这种方式在处理变化的输出空间时既高效又有效。它能够根据输入动态调整其输出，从而克服了传统方法在面对这类问题时的局限性。\nReference\n神经网络之Pointer Net (Ptr-net)",
    "url": "/blog/指针网络",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1154,
    "endPos": 1347,
    "originalTitle": "指针网络"
  },
  {
    "chunkId": "/blog/晕3D#chunk-0",
    "title": "晕3D",
    "content": "晕3D（Motion Sickness）是许多玩家在玩3D游戏时遇到的常见问题，主要是由于视觉、前庭系统（内耳平衡器官）和身体感觉之间的冲突所引起的。这种冲突会导致大脑混淆，从而引发一系列不适症状，如头晕、恶心、出汗等。以下是详细的原因解释：\n1. 视觉与前庭系统的冲突\n**视觉感知**：在玩3D游戏或使用虚拟现实（VR）设备时，玩家的眼睛看到的是快速移动的图像和场景变化。\n**前庭感知**：前庭系统通过内耳的半规管感知身体的实际运动和姿势变化。当玩家坐在固定的位置上玩游戏时，前庭系统感受到的是静止状态或非常有限的运动。\n**冲突**：当视觉系统感知到快速运动而前庭系统感知到静止时，产生了感知上的冲突。这种冲突使大脑难以协调两者的信息，从而引发晕动症。\n2. 感知延迟和不一致",
    "url": "/blog/晕3D",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 343,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/晕3D#chunk-1",
    "title": "晕3D (第2段)",
    "content": "...以协调两者的信息，从而引发晕动症。\n2. 感知延迟和不一致 **延迟（Latency）**：在VR环境中，系统可能会有轻微的延迟（延迟几毫秒到几百毫秒），这会导致图像更新与头部运动不一致，增加晕动症的可能性。\n**帧率不稳定（Frame Rate Instability）**：帧率的突然变化或不稳定会导致画面卡顿或不流畅，增加视觉与身体感知之间的冲突。\n3. 视角与运动方式\n**视角变化**：游戏中的快速视角变化或频繁的视角切换会增加视觉信息的复杂性，容易引发头晕和不适。\n**运动方式**：某些游戏中的运动方式，如第一人称视角的快速移动、旋转或突然加速和减速，容易引发晕动症。\n4. 屏幕和显示器因素\n**屏幕刷新率**：低刷新率的屏幕会导致画面拖影和闪烁，这会增加视觉疲劳和晕动症的可能性。",
    "url": "/blog/晕3D",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 343,
    "endPos": 663,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/晕3D#chunk-2",
    "title": "晕3D (第3段)",
    "content": "...幕会导致画面拖影和闪烁，这会增加视觉疲劳和晕动症的可能性。 **显示器尺寸和分辨率**：较小的显示器和低分辨率的画面容易引发视觉不适，增加晕动症的风险。\n5. 个人差异\n**敏感度**：不同个体对晕动症的敏感程度不同，有些人天生对视觉和前庭系统的冲突更敏感。\n**适应能力**：有些玩家经过一段时间的适应，可以逐渐减少晕动症的症状，而另一些人可能持续感到不适。\n6. 环境因素\n**光线和环境**：在昏暗的环境中玩游戏或使用VR设备可能会增加眼睛的疲劳度，进而增加晕动症的风险。\n**姿势和位置**：玩家的坐姿、头部和身体的位置也会影响前庭系统的感知，如果姿势不自然或长时间保持一种姿势，可能会增加不适感。\n总结",
    "url": "/blog/晕3D",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 663,
    "endPos": 940,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/晕3D#chunk-3",
    "title": "晕3D (第4段)",
    "content": "...果姿势不自然或长时间保持一种姿势，可能会增加不适感。\n总结 晕3D的主要原因是由于视觉系统和前庭系统之间的感知冲突，以及由此产生的感知不一致。各种因素，如延迟、帧率不稳定、视角变化、屏幕刷新率、个人敏感度和环境因素等，都会影响晕动症的发生。\nAI 缓解晕动症\n1. 动态摄像机控制\nAI可以实时分析玩家的反应和行为，动态调整游戏摄像机的视角和运动方式，以减少晕动症的发生。例如：\n**平滑摄像机移动**：AI可以通过预测玩家的移动方向和速度，提前调整摄像机的运动，使其更加平滑和自然，减少突兀的摄像机变化。\n**减少摄像机抖动**：AI可以检测和减少摄像机的抖动和剧烈运动，尤其是在玩家快速移动或旋转时。\n2. 自适应视野调整",
    "url": "/blog/晕3D",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 940,
    "endPos": 1224,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/晕3D#chunk-4",
    "title": "晕3D (第5段)",
    "content": "...运动，尤其是在玩家快速移动或旋转时。\n2. 自适应视野调整 AI可以根据玩家的反馈和生理信号（如眼动追踪数据、头部运动传感器等），自适应调整游戏的视野（Field of View, FOV）以减少晕动症。例如：\n**动态视野调整**：在玩家感觉不适时，AI可以自动缩小视野，减少边缘视觉的影响，帮助缓解晕动症。\n**智能缩放**：AI可以在玩家需要集中注意力时，智能放大重要的游戏区域，减少视觉杂乱。\n3. 平滑过渡效果\nAI可以在游戏中添加平滑过渡效果，减少画面切换的突兀感。例如：\n**淡入淡出效果**：在场景切换时，AI可以自动添加淡入淡出的过渡效果，使画面切换更加平滑。\n**智能加载**：AI可以预测玩家的下一步行动，并提前加载相关场景，减少加载时的卡顿和突兀感。\n4. 个性化设置推荐",
    "url": "/blog/晕3D",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1224,
    "endPos": 1543,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/晕3D#chunk-5",
    "title": "晕3D (第6段)",
    "content": "...相关场景，减少加载时的卡顿和突兀感。\n4. 个性化设置推荐 AI可以分析玩家的游戏历史和反馈，推荐个性化的游戏设置，以减少晕动症。例如：\n**个性化视角设置**：AI可以根据玩家的偏好和反馈，推荐最佳的视角和摄像机设置。\n**游戏优化建议**：AI可以根据玩家的硬件配置和游戏设置，提供优化建议，以提高游戏流畅度和画面稳定性。\n5. 虚拟现实中的应用\n在虚拟现实（VR）游戏中，AI可以通过多种方式减少晕动症。例如：\n**智能运动预测**：AI可以预测玩家的头部和身体运动，提前调整虚拟世界中的视角和物体位置，减少延迟和不自然的运动。\n**生理反馈监测**：AI可以实时监测玩家的生理信号（如心率、皮肤电反应等），在玩家出现不适迹象时，自动调整游戏设置或提供休息提示。\n具体例子\n1. 动态摄像机控制",
    "url": "/blog/晕3D",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1543,
    "endPos": 1864,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/晕3D#chunk-6",
    "title": "晕3D (第7段)",
    "content": "...整游戏设置或提供休息提示。\n具体例子\n1. 动态摄像机控制 许多现代游戏已经开始采用智能摄像机控制系统，例如《《The Legend of Zelda: Breath of the Wild》》中的摄像机系统，通过平滑移动和智能调整视角，减少了晕动症的发生。\n2. VR中的智能运动预测\n在一些高端VR设备中，已经开始采用AI技术来预测和补偿玩家的头部和身体运动。例如，Oculus和HTC Vive的一些应用程序中，AI可以实时调整视角，减少延迟和不自然的运动，从而减少晕动症。\n总结\nAI技术在解决晕3D问题上具有巨大的潜力。通过动态摄像机控制、自适应视野调整、平滑过渡效果、个性化设置推荐和虚拟现实中的应用，AI可以显著减少玩家的晕动症，使3D游戏和VR游戏体验更加舒适和愉快。",
    "url": "/blog/晕3D",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1864,
    "endPos": 2176,
    "originalTitle": "晕3D"
  },
  {
    "chunkId": "/blog/机器与人类的视角#chunk-0",
    "title": "机器与人类的视角",
    "content": "机器与人类的视角\n人类视角中一切都是符号的排列组合，通过符号沟通并理解世界；万物（人类能够理解的）的符号化都是逐步抽象演变出来的，比如从早期的象形文字，到当代的丰富多彩的多民族语言文字；再比如从 0/1 计算机编码规则，到更加抽象的编程语言；都是从底层的规则定义开始逐步演化组合出更加庞大的抽象符号",
    "url": "/blog/机器与人类的视角",
    "chunkIndex": 0,
    "totalChunks": 2,
    "startPos": 0,
    "endPos": 150,
    "originalTitle": "机器与人类的视角"
  },
  {
    "chunkId": "/blog/机器与人类的视角#chunk-1",
    "title": "机器与人类的视角 (第2段)",
    "content": "...；都是从底层的规则定义开始逐步演化组合出更加庞大的抽象符号 机器视角中一切都是像素的分布排列组合，人类通过投喂足够多的标注的图片跟数据来让机器逐步学习到抽象的规则（像素的不同分布代表不同的意义，可能是猫狗，也可能是人类）；理论上机器视角的世界是更加丰富的，而且更可能演化出人类从未定义过的符号（人类制定的符号化路径只是演化路径之一，肯定还有其他符号规则演化的可能性），**所以理论上机器可以模拟一切人类世界的东西（能理解的或者不能理解的）**，机器学习中的 VAE/GAN 等可以通过潜在空间分布来生成逼近真实世界（人类理解的真实世界）的样本正是这种理论的证明；而像素也是人类符号定义的一种，应该有更加本质的存在，等挖掘出后可能更加容易模拟人类视角中的真实世界\nwriter wizardpisces written 2024/7/5",
    "url": "/blog/机器与人类的视角",
    "chunkIndex": 1,
    "totalChunks": 2,
    "startPos": 150,
    "endPos": 487,
    "originalTitle": "机器与人类的视角"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-0",
    "title": "机器学习实践记录",
    "content": "简介\n业务目标是解决自动化场景遇到的验证码识别\n看完本文的收获：你将了解到机器学习在业务中的一种应用场景。分享将从非专业的机器学习开发的视角重现了以业务场景为核心，逐步介绍工具调研、模型调研、训练和部署等过程中所遇到的问题以及解决思路。\n问题具体化\n识别变长不规则的图片验证码（包含字母或数字）\n第三方工具调研\n遇到的问题\n付费且不准\n原因：结果很不准，需要付费\n成熟开源的 OCR 只能识别比较规整的字母跟数字\n结果：不选择，决定找开源模型，自己训练\n网上模型很多，需要甄选并改造成合适的模型\nCNN 调研\n寻找到并调研了的CNN 模型，赞数比较多，应该靠谱\n阅读源码后判断只能做定长识别\n技术栈\n模型实现：Tensorflow 框架的 CNN",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 0,
    "totalChunks": 13,
    "startPos": 0,
    "endPos": 324,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-1",
    "title": "机器学习实践记录 (第2段)",
    "content": "...别\n技术栈\n模型实现：Tensorflow 框架的 CNN CNN（Convolutional Neural Network 卷积神经网络） 做图片特征提取\n定长编码：one hot编码，将离散的分类数据转换为神经网络等模型可以处理的向量表示。如果编码是 4 位，则是一个识别 4 位字符的分类任务\n交叉熵损失函数推动反向传播\n遇到的问题\n问题1\n我们的目标验证码是变长的\n处理变长可能方案：裁剪，切割，并一个个识别文本\n结果：放弃直接的 CNN 模型，寻找更合适的模型\n原因：图片背景有噪声，导致对图片进行切割困难，会损失一些文本细节导致识别不准。\nCRNN 调研\n寻找到并调研的CRNN 模型，赞数相对 CNN 少了一个量级，看起来很顺眼，有论文支持\n阅读源码后判断可以做变长序列识别\n技术栈\nPytorch 框架的 CRNN 流程 \n!CRNN 流程",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 1,
    "totalChunks": 13,
    "startPos": 324,
    "endPos": 673,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-2",
    "title": "机器学习实践记录 (第3段)",
    "content": "...Pytorch 框架的 CRNN 流程 \n!CRNN 流程 CNN 做图片特征提取\nLSTM(RNN)(Long-short term memory)  对 CNN 提取的特征序列建模，利用上下文信息**提高识别的准确性**；\n对于 RNN 的作用\n作用1（字符内部像素序列）：对于常见的随机顺序验证码，RNN 通过处理构成字符的像素序列并捕捉序列中的特征信息，学习到字符的局部和全局特征，包括形状、纹理、笔画等信息，从而提升判定字符的准确率。",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 2,
    "totalChunks": 13,
    "startPos": 673,
    "endPos": 866,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-3",
    "title": "机器学习实践记录 (第4段)",
    "content": "...征，包括形状、纹理、笔画等信息，从而提升判定字符的准确率。 作用2（字符序列）：对于非随机顺序验证码，对于一些相似或者易混淆的字符，RNN可以根据前后的字符来判断最可能的结果。例如，如果验证码中有一个字符“l”，它可能是字母“l”或者数字“1”，但是如果前面的字符是“o”，并且训练数据中经常出现 ol，那么RNN就可以推断出它更可能是字母“l”；也即 RNN 能够在大样本中寻找到生成验证码序列的一些可能得规律，从而增加准确性\nPS：定长任务中可以理解成是对 CNN 识别能力的增强？\nCTC（Connectionist temporal classification 连接时序分类） 对 RNN 的输出序列对齐 + 计算损失驱动梯度下降反向传播",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 3,
    "totalChunks": 13,
    "startPos": 866,
    "endPos": 1161,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-4",
    "title": "机器学习实践记录 (第5段)",
    "content": "...RNN 的输出序列对齐 + 计算损失驱动梯度下降反向传播 CTC 算法不需要训练数据对齐（降低人工对齐工作量），它会把所有相同输出的对齐合并。帮助模型学习字符级别的对齐和映射关系，尤其在没有明确字符分隔符的情况下\n其他应用：适用于音频到文字的转码任务（音频的时长 t0->t1 可能对应一个字符）\n遇到的问题\n问题1\n样本量评估（经验问题）：到底多少数据才能训练出可观效果？知道量级后才能给同事时发出定量的帮忙请求，做到有的放失\n实践步骤\n    1. 参考开源库\n基本都在 >=五位数\n    2. 测试量级；找到最小量级同时又能得出不错效果的大概样本数\n找到合适的自动样本生成库，用自动生成的样本测试 5 位数能达到 90%；降低量级测试到 6k 数据能达到 80% 左右准确性；于是暂定为 6k 的目标标注数据\n问题2",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 4,
    "totalChunks": 13,
    "startPos": 1161,
    "endPos": 1495,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-5",
    "title": "机器学习实践记录 (第6段)",
    "content": "...0% 左右准确性；于是暂定为 6k 的目标标注数据\n问题2 真实样本数不足导致学习慢（损失率下不去）：1k 多的标注数据不足以直接训练出效果（发动人民群众标注前提是看到效果（死锁），后面知道，标注本身让人没啥好感）\n当时标注一个样本大致需要 10s，刷新 -> 下载 -> 打开 -> 标注；还是比较费时间\n标注加速（解决标注慢问题）：脚本实现样本批量下载，批量合并\n数据清洗：对大家帮忙标注的数据进行简单核对，例如：对包含 0，1，o，l 等的可能出错的标注进行简单核对（ls sample/train | grep 'l'）\n实践步骤\n微调\n猜想（微调）：迁移学习跟特征共享，用少量样本训练出效果",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 5,
    "totalChunks": 13,
    "startPos": 1495,
    "endPos": 1766,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-6",
    "title": "机器学习实践记录 (第7段)",
    "content": "...调\n猜想（微调）：迁移学习跟特征共享，用少量样本训练出效果 对比：九年义务教育中老师口中的举一反三，先学到如何使用公式（底层特征），然后套公式（知识迁移）；机器学习也可以通过其他样本（与真实样本共享一些特征）的学习积累底层特征，然后应用到少量样本加速学习过程\n猜想实践：\n        1. 用第三方库使用同样的字符集生成6万张验证码样本，4,5,6长度分别是2万张；划分为训练 57k + 测试集 30k，花费17个小时（M1 CPU，在更高级版本的 pytorch 中能够支持 M1 的 GPU）训练出参数模型 A.pt\n效果：识别自身测试集准确率 90% 左右\n        2. 基于 A.pt 的参数，使用 1k 多的标注数据进行训练模型 B.pt（体积是 31M）\n效果：损失率下降很快，3个小时，达到准确率 44% 左右",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 6,
    "totalChunks": 13,
    "startPos": 1766,
    "endPos": 2106,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-7",
    "title": "机器学习实践记录 (第8段)",
    "content": "...效果：损失率下降很快，3个小时，达到准确率 44% 左右 3. 改造数据加载器, 调参\n        4. 大家帮忙持续标注更多真实数据并优化训练模型\n        5. 数据修正\n        6. 最后将模型识别部署成 python 服务（目前达到准确率 75% 左右（训练集3k，测试集 250））\n感悟\n给定模型下，能搞到合适的训练数据集很重要\n是否可以通过已有样本进行变换生成新的样本？\n后续思考 + 实践\n如何进一步优化模型准确率？\n数据集较小\n本次应对：增加真实数据量标注\n后续尝试：\n        0. （已经实践）通过借助模型实际应用进行数据收集，识别准确的数据可以直接扩充标注样本库，识别失败的数据进行人工标记后喂给模型”刻意练习“\n刻意练习后得到的新权重有时候无法识别旧权重识别准确的数据",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 7,
    "totalChunks": 13,
    "startPos": 2106,
    "endPos": 2445,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-8",
    "title": "机器学习实践记录 (第9段)",
    "content": "...刻意练习后得到的新权重有时候无法识别旧权重识别准确的数据 思考：只做错题，而不去重复做会做的题不一定会提升模型能力\n实践：在可以刻意练习基础上进行重复的题目训练以维持旧能力（通过旧权重持续产生正确的数据，然后投喂给新权重）\n实践后的思考：\n实际应用收集的准确数据是能提升模型准确率的\n猜想：模型的识别由数据的多个特征综合判定的，比如人脸有耳鼻眼嘴 4 个特征，如果只有耳朵认识的准确率比较低（其他特征识别准确率比较高），则模型还是有可能判定成功一张脸，通过收集模型判定为脸的数据来训练模型，则可能提高识别耳朵特征的识别准确率，从而提升整体综合准确率\n只是刻意练习而不去强化准确的认知，会导致模型忘记之前会做的题\n类似的鸡生蛋，蛋生鸡：SAM 模型的数据也并非全都是标注的，后面大量的训练数据都是通过早期的 SAM 模型分割出，然后训练出更强大的 SAM 模型",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 8,
    "totalChunks": 13,
    "startPos": 2445,
    "endPos": 2796,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-9",
    "title": "机器学习实践记录 (第10段)",
    "content": "...期的 SAM 模型分割出，然后训练出更强大的 SAM 模型 1. 使用数据增强技术，如随机裁剪、旋转、翻转等，扩充训练数据的多样性。\n        2. 使用 VAE（变分自编码器） 模型根据现有数据生成类似样本（因为训练 VAE 本身就需要比较多的样本数据，并且 VAE 也需要知道生成样本的Label）\n        3. GAN?开发基于 mnist 数据集的 GAN 网络\n            1. 尝试了一般 cgan ，3k 张图训练，效果不佳（LOSS 会震荡，使用 Adam 优化器）\n            2. 后续尝试 wgan（训练更平滑，使用 RMSprop 优化器）\n        4. stable diffusion 图生图？\n已经尝试\n        1. 5k 张长度为 4 的类似样本的",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 9,
    "totalChunks": 13,
    "startPos": 2796,
    "endPos": 3143,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-10",
    "title": "机器学习实践记录 (第11段)",
    "content": "...1. 5k 张长度为 4 的类似样本的 cgan 训练，结果：训练后生成数字比较模糊\nwgan 训练，结果：生成数字还是比较模糊；原因：样本太少（真实样本只标记了 3k ，估计真实）\n模型复杂度过高：过多的参数和复杂的模型结构会使模型在训练数据上表现很好，但在新数据上泛化能力较差。\n本次应对：使用比较靠谱的论文模型；PS：模型使用的 LSTM 在每个 Step 共享参数能避免过拟合（RNN 的升级版，RNN 会有梯度消失跟爆炸问题（而正是由于共享参数导致）） \n方案汇总：模型参数缩减（剪枝（去除重要要的参数），量化（eg:缩减精度），知识蒸馏等），但是这个度不太好把控；例子：使用 LLaMa 模型初始权重（通过无监督学习获得）微调出更小的但是效果还不错的新模型 Alpaca 跟 Vicuna",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 10,
    "totalChunks": 13,
    "startPos": 3143,
    "endPos": 3474,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-11",
    "title": "机器学习实践记录 (第12段)",
    "content": "...小的但是效果还不错的新模型 Alpaca 跟 Vicuna 噪声和异常样本：当训练数据中存在噪声、异常样本或标注错误时，CRNN可能会过拟合这些不代表真实数据分布的异常情况。模型会试图适应这些异常数据，导致在新数据上的表现下降。\n本次应对：手动清理；模型去预测测试集，对测试集预测错误的样本进行归纳，再反向应用到训练集\n其他方案：基于统计，聚类，邻近度，机器学习，时间序等；异常检测方法的选择和调整需要根据具体问题和数据的特点进行\n不平衡的类别分布：如果训练数据中的类别分布不平衡，即某些类别的样本数量远远多于其他类别，模型可能会倾向于过拟合训练数据中较多的类别。这会导致模型对于少数类别的泛化能力较差。\n本次应对：真实的数据抓取，符合真实数据的生成规律分布，规避问题",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 11,
    "totalChunks": 13,
    "startPos": 3474,
    "endPos": 3779,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习实践记录#chunk-12",
    "title": "机器学习实践记录 (第13段)",
    "content": "...应对：真实的数据抓取，符合真实数据的生成规律分布，规避问题 过度训练：CRNN进行过多的训练轮次或使用过小的学习率，模型可能会过度拟合训练数据。过度训练会导致模型过度适应训练数据中的细节和噪声，而无法泛化到新数据。\n应对：早停法：验证集上监控模型性能，当性能不再提升时停止训练。\nReferences\nCRNN Paper\narchitecture - program mode\nText-Recognition-With-CRNN-CTC-Network\nepoch-vs-iterations-vs-batch-size\nunderstanding lstm\nconvolutional-neural-network\nCNN captcha\nCRNN pytorch\nRNN基础\n交叉熵损失函数",
    "url": "/blog/机器学习实践记录",
    "chunkIndex": 12,
    "totalChunks": 13,
    "startPos": 3779,
    "endPos": 4098,
    "originalTitle": "机器学习实践记录"
  },
  {
    "chunkId": "/blog/机器学习的种类#chunk-0",
    "title": "监督学习",
    "content": "监督学习\n在监督学习中，训练数据既包含输入特征也包含输出标签（或称为目标值）。算法通过学习这些数据，建立输入和输出之间的映射关系，以便能够预测新输入数据的输出。监督学习常用于分类和回归问题。常见的监督学习算法包括线性回归、逻辑回归、决策树、支持向量机、朴素贝叶斯、神经网络等。\n半监督学习\n在半监督学习中，训练数据包含少量的带有标签的样本和大量的无标签样本。这种方法结合了监督学习和无监督学习的优势，可以在标签数据有限的情况下提高模型的性能。\n无监督学习\n不依赖于标注过的训练数据来学习数据的特征。算法能够自动地从数据中发现结构和模式，而不需要任何外部的指导或标签。无监督学习特别适合于那些**难以获取标注数据的场景**，或者当我们对数据的结构和关系知之甚少时。",
    "url": "/blog/机器学习的种类",
    "chunkIndex": 0,
    "totalChunks": 6,
    "startPos": 0,
    "endPos": 332,
    "originalTitle": "监督学习"
  },
  {
    "chunkId": "/blog/机器学习的种类#chunk-1",
    "title": "监督学习 (第2段)",
    "content": "...注数据的场景**，或者当我们对数据的结构和关系知之甚少时。 聚类分析：通过聚类算法，如K-means或层次聚类，将数据分组，使得同一组内的数据点相似度高，不同组间的数据点相似度低。这有助于识别数据中的自然分布和结构。\n降维技术：如主成分分析（PCA）、核PCA、t-SNE等，通过降低数据的维度来提取关键特征，同时尽量保留数据的重要信息。\n自编码器（动态训练参数）：一种神经网络，通过重构输入数据来学习数据的有效表示。自编码器的隐藏层可以捕捉数据的关键特征。",
    "url": "/blog/机器学习的种类",
    "chunkIndex": 1,
    "totalChunks": 6,
    "startPos": 332,
    "endPos": 532,
    "originalTitle": "监督学习"
  },
  {
    "chunkId": "/blog/机器学习的种类#chunk-2",
    "title": "监督学习 (第3段)",
    "content": "...习数据的有效表示。自编码器的隐藏层可以捕捉数据的关键特征。 例子：MNIST 数据的压缩与解压中，对于每一张图像，编码器的函数都是试着去学习一种可以将图像的数千个像素点的信息压缩到一个32维的向量中的方法，而解码器则试图从这个32维的表示中重新构造出原始图像。训练过程中要达到的目标就是使得解码后的图像尽可能的接近原始的输入图像。 **输入图像数据本身就是训练目标**\n对比学习：通过比较数据点之间的相似性和差异性，学习数据的特征表示。提供了更多的灵活性和效率（比如服务于迁移学习），尤其是在处理大规模未标注数据集时\n对比学习的目标（**可以被视作迁移学习的准备步骤**，以下给定的 SimpleCNN 例子可以在训练好后在最后一层加上全连接层进行图像分类的迁移学习，具体可以查看迁移学习的示例代码例子）",
    "url": "/blog/机器学习的种类",
    "chunkIndex": 2,
    "totalChunks": 6,
    "startPos": 532,
    "endPos": 855,
    "originalTitle": "监督学习"
  },
  {
    "chunkId": "/blog/机器学习的种类#chunk-3",
    "title": "监督学习 (第4段)",
    "content": "...行图像分类的迁移学习，具体可以查看迁移学习的示例代码例子） 表征学习： 对比学习主要用于无监督的场景，因此它最主要的目标是学习出能够捕捉数据本质特征的表达（表征），而不是像监督学习那样直接用于分类或回归任务。这些特征可以用于下游任务，例如图像识别、目标检测或自然语言处理任务等。\n数据增强的效果理解： 利用数据增强创建的不同视图，模型学习到的特征应该是对这些视图改变具有不变性的。这意味着无论图像如何旋转或变色，模型都可以识别出图像中的同一对象。\n**对比学习示例**\nPyTorch实现的对比学习的简单代码示例。模型的目标是学习一个特征表示，这个表示能够区分不同的数据样本。具体来说，**模型通过最大化正样本（经过数据增强的相似图像）之间的相似度来实现这一点，同时最小化与负样本（不同的图像）之间的相似度。**不依赖于外部的标注信息。\n强化学习",
    "url": "/blog/机器学习的种类",
    "chunkIndex": 3,
    "totalChunks": 6,
    "startPos": 855,
    "endPos": 1199,
    "originalTitle": "监督学习"
  },
  {
    "chunkId": "/blog/机器学习的种类#chunk-4",
    "title": "监督学习 (第5段)",
    "content": "...图像）之间的相似度。**不依赖于外部的标注信息。\n强化学习 强化学习是一种通过与环境的交互来学习的方法。在这种学习方式中，算法通过尝试不同的行为来探索环境，并根据每次行为的结果（奖励或惩罚）来调整其策略，以最大化长期累积的奖励。强化学习常用于控制问题，如机器人导航、游戏AI等。（Python Gym库提供了一种简单有效的方式来设计和评估强化学习算法，特别适用于那些需要快速了解和应用新技术的场合。）\n三种方式：\n基于价值：例如 Q-learning\n基于策略\n价值与策略结合\n例子\n基于策略的代码例子\n基于价值的例子\n迁移学习",
    "url": "/blog/机器学习的种类",
    "chunkIndex": 4,
    "totalChunks": 6,
    "startPos": 1199,
    "endPos": 1434,
    "originalTitle": "监督学习"
  },
  {
    "chunkId": "/blog/机器学习的种类#chunk-5",
    "title": "监督学习 (第6段)",
    "content": "...略结合\n例子\n基于策略的代码例子\n基于价值的例子\n迁移学习 迁移学习是机器学习中的一种策略，它涉及将在一个任务上已经学习到的知识应用到另一个任务上。换句话说，你拿一个在大量数据上经过预训练的模型，然后将其应用到一个与之相关但数据相对较少的新任务上。这种做法可以加快模型的训练速度，提高模型的性能，尤其是当新任务的数据有限时。\n迁移学习应用例子\n使用Python中的PyTorch库对新的图像分类任务进行微调。这里所使用的预训练模型是ResNet，它经过在ImageNet数据集上的预训练，我们将其应用到一个新的分类任务上（如猫狗分类）。\nReference\ngpt\nAI by Doing",
    "url": "/blog/机器学习的种类",
    "chunkIndex": 5,
    "totalChunks": 6,
    "startPos": 1434,
    "endPos": 1698,
    "originalTitle": "监督学习"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-0",
    "title": "柏拉图表征假说与 AI 关系",
    "content": "柏拉图表征假说与 AI 关系\n引言\nIlya Sutskever在离开OpenAI后不久点赞了一篇由MIT团队发表的AI论文，这篇题为《The Platonic Representation Hypothesis》的论文引起了广泛关注。这篇论文探讨了AI模型在不同数据和模态上的训练是否趋向于收敛成一个共享的现实世界统计模型。本文将深入解析该论文的核心思想，并探讨其对未来AI发展的重要意义。\n柏拉图的洞穴寓言",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 0,
    "totalChunks": 9,
    "startPos": 0,
    "endPos": 206,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-1",
    "title": "柏拉图表征假说与 AI 关系 (第2段)",
    "content": "...思想，并探讨其对未来AI发展的重要意义。\n柏拉图的洞穴寓言 要理解柏拉图表征假说，首先需要了解柏拉图的洞穴寓言。在柏拉图的著作《理想国》中，他描述了一群囚犯从出生就被锁在洞穴中，只能看到身后物体在墙上的影子。这些影子成为了他们眼中的“现实”，但实际上这些影子只是现实的投影。哲学家被比喻为从洞穴中走出来，看到阳光下真实世界的人，他们通过逻辑、数学和自然科学等手段理解更高层次的“现实”。今天，这个目标传递到了AI科学家的手中。\n柏拉图表征假说\n柏拉图表征假说的核心是：不同的神经网络模型在不同的数据和模态上训练，最终会在其表征空间中收敛成一个共享的现实世界统计模型。换句话说，随着AI模型规模和训练数据的增加，不同的AI模型会趋向于对现实进行统一的表征。\n理论解释与模型拼接",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 1,
    "totalChunks": 9,
    "startPos": 206,
    "endPos": 514,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-2",
    "title": "柏拉图表征假说与 AI 关系 (第3段)",
    "content": "...AI模型会趋向于对现实进行统一的表征。\n理论解释与模型拼接 论文中提出了一种验证柏拉图假说的方法——模型拼接（Model Stitching）。该方法通过将两个模型的中间表示层连接起来，形成一个新的“缝合”模型，如果这个缝合模型表现良好，说明两个原始模型的表征是兼容的。通过这种方法，研究者分析了78个计算机视觉（CV）模型，发现性能越强的模型其表征相似度越高。\n表征收敛的三大原因\n论文指出，AI模型表征收敛主要有以下三大原因：\n任务通用性：当一个AI模型需要同时完成多种任务时，其表征空间会收敛到一个小范围，因为每个任务目标都会对模型施加额外的约束。\n模型容量：模型越大，越容易逼近全局最优表征，从而推动表征收敛。更大的模型能够找到一个共享的全局最优解，实现跨模态的通用性和适应性。",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 2,
    "totalChunks": 9,
    "startPos": 514,
    "endPos": 828,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-3",
    "title": "柏拉图表征假说与 AI 关系 (第4段)",
    "content": "...能够找到一个共享的全局最优解，实现跨模态的通用性和适应性。 简单性偏见：深度神经网络倾向于选择最简单的解决方案，这种倾向随着模型变大而更加显著。这种简单性偏见符合奥卡姆剃刀原则，促使模型找到更高质量的解决方案。\n实验结果与应用启示\n实验结果表明，模型性能越强，其表征相似度越高。论文作者提出了多种方法来验证柏拉图表征假说的有效性，并发现强大的模型往往在表征上趋同。\n这给我们的启示是：随着模型参数、任务多样性和算力的增加，AI模型的表征会逐渐收敛趋同。这是否意味着只要扩大模型规模就可以实现通用人工智能（AGI）呢？答案是复杂的。尽管扩大模型规模能实现表征收敛，但对于某些独立任务而言，单独训练一个专用模型可能更具经济价值。\n未来展望",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 3,
    "totalChunks": 9,
    "startPos": 828,
    "endPos": 1116,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-4",
    "title": "柏拉图表征假说与 AI 关系 (第5段)",
    "content": "...任务而言，单独训练一个专用模型可能更具经济价值。\n未来展望 柏拉图表征假说为我们提供了一个新的视角来审视多模态数据之间的关系。即使训练集中不存在跨模态的配对数据，不同模态的数据也会对模型训练有直接帮助。未来，随着AI技术的不断进步，**我们能否借助AI的力量走出洞穴，理解高维度的真正现实呢？**\n原文翻译带图：【论文简读】柏拉图：多模态殊途同归\n原文\n解读：柏拉图表征假说：AI模型趋同于现实的统一表征\n原本概念\n柏拉图表征假说（Plato's theory of representation）是柏拉图关于知识和现实的哲学理论，强调了抽象理念（或“形式”）和感知现实之间的关系。这一假说在柏拉图的对话中得到了广泛的讨论，特别是在《理想国》和《斐多篇》中。",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 4,
    "totalChunks": 9,
    "startPos": 1116,
    "endPos": 1416,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-5",
    "title": "柏拉图表征假说与 AI 关系 (第6段)",
    "content": "...对话中得到了广泛的讨论，特别是在《理想国》和《斐多篇》中。 柏拉图认为，感知世界中的所有事物都是不完美的、暂时的，它们只是更高层次的完美和永恒的“理念”或“形式”的影像或表征。这些理念是唯一真正的存在，而感知世界只是对这些理念的模仿或反映。以下是对柏拉图表征假说的具体解释和例子：\n理论概述\n1. **理念世界（World of Forms）**：这是一个抽象的、非物质的、完美和永恒的世界。所有的理念（如“美”、“善”、“正义”）都存在于这个世界中。\n2. **感知世界（World of Senses）**：这是我们日常生活中体验到的物质世界，充满了不完美和变化。这里的所有事物都是理念的模仿或表征。\n比喻和例子\n1. **洞穴比喻（Allegory of the Cave）**：",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 5,
    "totalChunks": 9,
    "startPos": 1416,
    "endPos": 1730,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-6",
    "title": "柏拉图表征假说与 AI 关系 (第7段)",
    "content": "...洞穴比喻（Allegory of the Cave）**： 在《理想国》第七卷中，柏拉图描述了一个洞穴中的囚徒，他们从出生起就被锁链锁住，只能看到洞穴墙壁上的影子。这些影子是洞外物体在火光下投射到墙上的影像。\n这些影子代表感知世界中的事物，而洞外的真实物体代表理念。\n当一个囚徒被解放并走出洞穴，他首先会被阳光（真理和知识的象征）刺痛眼睛，但逐渐适应后，他会看到真实的事物和它们的完美形式。\n这个比喻说明，人类的感知只是对真实理念的影像或表征，而通过哲学和知识的追求，我们可以理解和接近这些真实的理念。\n2. **床的例子**：\n在《理想国》第十卷中，柏拉图讨论了工匠制作的床和画家绘制的床之间的区别。\n工匠制作的床是对“床”的理念的表征，它在感知世界中存在。\n画家绘制的床是对工匠制作的床的模仿，是感知世界的二次表征。",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 6,
    "totalChunks": 9,
    "startPos": 1730,
    "endPos": 2061,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-7",
    "title": "柏拉图表征假说与 AI 关系 (第8段)",
    "content": "...画家绘制的床是对工匠制作的床的模仿，是感知世界的二次表征。 因此，画家的床与真实的“床”的理念相去甚远，因为它只是模仿的模仿。\n核心思想\n**现实世界中的事物**：我们在日常生活中感知到的所有事物（如树、桌子、人）都是理念的影像或表征。\n**理念或形式**：这些是永恒和完美的原型，它们存在于一个超越物质世界的抽象层面。\n**知识和感知**：真正的知识是对理念的理解，而感知只是对表征的认识。\n现代理解和应用\n柏拉图的表征假说对西方哲学的发展产生了深远影响，特别是在形而上学和认识论领域。它提出了关于现实、知识和真理的基本问题，这些问题在现代哲学和科学中仍然具有重要意义。例如：\n**科学理论**：科学家们试图通过实验和观察揭示自然界的基本法则，这些法则可以被视为对自然界“理念”的探索。",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 7,
    "totalChunks": 9,
    "startPos": 2061,
    "endPos": 2376,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/柏拉图表征假说#chunk-8",
    "title": "柏拉图表征假说与 AI 关系 (第9段)",
    "content": "...然界的基本法则，这些法则可以被视为对自然界“理念”的探索。 **艺术和文学**：艺术家和作家通过他们的作品表征和探索人类经验和理念，反映了柏拉图的表征假说的概念。\n总结\n柏拉图表征假说认为，感知世界中的事物只是永恒和完美的理念的影像或表征。通过哲学和知识的追求，我们可以超越感知世界，接近这些真实的理念。这个假说不仅是理解柏拉图哲学的关键，也是认识论和形而上学的基础理论之一。\nReference\nGPT-4o",
    "url": "/blog/柏拉图表征假说",
    "chunkIndex": 8,
    "totalChunks": 9,
    "startPos": 2376,
    "endPos": 2551,
    "originalTitle": "柏拉图表征假说与 AI 关系"
  },
  {
    "chunkId": "/blog/模型压缩#chunk-0",
    "title": "模型压缩",
    "content": "模型压缩\n知识蒸馏\n通过训练一个较小的“学生”模型来模仿一个大的“教师”模型的行为，从而达到压缩模型的目的。\n低秩分解\n效果\n低秩分解不仅减少了模型的计算和存储需求，还有助于提高模型的泛化能力（参数少，有助于降低过拟合，则泛化能力越强？）。\n压缩：图像矩阵的压缩\nHow-to：权重矩阵 W 可以表示为两个低秩矩阵A和B的乘积：W = A * B^T。这里A和B的秩远小于W，从而降低了GPU显存占用。\nreference\n模型压缩之模型分解篇：SVD分解，CP分解和Tucker分解\n量化\n将权重和激活函数的精度从单精度浮点数（32位）降低到更低位的表示，如16位、8位甚至更低。\n在极端的情况下，可以进行二值化或三值化，此时权重和激活只取{-1, 0, 1}这几个值。\n权重剪枝",
    "url": "/blog/模型压缩",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 342,
    "originalTitle": "模型压缩"
  },
  {
    "chunkId": "/blog/模型压缩#chunk-1",
    "title": "模型压缩 (第2段)",
    "content": "...此时权重和激活只取{-1, 0, 1}这几个值。\n权重剪枝 稀疏剪枝：移除模型中权重的一部分，通常是那些接近于零的权重。\n结构化剪枝：按照某种模式移除权值，比如剪枝整个卷积核或卷积滤波器。\n共享权重：\n在网络的不同部分共享同一组参数，这在循环神经网络（RNNs）中很常见。\n紧凑型卷积核：\n使用更小的卷积核或组合小卷积核来替代大卷积核，如深度可分离卷积。\n  小波变换：\n使用小波变换替代一部分卷积层来实现特征提取与降维。\n使用更高效的架构：\n设计或使用特别为效率优化的网络架构，如MobileNet、SqueezeNet、EfficientNet等。\n重参数化不仅仅指低秩分解，它指的是用一种不同的方式重新表达模型中的参数，以达到某种目的，比如减少参数总数、增加模型的稳定性或是改善性能，或者让模型能够进行求导梯度下降（例如 VAE 的训练）等。",
    "url": "/blog/模型压缩",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 342,
    "endPos": 687,
    "originalTitle": "模型压缩"
  },
  {
    "chunkId": "/blog/模型压缩#chunk-2",
    "title": "模型压缩 (第3段)",
    "content": "...或者让模型能够进行求导梯度下降（例如 VAE 的训练）等。 **低秩分解**是重参数化的一种方法。\nReference\ngpt",
    "url": "/blog/模型压缩",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 687,
    "endPos": 720,
    "originalTitle": "模型压缩"
  },
  {
    "chunkId": "/blog/正则化#chunk-0",
    "title": "定义模型",
    "content": "正则化是一种防止机器学习模型过拟合的重要技术，通过在模型训练过程中引入某些限制或惩罚，使模型更具泛化能力。正则化方法有多种，具体可以分为以下几类：\n1. 参数正则化\n**L1正则化 (Lasso)**\n**L1正则化**：通过在损失函数中添加权重绝对值的和作为惩罚项，鼓励模型的权重稀疏化，从而实现特征选择。\n**公式**：$ \\text{Loss} = \\text{Original Loss} + \\lambda \\sum_i |w_i| $\n**L2正则化 (Ridge)**\n**L2正则化**：通过在损失函数中添加权重平方和作为惩罚项，防止模型的权重值过大，增加模型的稳定性。",
    "url": "/blog/正则化",
    "chunkIndex": 0,
    "totalChunks": 12,
    "startPos": 0,
    "endPos": 294,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-1",
    "title": "定义模型 (第2段)",
    "content": "...平方和作为惩罚项，防止模型的权重值过大，增加模型的稳定性。 **公式**：$ \\text{Loss} = \\text{Original Loss} + \\lambda \\sum_i w_i^2 $\n2. 数据正则化\n**数据增强 (Data Augmentation)**\n**数据增强**：通过对训练数据进行各种变换（如旋转、裁剪、翻转等），生成新的训练样本，从而增加数据的多样性，防止模型过拟合。\n**Dropout**\n**Dropout**：在每次训练迭代中，随机“丢弃”一部分神经元，使模型在训练过程中每次都使用不同的网络结构，增强模型的泛化能力。\n**公式**：在每次训练迭代中，将每个神经元以概率 $ p $ 置为 0。\n3. 标签正则化\n**Label Smoothing**",
    "url": "/blog/正则化",
    "chunkIndex": 1,
    "totalChunks": 12,
    "startPos": 294,
    "endPos": 611,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-2",
    "title": "定义模型 (第3段)",
    "content": "...3. 标签正则化\n**Label Smoothing** **Label Smoothing**：通过对标签分布进行平滑处理，防止模型对训练数据中的特定标签过度自信，提高模型的泛化能力。\n**公式**：$ y_{\\text{smoothed}} = (1 - \\epsilon) \\cdot y_{\\text{one-hot}} + \\frac{\\epsilon}{k} $\n4. 模型结构正则化\n**Early Stopping**\n**Early Stopping**：在训练过程中监控验证集的表现，当验证集误差不再下降时，提前停止训练，防止模型过拟合。\n**Weight Sharing**\n**Weight Sharing**：在网络结构中共享部分权重，减少模型的自由参数，从而防止过拟合。例如，在卷积神经网络中，共享卷积核的权重。",
    "url": "/blog/正则化",
    "chunkIndex": 2,
    "totalChunks": 12,
    "startPos": 611,
    "endPos": 953,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-3",
    "title": "定义模型 (第4段)",
    "content": "...从而防止过拟合。例如，在卷积神经网络中，共享卷积核的权重。 5. 对抗训练 (Adversarial Training)\n**对抗训练**：通过在训练过程中加入对抗样本，使模型在面对恶意样本时也能表现良好，从而提高模型的鲁棒性。\n6. Batch Normalization\n**Batch Normalization**：在每个小批量数据上对网络的输入进行标准化，使得每一层的输入在训练过程中保持稳定，从而加速训练并提高模型的泛化能力。\n具体例子\n1. 参数正则化（L2正则化）\n2. 数据正则化（Dropout）\nVQ 正则 \nVQ 正则化（Vector Quantization Regularization）在某种程度上结合了多种正则化技术的特点，但它最接近于模型结构正则化和数据正则化的混合体。具体来说：",
    "url": "/blog/正则化",
    "chunkIndex": 3,
    "totalChunks": 12,
    "startPos": 953,
    "endPos": 1281,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-4",
    "title": "定义模型 (第5段)",
    "content": "...但它最接近于模型结构正则化和数据正则化的混合体。具体来说： 模型结构正则化：通过在模型结构中引入向量量化层，强制潜在表示离散化，减少模型的自由度，从而防止过拟合。\n数据正则化：通过离散化潜在表示，实际上增加了数据表示的稀疏性和鲁棒性，类似于数据增强技术。\nVQ 过程\n*例子：*\n假设你拍摄了一张照片，照片中有许多不同的颜色，我们需要对照片中的颜色进行量化，即我们采用一组有限的颜色来近似表示照片中的所有颜色。\n具体步骤如下：\n1. **选择代码簿（Codebook）**：为了量化颜色，我们首先需要一个颜色的代码簿。代码簿就是我们选择用来表示所有颜色的那组颜色，比如我们选择红色，蓝色，绿色，黄色，黑色和白色作为我们的代码簿，即这六种颜色作为我们用来表示所有颜色的基本颜色集合。",
    "url": "/blog/正则化",
    "chunkIndex": 4,
    "totalChunks": 12,
    "startPos": 1281,
    "endPos": 1592,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-5",
    "title": "定义模型 (第6段)",
    "content": "...码簿，即这六种颜色作为我们用来表示所有颜色的基本颜色集合。 2. **将照片中的每个像素颜色映射到最接近的代码簿颜色**：然后我们遍历照片中的每个像素，找到距离这个像素颜色最近的代码簿中的颜色，然后用这个最近的颜色来替代原来的像素颜色。例如，一个淡紫色的像素在我们的代码中可能会被替换为蓝色，因为淡紫色在距离上最接近蓝色。\n3. **保存映射信息**：为了重构原图像，我们需要保存颜色的映射信息，即每个像素颜色对应的代码簿中的颜色序号。有了这个信息，我们可以从代码簿中找到正确的颜色来重新构建图像。\n向量量化（VQ，Vector Quantization）的代码簿一般通过无监督学习方法获得，其中最常见的就是k-means聚类算法。例子：\nVQ-Layer 的训练\n创建一个VQ层通常涉及以下几个步骤：",
    "url": "/blog/正则化",
    "chunkIndex": 5,
    "totalChunks": 12,
    "startPos": 1592,
    "endPos": 1914,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-6",
    "title": "定义模型 (第7段)",
    "content": "...-Layer 的训练\n创建一个VQ层通常涉及以下几个步骤： 1. **初始化一个码本（Codebook）**：这是一组可以学习的向量，模型在训练中会逐渐更新这些向量，以便它们代表数据中的通用模式。\n2. **前向传播（Forward Pass）**：在前向传播期间，模型接收输入的连续数据，并将其映射到码本中最接近的向量上，这一步称为量化。\n3. **损失函数（Loss Function）**：VQ层需要一个损失函数来指导学习过程。通常有两部分组成——量化损失和码本损失。量化损失鼓励输入靠近它们对应的码本向量，码本损失则保证码本向量靠近输入数据。\n*代码例子*",
    "url": "/blog/正则化",
    "chunkIndex": 6,
    "totalChunks": 12,
    "startPos": 1914,
    "endPos": 2167,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-7",
    "title": "定义模型 (第8段)",
    "content": "...本向量，码本损失则保证码本向量靠近输入数据。\n*代码例子* 这个例子中的类定义了VQ层的核心功能。在前向传播中，输入被量化到最接近的码本向量，计算损失后返回量化的输出、损失以及一个度量码本使用情况的复杂度(perplexity)指标。在训练中，这个损失将被用来更新码本向量以及可能的其他网络参数。\nLabel Smoothing \nLabel Smoothing 是一种正则化技术，用于减少深度学习模型在训练过程中对特定标签的过度自信，从而提高模型的泛化能力。通过将一个类别的标签分布稍微平滑化，使得模型不会过度拟合训练数据中的噪声。\nLabel Smoothing 的概念",
    "url": "/blog/正则化",
    "chunkIndex": 7,
    "totalChunks": 12,
    "startPos": 2167,
    "endPos": 2425,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-8",
    "title": "定义模型 (第9段)",
    "content": "...训练数据中的噪声。\nLabel Smoothing 的概念 在分类任务中，标准的一个热编码（one-hot encoding）将目标标签表示为一个向量，其中正确的类别被编码为 1，其他类别被编码为 0。例如，对于一个 4 类分类任务，如果正确类别是第 2 类，标签向量是 [0, 1, 0, 0]。\n使用 Label Smoothing，我们将目标标签从一个热编码转换为一个平滑分布。例如，对于一个 4 类分类任务，我们可以将标签向量 [0, 1, 0, 0] 转换为 [0.1, 0.7, 0.1, 0.1]，其中0.1表示的是平滑因子的一部分。\n具体例子\n假设我们有一个 3 类分类任务：\n1. 类别 A\n2. 类别 B\n3. 类别 C\n标准一个热编码标签（没有 Label Smoothing）：\n类别 A 的标签： [1, 0, 0]",
    "url": "/blog/正则化",
    "chunkIndex": 8,
    "totalChunks": 12,
    "startPos": 2425,
    "endPos": 2767,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-9",
    "title": "定义模型 (第10段)",
    "content": "...oothing）：\n类别 A 的标签： [1, 0, 0] 类别 B 的标签： [0, 1, 0]\n类别 C 的标签： [0, 0, 1]\n使用 Label Smoothing 后的标签（假设平滑参数为 0.1）：\n类别 A 的标签： [0.9, 0.05, 0.05]\n类别 B 的标签： [0.05, 0.9, 0.05]\n类别 C 的标签： [0.05, 0.05, 0.9]\n计算过程\n假设我们有一个类别数为 $ k $ 的分类任务，平滑因子为 $ \\epsilon $。对每个标签的转换公式为：\n$ y_{\\text{smoothed}} = (1 - \\epsilon) \\cdot y_{\\text{one-hot}} + \\frac{\\epsilon}{k} $",
    "url": "/blog/正则化",
    "chunkIndex": 9,
    "totalChunks": 12,
    "startPos": 2767,
    "endPos": 3077,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-10",
    "title": "定义模型 (第11段)",
    "content": "...-hot}} + \\frac{\\epsilon}{k} $ 其中，$ y_{\\text{one-hot}} $ 是一个热编码标签向量，$ y_{\\text{smoothed}} $ 是平滑后的标签向量。\n实际应用\n1. 图像分类\n在图像分类任务中，使用 Label Smoothing 可以防止模型在训练过程中对特定类别的过度自信，尤其是当训练数据中存在噪声时。这有助于提高模型的泛化能力，从而在测试数据上的表现更好。\n2. 自然语言处理\n在机器翻译、文本分类等任务中，Label Smoothing 也被广泛使用。它可以帮助模型在处理词汇表较大的情况下，更好地进行分类和预测。\n代码示例（使用 PyTorch）\n总结",
    "url": "/blog/正则化",
    "chunkIndex": 10,
    "totalChunks": 12,
    "startPos": 3077,
    "endPos": 3357,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/正则化#chunk-11",
    "title": "定义模型 (第12段)",
    "content": "...地进行分类和预测。\n代码示例（使用 PyTorch）\n总结 Label Smoothing 是一种有效的正则化技术，通过平滑标签分布，减少模型对训练数据的过度拟合，提高泛化能力。它在图像分类、自然语言处理等任务中都有广泛应用，能够显著提升模型在测试集上的表现。",
    "url": "/blog/正则化",
    "chunkIndex": 11,
    "totalChunks": 12,
    "startPos": 3357,
    "endPos": 3457,
    "originalTitle": "定义模型"
  },
  {
    "chunkId": "/blog/理解 webGPU#chunk-0",
    "title": "WebGPU",
    "content": "WebGPU\nWebGPU shaders定义了具体的渲染操作指令，而pipelines则组织了这些指令和状态，整个WebGPU渲染流程则负责执行这些指令，最终完成图形渲染。\n实际例子：vite-site/src/pages/machine-learning/webgpu/util.ts\nBindGroup\n是WebGPU中的一个核心概念，它是一种资源绑定机制，允许开发者将资源（如缓冲区、纹理、采样器等）与着色器的绑定点（binding points）关联起来。在着色器程序中，这些绑定点可以通过特定的标识符访问对应的资源。理解的关键在于以下几点：",
    "url": "/blog/理解 webGPU",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 277,
    "originalTitle": "WebGPU"
  },
  {
    "chunkId": "/blog/理解 webGPU#chunk-1",
    "title": "WebGPU (第2段)",
    "content": "...以通过特定的标识符访问对应的资源。理解的关键在于以下几点： 1. **资源封装**：封装了一组资源，这些资源可以是缓冲区、纹理、采样器等。这些资源在着色器中用于各种目的，例如存储顶点数据、纹理映射、统一缓冲区（uniforms）等。\n2. **布局（Layout）**：每个都有一个对应的，它定义了中资源的类型、数量和绑定方式。这个布局必须与在管线创建时指定的布局相匹配，这样资源才能被正确地绑定和使用。\n3. **绑定点（Binding Points）**：资源在中通过绑定点索引来引用。这些索引对应着色器代码中的绑定标识符，确保着色器可以正确地访问绑定的资源。\n4. **管线兼容性**：必须与管线兼容，这意味着它的布局要与管线中预期的布局一致。如果管线期望在绑定点0上有一个缓冲区，那么也应该在绑定点0上提供一个缓冲区。",
    "url": "/blog/理解 webGPU",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 277,
    "endPos": 611,
    "originalTitle": "WebGPU"
  },
  {
    "chunkId": "/blog/理解 webGPU#chunk-2",
    "title": "WebGPU (第3段)",
    "content": "...点0上有一个缓冲区，那么也应该在绑定点0上提供一个缓冲区。 5. **性能优化**：使用可以优化性能，因为它允许开发者一次设置多个资源，然后在多个绘制调用中重用相同的，无需在每次绘制时都重新绑定资源。\n6. **着色器访问**：在着色器代码中，通过绑定点索引访问中的资源。例如，如果一个缓冲区绑定到的绑定点0，那么在着色器中就可以通过定义的绑定点0来访问这个缓冲区。\n7. **命令编码**：在WebGPU的命令编码过程中，被设置到渲染或计算管线上。这样，当管线运行着色器时，它会使用这些绑定的资源。\n举个例子，如果你有一个计算着色器需要两个输入缓冲区和一个输出缓冲区，你会创建一个，在其中绑定这三个缓冲区到指定的绑定点。然后，你可以将这个设置到计算管线上，当计算命令执行时，着色器就可以读取输入缓冲区的数据并将结果写入输出缓冲区。",
    "url": "/blog/理解 webGPU",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 611,
    "endPos": 948,
    "originalTitle": "WebGPU"
  },
  {
    "chunkId": "/blog/理解 webGPU#chunk-3",
    "title": "WebGPU (第4段)",
    "content": "...，着色器就可以读取输入缓冲区的数据并将结果写入输出缓冲区。 总之，是WebGPU中管理和优化资源访问的一种机制，它确保了资源可以被高效地组织和重用，同时为着色器提供了必要的数据和参数。",
    "url": "/blog/理解 webGPU",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 948,
    "endPos": 1010,
    "originalTitle": "WebGPU"
  },
  {
    "chunkId": "/blog/理解Cursor Indexing#chunk-0",
    "title": "LSP（Language Server Protocol）",
    "content": "LSP（Language Server Protocol）\nCursor 是在 **LSP 基础上构建了智能中间层**\nCursor 的 LSP 增强架构\n**1. 传统 LSP 架构**\n**2. Cursor 的增强架构**\n具体的智能处理机制\n**1. 请求预处理（发给 LSP 前）**\n**2. 响应后处理（LSP 返回后）**\n**3. 上下文增强**\n实际优化示例\n**1. 智能补全优化**\n**2. 错误诊断增强**\n**3. 代码导航优化**\n技术实现推测\n**1. 中间件模式**\n**2. 上下文感知**\n这种架构的优势\n**1. 兼容性**：继承了整个 LSP 生态系统\n**2. 可扩展性**：可以为任何支持 LSP 的语言添加 AI 能力",
    "url": "/blog/理解Cursor Indexing",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 335,
    "originalTitle": "LSP（Language Server Protocol）"
  },
  {
    "chunkId": "/blog/理解Cursor Indexing#chunk-1",
    "title": "LSP（Language Server Protocol） (第2段)",
    "content": "...扩展性**：可以为任何支持 LSP 的语言添加 AI 能力 **3. 渐进增强**：即使 AI 层失效，基础 LSP 功能仍然可用\n**4. 性能优化**：智能过滤减少了不必要的信息噪音\nCode Index\n理解从 code index 的建立开始，到 diff code review 可能的流程\n简单例子：一个用户管理系统\n1. **代码结构**\n2. **Code Index 建立过程**\n2.1 **文件内容示例**\n2.2 **Index 建立**\n3. **Diff 出现**\n假设有人修改了 ：\n4. **Diff 分析流程**\n4.1 **解析变更**\n4.2 **查找相关文件**\n4.3 **提取相关代码片段**\n5. **构建 Code Review 上下文**\n最终发送给 AI 的上下文：\njavascript",
    "url": "/blog/理解Cursor Indexing",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 335,
    "endPos": 676,
    "originalTitle": "LSP（Language Server Protocol）"
  },
  {
    "chunkId": "/blog/理解Cursor Indexing#chunk-2",
    "title": "LSP（Language Server Protocol） (第3段)",
    "content": "...文**\n最终发送给 AI 的上下文：\njavascript async register(userData) {\n  return this.userService.createUser(userData); // 需要确保传入的 userData 有 username\n}\njavascript\nasync create(req, res) {\n  const userData = req.body;\n  const user = await this.userService.createUser(userData); // 需要验证前端是否传入 username\n}\njavascript\nstatic create(userData) {",
    "url": "/blog/理解Cursor Indexing",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 676,
    "endPos": 971,
    "originalTitle": "LSP（Language Server Protocol）"
  },
  {
    "chunkId": "/blog/理解Cursor Indexing#chunk-3",
    "title": "LSP（Language Server Protocol） (第4段)",
    "content": "...ipt\nstatic create(userData) { return new User(userData); // 确认 User 模型是否包含 username 字段\n}\n``username.lengthuserData.usernameauthService.registeruserController.create` 都需要确保传入 username\n3. **建议**：\n添加 username 存在性检查\n更新相关的测试用例\n检查前端是否正确传递 username 字段\n总结\n整个流程就是：\n1. **建立索引**：分析代码结构和依赖关系\n2. **解析变更**：识别修改了什么\n3. **查找相关**：从索引中找到相关的文件和函数\n4. **提取片段**：只取相关的代码片段，不是整个文件",
    "url": "/blog/理解Cursor Indexing",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 971,
    "endPos": 1299,
    "originalTitle": "LSP（Language Server Protocol）"
  },
  {
    "chunkId": "/blog/理解Cursor Indexing#chunk-4",
    "title": "LSP（Language Server Protocol） (第5段)",
    "content": "...4. **提取片段**：只取相关的代码片段，不是整个文件 5. **构建上下文**：组装成 AI 能理解的格式进行分析",
    "url": "/blog/理解Cursor Indexing",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1299,
    "endPos": 1329,
    "originalTitle": "LSP（Language Server Protocol）"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-0",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式",
    "content": "压缩稀疏行（Compressed Sparse Row, CSR）格式\n压缩过程\n生成数组\n数组的生成是基于每行非零元素的累积数量来确定的。对于每一行，存储的是第i行第一个非零元素在数组中的起始位置。具体步骤如下：\n1. **初始化数组**：\n创建一个长度为行数加一的数组。额外的一个元素用于标记所有非零元素之后的位置。\n2. **累计每行的非零元素数量**：\n遍历稀疏矩阵，每遇到一个非零元素就增加相应行的非零元素计数。\n3. **填充数组**：\n从第0行开始，累计每行的非零元素计数，并将其存储到数组中。\n具体例子\n假设我们有以下稀疏矩阵A：\n我们生成和数组如下：\n**values**：\n**col_indices**：\n现在生成数组的步骤如下：\n1. **初始化**：",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 0,
    "totalChunks": 9,
    "startPos": 0,
    "endPos": 339,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-1",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第2段)",
    "content": "...s**：\n现在生成数组的步骤如下：\n1. **初始化**： 2. **累计每行的非零元素数量**：\n第0行有2个非零元素（1和2）\n第1行有2个非零元素（3和4）\n第2行有1个非零元素（5）\n第3行有1个非零元素（6）\n3. **填充数组**：\n= 0 （第0行的非零元素起始于）\n=  + 第0行的非零元素数量 = 0 + 2 = 2 （第1行的非零元素起始于）\n=  + 第1行的非零元素数量 = 2 + 2 = 4 （第2行的非零元素起始于）\n=  + 第2行的非零元素数量 = 4 + 1 = 5 （第3行的非零元素起始于）\n=  + 第3行的非零元素数量 = 5 + 1 = 6 （这是所有非零元素之后的位置）\n最终生成的数组为：\n还原过程\n在还原稀疏矩阵时，数组起到重要作用。它帮助我们确定每行非零元素在和中的范围。具体步骤如下：",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 1,
    "totalChunks": 9,
    "startPos": 339,
    "endPos": 681,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-2",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第3段)",
    "content": "...用。它帮助我们确定每行非零元素在和中的范围。具体步骤如下： 1. **初始化还原矩阵**：\n创建一个与原始矩阵A尺寸相同的零矩阵。\n2. **遍历每一行的非零元素**：\n使用数组确定每行的非零元素在和中的起始和结束位置。\n将这些非零元素填充回零矩阵的对应位置。\n具体还原步骤\n假设我们要还原上面的矩阵A：\n1. **初始化还原矩阵**：\n2. **遍历每一行的非零元素**：\n第0行：, \n第1行：, \n第2行：, \n第3行：, \n最终还原的矩阵为：\n是的，除了压缩稀疏行（Compressed Sparse Row, CSR）格式外，还有其他几种常见的稀疏矩阵压缩方法。下面介绍几种常见的方法及其特点：\n其他压缩方法\n1. 压缩稀疏列（Compressed Sparse Column, CSC）",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 2,
    "totalChunks": 9,
    "startPos": 681,
    "endPos": 1001,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-3",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第4段)",
    "content": "...ompressed Sparse Column, CSC） CSC格式与CSR格式类似，但它按列而不是按行存储非零元素。它使用三个数组来存储稀疏矩阵：\n**values**：存储非零元素。\n**row_indices**：存储每个非零元素的行索引。\n**col_pointers**：存储每列的非零元素在数组中的起始位置。\n例子\n对于矩阵A：\n**values**：\n**row_indices**：\n**col_pointers**：\n2. 块稀疏行（Block Compressed Sparse Row, BCSR）\nBCSR格式是CSR格式的扩展，通过将稀疏矩阵划分为固定大小的块来进行压缩。这种方法可以提高存储和计算的局部性，从而提高性能。\n例子\n对于矩阵A：\n可以划分为2x2的块：\n**values**：包含所有块中的非零元素。",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 3,
    "totalChunks": 9,
    "startPos": 1001,
    "endPos": 1343,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-4",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第5段)",
    "content": "...x2的块：\n**values**：包含所有块中的非零元素。 **block_row_ptr**：指示每个块行的起始位置。\n**block_col_ind**：指示每个块列的索引。\n3. 稀疏对角（Diagonal, DIA）\nDIA格式用于对角线为主的稀疏矩阵，通过存储矩阵的对角线来压缩数据。它使用两个数组：\n**values**：存储对角线元素。\n**offsets**：存储每条对角线的偏移。\n例子\n对于矩阵A：\n**values**：\n**offsets**：\n4. 协同存储格式（Coordinate List, COO）\nCOO格式通过存储非零元素的行索引、列索引和对应值来表示稀疏矩阵。它使用三个数组：\n**row_indices**：存储非零元素的行索引。\n**col_indices**：存储非零元素的列索引。",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 4,
    "totalChunks": 9,
    "startPos": 1343,
    "endPos": 1678,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-5",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第6段)",
    "content": "...。\n**col_indices**：存储非零元素的列索引。 **values**：存储非零元素的值。\n例子\n对于矩阵A：\n**row_indices**：\n**col_indices**：\n**values**：\n5. 压缩稀疏块（Compressed Sparse Blocks, CSB）\nCSB格式是一种块压缩格式，适用于具有局部密集块的稀疏矩阵。它将矩阵划分为小块，并仅存储非零块的信息。CSB格式在并行计算中表现良好。\n例子\n假设矩阵A划分为2x2的块：\n只存储含非零元素的块。\n总结\n不同的稀疏矩阵压缩方法适用于不同的应用场景和矩阵结构。选择合适的压缩方法可以大大提高存储效率和计算性能。\n块稀疏行跟 压缩稀疏块 区别\n块稀疏行（BCSR）",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 5,
    "totalChunks": 9,
    "startPos": 1678,
    "endPos": 1975,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-6",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第7段)",
    "content": "...性能。\n块稀疏行跟 压缩稀疏块 区别\n块稀疏行（BCSR） BCSR格式是CSR格式的扩展，通过将稀疏矩阵划分为固定大小的块来进行压缩。它在块级别上存储数据，从而提高存储和计算的局部性。\n例子\n假设我们有以下稀疏矩阵A：\n我们将矩阵A划分为2x2的块：\nBCSR格式会存储这些块中的非零元素及其索引：\n**values**：\n**block_row_ptr**：（每个块行的起始位置）\n**block_col_ind**：（每个块列的索引）\n压缩稀疏块（CSB）\nCSB格式通过将稀疏矩阵划分为大小相等的小块，并仅存储含有非零元素的块。它适用于矩阵具有局部密集块的情况，尤其是在并行计算中表现良好。\n例子\n我们使用相同的矩阵A，并将其划分为2x2的块：\nCSB格式会存储每个非零块及其位置：\n**values**：存储非零块的内容：",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 6,
    "totalChunks": 9,
    "startPos": 1975,
    "endPos": 2312,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-7",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第8段)",
    "content": "...非零块及其位置：\n**values**：存储非零块的内容： **block_indices**：存储每个非零块的位置（块的行和列索引）：\n区别\n1. **数据存储方式**：\n**BCSR**：按固定大小的块存储，适用于较为均匀分布的稀疏矩阵。每行块的起始位置和列索引分别存储在和中。\n**CSB**：按包含非零元素的块存储，适用于具有局部密集块的稀疏矩阵。每个非零块的内容和位置分别存储在和中。\n2. **适用场景**：\n**BCSR**：适用于较为均匀分布的稀疏矩阵，通过块级别的存储优化提高存储和计算的局部性。\n**CSB**：适用于具有局部密集块的稀疏矩阵，在并行计算中表现良好，因为可以独立处理每个块。\n3. **实现复杂度**：\n**BCSR**：相对简单，因为只需处理固定大小的块。",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 7,
    "totalChunks": 9,
    "startPos": 2312,
    "endPos": 2630,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/稀疏矩阵压缩#chunk-8",
    "title": "压缩稀疏行（Compressed Sparse Row, CSR）格式 (第9段)",
    "content": "...：\n**BCSR**：相对简单，因为只需处理固定大小的块。 **CSB**：相对复杂，因为需要动态确定每个非零块的位置和内容。\n具体操作步骤\n**还原BCSR矩阵**：\n根据和确定每个块的位置。\n从中提取每个块的内容，填充到原始矩阵中相应位置。\n**还原CSB矩阵**：\n根据确定每个非零块的位置。\n从中提取每个非零块的内容，填充到原始矩阵中相应位置。",
    "url": "/blog/稀疏矩阵压缩",
    "chunkIndex": 8,
    "totalChunks": 9,
    "startPos": 2630,
    "endPos": 2776,
    "originalTitle": "压缩稀疏行（Compressed Sparse Row, CSR）格式"
  },
  {
    "chunkId": "/blog/视频发展 AI ing#chunk-0",
    "title": "正在编辑....",
    "content": "正在编辑....\n几种生成方式\n已有图片 + 文字描述\n多图片各自短视频生成合并成长视频\n已有视频 + 风格替换\nAI 视频生成发展\nRNN -> GAN -> 自回归(transformer) -> diffusion -> sora/V-JEPA\nRNN：循环神经网络，是一种能够处理序列数据的神经网络结构，可以捕捉视频帧之间的时间依赖关系，生成连续的视频序列。RNN的代表模型有LSTM、GRU等。\nGAN：生成对抗网络，是一种无监督的生成模型框架，通过让两个神经网络相互博弈来进行机器学习。GAN可以生成视觉逼真度高的视频，但控制难度大、时序建模较弱。GAN的代表模型有DCGAN、WGAN、Pix2Pix、PatchGAN等。",
    "url": "/blog/视频发展 AI ing",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 319,
    "originalTitle": "正在编辑...."
  },
  {
    "chunkId": "/blog/视频发展 AI ing#chunk-1",
    "title": "正在编辑.... (第2段)",
    "content": "...DCGAN、WGAN、Pix2Pix、PatchGAN等。 自回归（transformer）：自回归模型是一种基于概率的生成模型，可以根据已有的数据预测下一个数据的概率分布。自回归模型可以实现细粒度语义控制，时序建模能力强，但计算量大。自回归模型的代表模型有Transformer、BART、GPT等。\ndiffusion ：扩散模型是一种基于能量最小化的生成模型，可以将数据从高维空间扩散到低维空间，再从低维空间还原到高维空间。扩散模型可以生成高质量、高分辨率的视频，但生成速度慢。扩散模型的代表模型有DDPM、DVAE、Score-based等。 \ndVAE 的基本思想是，首先使用 VAE 将原始数据编码成离散的潜在变量，然后使用扩散模型将潜在变量逐步加入噪声，最后使用逆向过程从噪声中重建潜在变量和原始数据",
    "url": "/blog/视频发展 AI ing",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 319,
    "endPos": 647,
    "originalTitle": "正在编辑...."
  },
  {
    "chunkId": "/blog/视频发展 AI ing#chunk-2",
    "title": "正在编辑.... (第3段)",
    "content": "...步加入噪声，最后使用逆向过程从噪声中重建潜在变量和原始数据 sora/V-JEPA：sora是一种基于扩散模型的视频生成方法，可以从文本生成视频，具有高效、稳定、可控的特点。V-JEPA是一种基于自回归模型的视频生成方法，可以从图片生成视频，具有高质量、高分辨率、高连贯性的特点。\nV-JEPA 是一种视频自监督学习的方法，它可以通过观看视频来学习视觉表示。它的特征预测方法是，让模型能够预测视频中一个区域（称为目标区域y）的特征表示，这个预测基于另一个区域（称为源区域x）的特征表示。这样，模型可以学习视频中不同时间步骤之间的语义关系，以及视频中的高级概念信息。\nSora\nSora 架构\n什么是 Patches？ - ViT\n为什么可以做到多种分辨率？- 动态分辨率 NaViT 多尺寸分辨率训练及特征融合训练",
    "url": "/blog/视频发展 AI ing",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 647,
    "endPos": 975,
    "originalTitle": "正在编辑...."
  },
  {
    "chunkId": "/blog/视频发展 AI ing#chunk-3",
    "title": "正在编辑.... (第4段)",
    "content": "...- 动态分辨率 NaViT 多尺寸分辨率训练及特征融合训练 视频数据怎么提取 patches？- 空间 patches - ViViT - 针对视频数据 patches 提取\n主体架构？ -扩散 transformer - Dit - UNet 采用归纳偏置保持空间局部性和平移等边性，transformer 逐步学习更远像素点\n提示词是否优化？- 提示词扩写 - GPT4",
    "url": "/blog/视频发展 AI ing",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 975,
    "endPos": 1132,
    "originalTitle": "正在编辑...."
  },
  {
    "chunkId": "/blog/语言是交流工具而不是思维工具#chunk-0",
    "title": "理论",
    "content": "理论\nMIT的这篇论文通过详细的实验和案例研究，挑战了语言是思维基础的传统观点，为人工智能的发展提供了新的思路。未来的AI研究可能需要更多地关注非语言形式的数据和方法，探索语言之外的思维形式。这不仅为大语言模型的改进提供了新的方向，也为实现更强大、更智能的人工智能系统奠定了基础。\nas a powerful tool for transmitting knowledge, language reflects the sophistication of human cognition — but does not give rise to it. \nReference\nlanguage-is-a-tool-for-communication-not-for-thought",
    "url": "/blog/语言是交流工具而不是思维工具",
    "chunkIndex": 0,
    "totalChunks": 2,
    "startPos": 0,
    "endPos": 340,
    "originalTitle": "理论"
  },
  {
    "chunkId": "/blog/语言是交流工具而不是思维工具#chunk-1",
    "title": "理论 (第2段)",
    "content": "...communication-not-for-thought hacker news\n中文翻译",
    "url": "/blog/语言是交流工具而不是思维工具",
    "chunkIndex": 1,
    "totalChunks": 2,
    "startPos": 340,
    "endPos": 356,
    "originalTitle": "理论"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-0",
    "title": "软件2.0",
    "content": "软件2.0\n原文\n概念：软件2.0通常指的是那些在其核心集成了机器学习模型的软件系统。这些系统的行为不仅仅是由传统的编程代码决定的，而是由数据驱动的模型生成的。\n以下是对文章一些观点的理解\n融合模块以求最优\nModules can meld into an optimal whole\n>原文：普通软件通常被分解成多个模块，各个模块中间通过共有函数、API 或者端到端的方式通信。然而，对于软件2.0，如果一开始2个相交互的模块是独立训练的，我们之后也很容易在整个系统中进行反向传播。想想看，如果你的浏览器可以自动设计底层指令，从而提高加载页面的速度；或者说你导入的计算机视觉库（比如 OpenCV）可以根据你的特定数据，自动调整行为；\n理解：",
    "url": "/blog/软件 2.0",
    "chunkIndex": 0,
    "totalChunks": 11,
    "startPos": 0,
    "endPos": 323,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-1",
    "title": "软件2.0 (第2段)",
    "content": "...OpenCV）可以根据你的特定数据，自动调整行为；\n理解： 软件2.0指的是那些利用机器学习模型作为其核心组件的软件系统。关键特点是它能够通过收集数据和反向传播来持续学习和自我优化。这种方式**使得软件能够更加智能和适应性强，因为它不再是静态的代码集合，而是一个能够随着时间和数据的积累而变得更加高效的动态系统。**\n举例：\n1. **浏览器自动设计底层指令：**",
    "url": "/blog/软件 2.0",
    "chunkIndex": 1,
    "totalChunks": 11,
    "startPos": 323,
    "endPos": 476,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-2",
    "title": "软件2.0 (第3段)",
    "content": "...系统。**\n举例：\n1. **浏览器自动设计底层指令：** 在这个例子中，我们可以想象一个浏览器，它不仅仅是静态地执行预定义的指令来加载页面。相反，它具备了通过机器学习来优化这些指令的能力。例如，浏览器可以监控用户的上网习惯、页面加载时间、系统资源使用情况等数据，并且使用这些数据来训练一个模型，这个模型能够预测并调整底层的网络请求、资源分配策略，甚至是JavaScript引擎的工作方式，以提高页面加载的速度。这种优化是动态进行的，能够适应不同用户的使用环境和习惯。\n2. **计算机视觉库自动调整行为：**",
    "url": "/blog/软件 2.0",
    "chunkIndex": 2,
    "totalChunks": 11,
    "startPos": 476,
    "endPos": 705,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-3",
    "title": "软件2.0 (第4段)",
    "content": "...使用环境和习惯。\n2. **计算机视觉库自动调整行为：** 在另一个例子中，传统的计算机视觉库，比如OpenCV，提供了一系列预定义的算法和函数来处理图像和视频数据。在软件2.0的情况下，这些库可以进一步智能化。假设你正在使用这样的库来进行面部识别，库本身可以包含一个或多个机器学习模型，这些模型可以根据你提供的特定数据（比如，你的应用中的用户面部图像）自动调整其内部参数。这样，面部识别的准确性不仅仅取决于通用算法，还取决于它如何通过学习特定的数据集来自我优化。\n对抗样本导致软件 2.0 异常\n>原文：软件2.0的奇怪特性也在不断出现。比如，对抗样本和攻击样本的存在，使得软件2.0的不可解释性问题变得更加突出。\n理解：",
    "url": "/blog/软件 2.0",
    "chunkIndex": 3,
    "totalChunks": 11,
    "startPos": 705,
    "endPos": 991,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-4",
    "title": "软件2.0 (第5段)",
    "content": "...存在，使得软件2.0的不可解释性问题变得更加突出。\n理解： 对抗样本是经过特别设计的输入数据，它们对人类来说可能看起来和正常数据没有区别，但是能够欺骗机器学习模型，使其做出错误的预测或分类。这些情况突出了软件2.0的不可解释性问题，因为即使是模型的开发者也很难完全理解或解释为什么模型会被这些对抗样本所欺骗。这种不可解释性不仅挑战了模型的可靠性，也给安全性带来了风险，尤其是在那些对精确性和可靠性有着极高要求的应用场景中。\n例如：\n1. **自动驾驶汽车：**\n   在自动驾驶汽车中，使用了大量的机器学习模型来处理视觉识别任务，例如识别交通标志。一个对抗样本的例子可能是一个轻微修改过的停车标志，虽然对于人类来说这个标志看起来没有任何问题，但是修改可能会导致自动驾驶系统无法正确识别这个标志，从而可能忽略停车指令，引发安全问题。\n2. **面部识别系统：**",
    "url": "/blog/软件 2.0",
    "chunkIndex": 4,
    "totalChunks": 11,
    "startPos": 991,
    "endPos": 1342,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-5",
    "title": "软件2.0 (第6段)",
    "content": "...忽略停车指令，引发安全问题。\n2. **面部识别系统：** 在安全性要求高的面部识别系统中，对抗样本可能是经过精心设计的图像或者是特定的化妆或配饰，这些对于人眼来说不会影响识别，但可能会导致面部识别系统无法正确识别或者将一个人错误地识别为另一个人。\n理解 1.0 vs 2.0\n软件 1.0\n**模块演化**\n初始：单一大型服务（单体架构）。\n演化：服务分解为小型、独立的模块，这些模块相互配合工作（微服务架构）。\n**设计哲学：** 基于规则的编程，开发者需要手动编写代码来明确规定软件的每一步行为。\n**开发方式：** 往往是水平式的，需要事先规划架构和未来可能的扩展点。\n**更新迭代：** 更新通常涉及整个系统的重新部署或至少是较大模块的重新部署。\n**可解释性：** 高，因为行为是由清晰的代码逻辑决定的。",
    "url": "/blog/软件 2.0",
    "chunkIndex": 5,
    "totalChunks": 11,
    "startPos": 1342,
    "endPos": 1674,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-6",
    "title": "软件2.0 (第7段)",
    "content": "...**可解释性：** 高，因为行为是由清晰的代码逻辑决定的。 **示例：** 传统的ERP系统，银行交易系统等，这些系统都是具有固定逻辑和复杂业务规则的系统。\n软件 2.0\n**模块演化** \n初始：独立的专用模型完成各自的任务，然后将结果整合（如多个单独的模型串联处理任务）。\n演化：单个端到端模型直接处理整个任务，没有中间转换步骤（如一个模型同时处理语音识别、自然语言理解和语音合成）。\n**设计哲学：** 基于数据和学习的编程，软件通过对大量数据进行学习来自我优化和改进，而非仅仅依据预编程的规则。\n**开发方式：** 往往是垂直式的，能够从数据中自主学习并适应新任务，不需要开发者预见到每一种可能。\n**更新迭代：** 在很多情况下，模型可以通过持续学习实现自我更新而无需人为干预。\n**可解释性：** 相对较低，因为模型决策过程复杂且不总是透明的。",
    "url": "/blog/软件 2.0",
    "chunkIndex": 6,
    "totalChunks": 11,
    "startPos": 1674,
    "endPos": 2023,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-7",
    "title": "软件2.0 (第8段)",
    "content": "...释性：** 相对较低，因为模型决策过程复杂且不总是透明的。 **示例：** 机器学习驱动的推荐系统（如YouTube或Netflix的推荐算法），自然语言处理系统（如GPT-3），自动驾驶车辆。\n软件1.0更倾向于模块化和微服务架构，其设计是为了解决特定的、已知的问题而构建的。而软件2.0则向着使用数据驱动的方法，通过端到端的模型自动学习解决问题，这常涉及人工智能和机器学习特别是深度学习领域。\n水平跟垂直式开发\n水平式开发（Software 1.0）\n水平式开发通常指的是传统的软件开发过程，这里的\"水平\"可以类比于搭建房屋的每一层。这种方法的特点包括：\n**层次结构**：软件以层的形式构建，每一层依赖于下面的一层。比如，用户界面层依赖于业务逻辑层，而业务逻辑层则依赖于数据访问层。\n**模块化**：系统被分解为功能模块，每个模块负责特定的功能或服务。",
    "url": "/blog/软件 2.0",
    "chunkIndex": 7,
    "totalChunks": 11,
    "startPos": 2023,
    "endPos": 2373,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-8",
    "title": "软件2.0 (第9段)",
    "content": "...**：系统被分解为功能模块，每个模块负责特定的功能或服务。 **规划先行**：在开发之前需要详尽的规划，了解系统所有层和模块如何相互作用。\n**硬编码**：逻辑是通过编写具体的代码指令来实现的，对于新的问题和需求通常需要开发人员手动进行修改和更新。\n垂直式开发（Software 2.0）\n垂直式开发则更多地与数据驱动的机器学习方法相联系，\"垂直\"可以类比于从基础设施一直向上生长的树木。这种方法的特点包括：\n**端到端学习**：任务从输入到输出通过一个端到端的系统来完成，没有必须人为编写的规则。\n**数据为中心**：系统主要通过分析和学习大量数据来获得知识和解决问题的能力。\n**动态适应**：系统可以不断从新的数据中学习，从而适应新的问题和场景。\n**自主性**：因为模型可以自我学习，所以对于未知问题的适应性强，这减少了人工编写代码的需要。",
    "url": "/blog/软件 2.0",
    "chunkIndex": 8,
    "totalChunks": 11,
    "startPos": 2373,
    "endPos": 2718,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-9",
    "title": "软件2.0 (第10段)",
    "content": "...，所以对于未知问题的适应性强，这减少了人工编写代码的需要。 在机器学习（尤其是深度学习）中，垂直式的发展体现在从底层特征直接学习到高层的决策，而无需人类专家制定复杂的规则或者手动设计特征。\n总体来说，水平式开发注重于开发者明确规划各个模块的交互和功能，而垂直式开发依赖于从数据中自动学习模式和规律，这样的系统通常能自适应未见过的数据或情况。\nIlya 推荐的 30 篇\n(30篇论文，就能掌握当今科技90%的知识！ILYA公布神级论文清单(上）)[https://mp.weixin.qq.com/s?__biz=Mzk0NzQzOTczOA%3D%3D&mid=2247507514&idx=3&sn=6f90564bb8a07f39d360aec1968e6b14&ref=openi.cn]",
    "url": "/blog/软件 2.0",
    "chunkIndex": 9,
    "totalChunks": 11,
    "startPos": 2718,
    "endPos": 3037,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/软件 2.0#chunk-10",
    "title": "软件2.0 (第11段)",
    "content": "...360aec1968e6b14&ref=openi.cn] (下)[https://mp.weixin.qq.com/s?__biz=Mzk0NzQzOTczOA==&mid=2247507451&idx=1&sn=d586514585870f4e3205199a8f6f2f5f&chksm=c3744ceef403c5f883ea5a495e58764ffa57cbf7a7c5c0fa30b4493057f58ef288774b0768a4&scene=21#wechat_redirect]\nReference\n翻译 颠覆式编程：软件2.0\n视频：大模型解决不了英伟达的难题，AI新范式必将出现：专访安克创新CEO阳萌",
    "url": "/blog/软件 2.0",
    "chunkIndex": 10,
    "totalChunks": 11,
    "startPos": 3037,
    "endPos": 3320,
    "originalTitle": "软件2.0"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-0",
    "title": "逆变换采样",
    "content": "逆变换采样\n逆变换采样（Inverse Transform Sampling）是一种用于从任意概率分布中抽样的方法。它的基本思想是利用均匀分布的样本生成符合目标分布的样本。这个过程基于目标分布的累积分布函数（CDF，Cumulative Distribution Function）和逆累积分布函数（Inverse CDF，或Quantile Function）。\n1. 基本步骤\n**步骤1：从均匀分布中抽样**\n首先，从均匀分布 \\(U(0, 1)\\) 中抽取样本。均匀分布意味着每个数字在0到1之间出现的概率相等。\n**步骤2：计算逆变换**\n使用目标分布的逆累积分布函数（Inverse CDF）将从均匀分布中抽取的样本转换为符合目标分布的样本。\n2. 示例：从指数分布中抽样",
    "url": "/blog/逆变换采样",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 343,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-1",
    "title": "逆变换采样 (第2段)",
    "content": "...本转换为符合目标分布的样本。\n2. 示例：从指数分布中抽样 假设我们想从指数分布中抽样。指数分布的概率密度函数（PDF）和累积分布函数（CDF）分别如下：\n概率密度函数（PDF）：\n$$f(x; \\lambda) = \\lambda e^{-\\lambda x} $$\n累积分布函数（CDF）：\n$$F(x; \\lambda) = 1 - e^{-\\lambda x} $$\n对于指数分布：\n**累积分布函数（CDF）** \\(F(x)\\) 给出了 \\(X\\) 小于或等于某个值的概率。\n**逆累积分布函数（Inverse CDF）** \\($F^{-1}(p)$\\)，其中 \\($p \\in [0, 1]$\\)，给出了一个概率值对应的下限。\n对于指数分布，其逆累积分布函数可以通过解以下方程得到：\n$$p = 1 - e^{-\\lambda x} $$",
    "url": "/blog/逆变换采样",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 343,
    "endPos": 691,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-2",
    "title": "逆变换采样 (第3段)",
    "content": "...：\n$$p = 1 - e^{-\\lambda x} $$ 将这个等式解为 \\(x\\)：\n$$x = -\\frac{1}{\\lambda} \\ln(1 - p) $$\n这里 \\(p\\) 是从均匀分布 \\( U(0, 1) \\) 中抽取的样本。\n3. 逆变换采样的步骤\n**步骤1：从均匀分布 \\(U(0, 1)\\) 中抽样**\n假设我们抽取 \\(p = 0.5\\) （任何介于0和1之间的均匀随机数）。\n**步骤2：计算逆变换**\n针对特定的 \\(\\lambda\\) 值（假设 \\(\\lambda = 1\\)），我们使用逆累积分布函数 \\(F^{-1}(p)\\) 来转换 \\(p\\)：\n$$x = -\\frac{1}{1} \\ln(1 - 0.5) = - \\ln(0.5) \\approx 0.693 $$",
    "url": "/blog/逆变换采样",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 691,
    "endPos": 1016,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-3",
    "title": "逆变换采样 (第4段)",
    "content": "...= - \\ln(0.5) \\approx 0.693 $$ 所以，使用逆变换采样，我们得到了一个符合指数分布的样本 \\(x \\approx 0.693\\)。\nBox-Muller\nBox-Muller 通过角度和半径大小两个分量的独立性分别单独生成并转换成 (x, y) 对。\n无法直接通过逆变换生成一维正态分布的主要原因是正态分布的累积分布函数 (CDF) 没有解析形式，这使得逆变换方法不太实用。\nbox-muller 数学推导\n什么样的函数没有解析形式？\n没有解析形式的函数是指无法通过有限个基本函数（如多项式、指数函数、对数函数、三角函数等）的代数运算和复合运算来表示其精确值的函数。换句话说，这些函数无法用一组封闭形式的表达式来表示，通常需要以数值方法、级数展开或图形来近似表示或解析。\n以下是一些常见的没有解析形式的函数类型：\n1. 特殊函数",
    "url": "/blog/逆变换采样",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 1016,
    "endPos": 1364,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-4",
    "title": "逆变换采样 (第5段)",
    "content": "...以下是一些常见的没有解析形式的函数类型：\n1. 特殊函数 许多特殊函数通常没有简单的解析形式。例如：\n**误差函数（Error Function, \\(\\operatorname{erf}(x)\\)）**：这是一个出现在概率、统计和偏微分方程中的常见函数。虽然它有定义和性质，但无法用基本初等函数的有限组合表示。\n  $$\n  \\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} \\, dt\n  $$\n2. 隐函数\n隐函数是通过多个变量间的关系定义的，并且无法显式解出。例如：\n**兰伯特 \\(W\\) 函数**：通过关系 \\(We^W = x\\) 定义。对于大多数 \\(x\\) 它没有闭式表达。\n**指数方程**：例如 \\(x = e^{-x}\\)，无法通过代数方法得到显式解。",
    "url": "/blog/逆变换采样",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1364,
    "endPos": 1712,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-5",
    "title": "逆变换采样 (第6段)",
    "content": "...\\(x = e^{-x}\\)，无法通过代数方法得到显式解。 3. 特定的无理或超越方程\n在某些情况下，无法解析地表达某些无理或者超越方程的解。举个例子：\n**代数方程级数解**：如一般五次及更高次多项式的根，根据阿贝尔-鲁芬尼定理，无法用根式表示。\n4. 特定积分\n一些积分无法通过单一的基本函数或其简单组合进行表达。例如：\n**椭圆积分**：这些积分经常出现于物理学和工程学中，并不能通过基本函数的具体表达来表示。\n$$\nE(x) = \\int_0^x \\sqrt{1 - t^2} \\, dt\n$$\n5. 特定微分方程的解\n某些微分方程具有解，但这些解不能以初等函数的形式表达。例如：",
    "url": "/blog/逆变换采样",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1712,
    "endPos": 1977,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/逆变换采样#chunk-6",
    "title": "逆变换采样 (第7段)",
    "content": "...些微分方程具有解，但这些解不能以初等函数的形式表达。例如： **艾里函数（Airy function, \\(\\operatorname{Ai}(x)\\) 和 \\(\\operatorname{Bi}(x)\\)）**：这些函数出现在量子力学和光学等领域中，经常用来描述某些物理现象。\n  $$\n  \\frac{d^2y}{dx^2} - xy = 0 \n  $$\n总结\n总体而言，当函数的定义涉及复杂的代数运算、特定的积分、微分方程的解，或者当它们的定义关系本质上是隐含的，这些函数往往没有简单的解析形式。现代数学中，尽管没有解析形式，但我们可以通过数值方法、级数展开或其他方法对它们进行近似分析和计算。这对实用计算和理论研究都是非常重要的。",
    "url": "/blog/逆变换采样",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1977,
    "endPos": 2266,
    "originalTitle": "逆变换采样"
  },
  {
    "chunkId": "/blog/Go简介#chunk-0",
    "title": "Goroutine",
    "content": "Goroutine\nGoroutine 可以看作对 thread 加的一层抽象，它更轻量级，可以单独执行。因为有了这层抽象，Gopher 不会直接面对 thread。\nGoroutine vs threads \n内存占用\n1. 创建一个 goroutine 的栈内存消耗为 2 KB，实际运行过程中，如果栈空间不够用，会自动进行扩容。创建一个 thread 则需要消耗 1 MB 栈内存，而且还需要一个被称为 “a guard page” 的区域用于和其他 thread 的栈空间进行隔离。",
    "url": "/blog/Go简介",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 246,
    "originalTitle": "Goroutine"
  },
  {
    "chunkId": "/blog/Go简介#chunk-1",
    "title": "Goroutine (第2段)",
    "content": "...ge” 的区域用于和其他 thread 的栈空间进行隔离。 2. 对于一个用 Go 构建的 HTTP Server 而言，对到来的每个请求，创建一个 goroutine 用来处理是非常轻松的一件事。而如果用一个使用线程作为并发原语的语言构建的服务，例如 Java 来说，每个请求对应一个线程则太浪费资源了，很快就会出 OOM 错误（OutOfMermoryError）。\n创建和销毀\n1. Thread 创建和销毀都会有巨大的消耗，因为要和操作系统打交道，是内核级的，通常解决的办法就是线程池。\n2. 而 goroutine 因为是由 Go runtime 负责管理的，创建和销毁的消耗非常小，是用户级。\n切换\n1. 当 threads 切换时，需要保存各种寄存器，以便将来恢复：",
    "url": "/blog/Go简介",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 246,
    "endPos": 557,
    "originalTitle": "Goroutine"
  },
  {
    "chunkId": "/blog/Go简介#chunk-2",
    "title": "Goroutine (第3段)",
    "content": "...threads 切换时，需要保存各种寄存器，以便将来恢复： 一般而言，线程切换会消耗 1000-1500 纳秒，一个纳秒平均可以执行 12-18 条指令。所以由于线程切换，执行指令的条数会减少 12000-18000。\n2. Goroutine 的切换约为 200 ns，相当于 2400-3600 条指令。\n因此，goroutines 切换成本比 threads 要小得多。\nscheduler (M:N模型)\nGo runtime 会负责 goroutine 的生老病死，从创建到销毁，都一手包办。\nRuntime 会在程序启动的时候，创建 M 个线程（CPU 执行调度的单位），之后创建的 N 个 goroutine 都会依附在这 M 个线程上执行。这就是 M:N 模型\n什么是scheduler？\n!scheduler-concepts",
    "url": "/blog/Go简介",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 557,
    "endPos": 900,
    "originalTitle": "Goroutine"
  },
  {
    "chunkId": "/blog/Go简介#chunk-3",
    "title": "Goroutine (第4段)",
    "content": "...cheduler？\n!scheduler-concepts scheduler时机\n1. 使用关键字 go\ngo创建一个新的 goroutine\n2. GC\nGC 需要在M 上进行所以会调度\n3. 系统调用\n4. 内存同步访问\natomic, mutex, channel 等操作\nReference\ngo practice\nhttps://golangbot.com/goroutines/\nhttps://rakyll.org/scheduler/\nhttps://blog.nindalf.com/posts/how-goroutines-work/\nhttps://speakerdeck.com/retervision/go-runtime-scheduler?slide=27\nhttps://povilasv.me/go-scheduler/#",
    "url": "/blog/Go简介",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 900,
    "endPos": 1250,
    "originalTitle": "Goroutine"
  },
  {
    "chunkId": "/blog/Go简介#chunk-4",
    "title": "Goroutine (第5段)",
    "content": "...://povilasv.me/go-scheduler/# https://morsmachine.dk/netpoller\nhttps://morsmachine.dk/go-scheduler\nhttps://golangbot.com/structs-instead-of-classes/\nhttps://zhuanlan.zhihu.com/p/80853548",
    "url": "/blog/Go简介",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1250,
    "endPos": 1406,
    "originalTitle": "Goroutine"
  },
  {
    "chunkId": "/blog/JSON序列化#chunk-0",
    "title": "JSON序列化",
    "content": "问：easyjson 跟 golang 原生 JSON 方法对比\neasyjson是一个用于快速进行json序列化和反序列化的工具包，它通过为结构体生成方法来避免使用反射，从而提高性能和效率。\n与golang原生的json方法相比，easyjson的性能可以提高2～3倍。\neasyjson的使用方法是先安装它，然后为需要序列化的结构体添加注释，然后运行easyjson命令生成对应的解析代码。\n问： 一些easyjson的优缺点？\n答：easyjson的优点是：\n它可以提高json序列化和反序列化的性能和效率，比golang原生的json方法快2～3倍。\n它可以避免使用反射，从而减少内存分配和GC压力。\n它可以通过注释和命令行工具自动生成解析代码，使用方便。\neasyjson的缺点是：",
    "url": "/blog/JSON序列化",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 347,
    "originalTitle": "JSON序列化"
  },
  {
    "chunkId": "/blog/JSON序列化#chunk-1",
    "title": "JSON序列化 (第2段)",
    "content": "...具自动生成解析代码，使用方便。\neasyjson的缺点是： 它不会校验json的正确性，可能导致解析错误或异常。\n它的代码风格可能不太优雅，有些重复或冗余。\n它需要为每个解析字段指定FieldTag，否则会使用变量名作为解析字段2。\n问：easyjson 是什么原理\n答：\n它通过给我们要进行序列化的 struct 生成方法来实现不通过反射进行json序列化。\n它只针对预先定义好的 json 结构体对输入的json字符串进行纯字符串的截取，并将对应的json字段赋值给结构体。\n它提供了代码生成工具，可以一键生成go文件中定义的结构体对应的解析代码。\n问：举个例子\n答：\n好的，我可以给你一些示例代码来说明 easyjson 跟 golang 自带 JSON 工具的不同。\n假设我们有一个结构体如下：",
    "url": "/blog/JSON序列化",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 347,
    "endPos": 669,
    "originalTitle": "JSON序列化"
  },
  {
    "chunkId": "/blog/JSON序列化#chunk-2",
    "title": "JSON序列化 (第3段)",
    "content": "...自带 JSON 工具的不同。\n假设我们有一个结构体如下： 如果我们使用 golang 自带的 JSON 工具，我们可以这样序列化和反序列化：\n如果我们使用 easyjson，我们需要先安装 easyjson 工具：\n然后在结构体上加上注释 ，并使用命令  生成对应的序列化和反序列化方法：\n生成的方法会在一个新的文件  中，我们可以这样使用：\n从这些示例代码中，我们可以看到 easyjson 跟 golang 自带 JSON 工具的不同。\n***通过 GPT 生成***",
    "url": "/blog/JSON序列化",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 669,
    "endPos": 876,
    "originalTitle": "JSON序列化"
  },
  {
    "chunkId": "/blog/napi 宏的理解#chunk-0",
    "title": "napi 宏的理解",
    "content": "napi 宏的理解\n宏与 DSL\nRust 宏的核心之一是通过生成代码来简化重复任务，而 DSL（领域专用语言）则是在宏的帮助下，为特定领域问题设计的一种更易读、易用的语法。通过宏，可以把 Rust 的代码变得像定制的小语言一样，让开发者专注于问题本身，而不是细节的实现。\n以下是几个示例，展示如何用 Rust 宏构建 DSL：\n示例 2：构建命令行解析器 DSL\n以下宏提供了一种简化命令行参数解析的 DSL：\n**运行示例：**\n**分析：**\n通过  宏定义命令行参数的格式和类型。\n用户只需描述参数，而无需手动解析或处理错误。\n---\n示例 3：实现状态机 DSL\n以下宏用来定义一个简单的有限状态机：\n**输出：**\n**分析：**\n通过  宏，用户可以简单地定义状态和转移规则。",
    "url": "/blog/napi 宏的理解",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 346,
    "originalTitle": "napi 宏的理解"
  },
  {
    "chunkId": "/blog/napi 宏的理解#chunk-1",
    "title": "napi 宏的理解 (第2段)",
    "content": "...分析：**\n通过  宏，用户可以简单地定义状态和转移规则。 宏将 DSL 编译成 Rust 代码，完成状态机的实现。\n代码清晰且具有实际用途。\n---\n总结\nRust 宏在构建 DSL 时具有以下优点：\n1. **可读性**：用自然的语法描述特定领域的规则，用户无需了解底层实现。\n2. **简化代码**：减少样板代码，专注于核心逻辑。\n3. **强类型保障**：结合 Rust 的类型系统，确保生成代码的安全性。\n这些 DSL 示例涵盖了 HTML 构建、命令行解析和状态机定义，是 Rust 宏在领域专用语言设计中的常见用法。\n手写实现\n下面是之前手写的简化实现版本，并为其添加了详细注释，帮助理解各部分的功能和逻辑：\n---\n**逐步拆解注释说明**\n**1. 模块入口点 ()**\n这是 Rust 编写的 N-API 模块的入口点。",
    "url": "/blog/napi 宏的理解",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 346,
    "endPos": 689,
    "originalTitle": "napi 宏的理解"
  },
  {
    "chunkId": "/blog/napi 宏的理解#chunk-2",
    "title": "napi 宏的理解 (第3段)",
    "content": "...*\n这是 Rust 编写的 N-API 模块的入口点。 Node.js 在加载  文件时，会查找并调用这个函数。\n关键参数：\n：当前 N-API 的上下文，保存模块运行时的状态。\n：代表模块的导出对象，相当于 Node.js 中的 。\n函数作用：\n注册模块的所有导出方法，并将它们绑定到 。\n---\n**2. 注册函数 ()**\n这个部分通过  创建一个符合 N-API 标准的函数。\n的关键参数：\n：N-API 环境上下文。\n：JavaScript 中函数的名字。\n：指向 Rust 中实际的函数实现。\n---\n**3. 函数实现 ()**\n这是具体的 Rust 函数逻辑，通过 FFI 暴露给 Node.js 调用。\n参数解析：\n使用  获取传递给函数的参数，期望两个参数。\n每个参数需要用  解析并转换为 Rust 类型。\n结果处理：",
    "url": "/blog/napi 宏的理解",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 689,
    "endPos": 1032,
    "originalTitle": "napi 宏的理解"
  },
  {
    "chunkId": "/blog/napi 宏的理解#chunk-3",
    "title": "napi 宏的理解 (第4段)",
    "content": "...个参数需要用  解析并转换为 Rust 类型。\n结果处理： 计算两个整数的和。\n使用  创建一个 JavaScript 的数值对象，将结果返回给调用者。\n---\n**调用链的工作流程**\n1. Node.js 加载  文件时，调用 。\n2.  使用  创建函数并将其绑定到模块的导出对象。\n3. 在 JavaScript 中调用 ，会触发  函数的执行：\n获取参数。\n调用 Rust 函数。\n将结果转换为 JavaScript 类型并返回。\n---\n**优缺点对比**\n**优点：**\n直接操作 N-API，可以完全控制模块行为。\n适用于需要手动优化性能或有特殊需求的场景。\n**缺点：**\n编写 N-API 代码繁琐且容易出错。\n需要处理参数解析、类型转换、错误管理等大量细节。\n难以维护，代码量大。\n---\n**总结**",
    "url": "/blog/napi 宏的理解",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 1032,
    "endPos": 1365,
    "originalTitle": "napi 宏的理解"
  },
  {
    "chunkId": "/blog/napi 宏的理解#chunk-4",
    "title": "napi 宏的理解 (第5段)",
    "content": "...理等大量细节。\n难以维护，代码量大。\n---\n**总结** 手写实现展示了 Rust 和 Node.js 交互的基础，但在实际项目中，推荐使用类似  宏来简化开发。属性宏会自动生成上述复杂逻辑，让开发者专注于核心功能。\n参考资料\ngpt",
    "url": "/blog/napi 宏的理解",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1365,
    "endPos": 1453,
    "originalTitle": "napi 宏的理解"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-0",
    "title": "rust Arena内存分配",
    "content": "Arena\n在 Rust 中， 是一种内存分配策略，主要用于高性能场景中高效地分配和管理一组对象。相比 、、 和  等智能指针， 的优势在于它可以集中管理对象的内存，从而避免频繁的分配与释放操作。\n什么是 Arena？\n（内存池）是一种分配器，通过在一块连续的内存区域中分配多个对象来提升性能。这些对象的生命周期与  本身绑定。当释放  时，所有分配的对象会统一释放，无需逐一销毁。\nRust 的一些库（如 [](https://crates.io/crates/typed-arena)、[](https://crates.io/crates/bumpalo)）提供了  的实现。\n2. **短生命周期的高性能批量分配**",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 0,
    "totalChunks": 14,
    "startPos": 0,
    "endPos": 313,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-1",
    "title": "rust Arena内存分配 (第2段)",
    "content": "...供了  的实现。\n2. **短生命周期的高性能批量分配** 当程序需要频繁创建并销毁对象，且这些对象的生命周期较短时， 可以避免频繁调用系统内存分配器，提高性能。\n**示例：批量计算临时对象**\n**优势**：\n分配性能优于堆分配（如 ）。\n对象销毁集中在  的生命周期结束时，减少了单个对象的析构开销。\n---\n3. **多对象共享管理，替代 /**\n当多个对象需要共享同一批数据时，使用  可以避免  或  的引用计数开销。\n**示例：共享数据结构**\n**优势**：\n统一管理节点的内存，避免循环引用。\n不需要手动清理，生命周期简单。\n---\n4. **需要快速分配和清理的大量小对象**\n对于游戏开发或其他需要频繁更新大量小对象的场景（如粒子系统、实体管理）， 可以显著提升分配和清理性能。\n**示例：粒子系统**\n**优势**：",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 1,
    "totalChunks": 14,
    "startPos": 313,
    "endPos": 653,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-2",
    "title": "rust Arena内存分配 (第3段)",
    "content": "...升分配和清理性能。\n**示例：粒子系统**\n**优势**： 避免了频繁的分配和释放，尤其是在帧更新频繁的场景中。\n更高的缓存命中率。\n智能指针 vs arena\n虽然  确实在某些场景下具有显著优势，但它并不是万能的工具，也不适合所有场景。使用  需要权衡以下几个关键点：\n---\n1. **生命周期绑定的限制**\n 的核心理念是将分配的对象生命周期绑定到  自身。这带来了两个问题：\n**无法灵活控制对象的释放时间**：对象的内存只能在整个  被销毁时统一释放，无法提前释放单个对象。如果你的场景需要精细控制对象的生命周期（比如按需释放某些资源）， 就不合适。\n**容易造成内存浪费**：如果  存在一些对象长时间不被使用，而  本身又不能销毁，这些对象占用的内存会被浪费。\n---\n2. **对象不可移动**",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 2,
    "totalChunks": 14,
    "startPos": 653,
    "endPos": 980,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-3",
    "title": "rust Arena内存分配 (第4段)",
    "content": "...象占用的内存会被浪费。\n---\n2. **对象不可移动** 分配的对象通常是不可移动的，因为它们存储在  的内存块中。这样会导致以下问题：\n不能直接使用一些需要所有权移动的特性（例如对象放入  或其他容器中）。\n必须使用引用来访问  分配的对象，可能会导致生命周期管理变得复杂。\n---\n3. **不适合需要线程安全的场景**\n大多数  实现（如 ）并不是线程安全的，如果需要跨线程共享对象，还需要额外的同步机制。这时，线程安全的智能指针（如 ）会更合适。\n**例外**： 支持跨线程，但需要特别小心使用。\n---\n4. **内存使用的不可预测性**\n由于  使用内存池进行分配，所有对象会一直占用内存直到  释放。这种方式可能导致内存占用的峰值比智能指针高，尤其是分配了很多临时对象但未及时销毁  时。\n---\n5. **缺乏细粒度的所有权管理**",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 3,
    "totalChunks": 14,
    "startPos": 980,
    "endPos": 1327,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-4",
    "title": "rust Arena内存分配 (第5段)",
    "content": "...销毁  时。\n---\n5. **缺乏细粒度的所有权管理** 的对象不具有 Rust 所强调的所有权语义（比如  和 ），这可能导致以下问题：\n**安全性降低**：如果程序逻辑复杂，可能出现逻辑错误（例如悬空引用）。\n**借用规则变得模糊**：你可能需要手动确保引用的正确性，而不是依赖编译器自动检查。\n---\n6. **性能优化是否真的必要**\n虽然  性能非常高，但它的优势只有在以下场景下才会显现：\n大量的频繁对象分配和释放。\n对象的生命周期高度统一。\n对于普通的业务逻辑（如 CRUD 应用），智能指针（如 、、）提供了更直观的代码语义和更安全的内存管理方式。\n---\n**什么时候选择智能指针而不是 Arena？**",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 4,
    "totalChunks": 14,
    "startPos": 1327,
    "endPos": 1611,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-5",
    "title": "rust Arena内存分配 (第6段)",
    "content": "...---\n**什么时候选择智能指针而不是 Arena？** | 场景                              | 使用智能指针                  | 使用 Arena                     |\n|-----------------------------------|-------------------------------|---------------------------------|\n| **复杂生命周期管理**               | ✅ 可以用  或          | ❌ 生命周期过于统一可能不适用   |\n| **按需释放对象**                   | ✅ 可以释放单个对象             | ❌ 只能统一释放所有对象         |",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 5,
    "totalChunks": 14,
    "startPos": 1611,
    "endPos": 1960,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-6",
    "title": "rust Arena内存分配 (第7段)",
    "content": "...| ❌ 只能统一释放所有对象         | | **多线程环境**                     | ✅ 用                    | ❌ 多数 Arena 不支持线程安全    |\n| **高内存利用率（避免浪费）**        | ✅ 更细粒度释放内存             | ❌ 长期运行可能导致内存浪费     |\n| **轻量级分配和高性能需求**         | ❌ 频繁分配释放会增加开销       | ✅  高效分配与释放       |\n| **递归结构或大量小对象**           | ❌ 智能指针管理较为复杂         | ✅  简化生命周期和管理   |\n---\n总结\n 是一个强大的工具，但它的使用场景非常明确：\n**高性能需求**：大量对象的快速分配和释放。",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 6,
    "totalChunks": 14,
    "startPos": 1960,
    "endPos": 2309,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-7",
    "title": "rust Arena内存分配 (第8段)",
    "content": "...非常明确：\n**高性能需求**：大量对象的快速分配和释放。 **生命周期统一**：所有对象的生命周期可以和  绑定。\n**复杂递归结构**：例如语法树、图等需要高效管理的结构。\n在大多数常见场景中（如 Web 应用、后端服务等），智能指针（、、 等）提供了更安全、更灵活的内存管理方案。选择是否使用  时，应该基于你的应用需求、生命周期复杂性以及性能瓶颈来决定。\n**结论**：**不要过度优化，除非确实需要。** 如果你的应用性能瓶颈明确在内存分配上，且生命周期统一， 才是最佳选择。否则，智能指针更符合 Rust 的所有权和安全性设计理念。\nArena 的原理简单实现",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 7,
    "totalChunks": 14,
    "startPos": 2309,
    "endPos": 2566,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-8",
    "title": "rust Arena内存分配 (第9段)",
    "content": "...t 的所有权和安全性设计理念。\nArena 的原理简单实现 的原理可以简单理解为一次性分配一大块连续的内存，然后从这块内存中逐步划分小块来分配给对象。分配的对象不会单独释放，而是等到整个  生命周期结束时，统一回收整块内存。这种方法减少了频繁调用操作系统内存分配器的开销，从而提升了性能。\n下面通过一个简单的例子手动实现一个  的简化版本来说明其工作原理：\n---\n手动实现一个简单的 \n---\n运行过程的解析\n1. **初始化 **：\n创建一个大小为 1024 字节的内存池，用于存储分配的对象。\n2. **分配对象**：\n调用  方法时， 会检查是否有足够的剩余内存。\n它将对象写入内存池中的下一个空闲位置，同时满足类型的对齐要求。\n3. **访问对象**：\n返回的指针是对象在  中的地址，因此可以像普通引用一样访问它们。\n4. **释放内存**：",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 8,
    "totalChunks": 14,
    "startPos": 2566,
    "endPos": 2915,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-9",
    "title": "rust Arena内存分配 (第10段)",
    "content": "...因此可以像普通引用一样访问它们。\n4. **释放内存**： 对象的内存不会单独释放，只有在  的生命周期结束时，整个内存池会统一释放。\n---\n示例输出\n---\n原理总结\n**分配**：通过维护一个偏移量 ()，每次从内存池中分配指定大小的块。\n**对齐**：确保分配的内存地址符合对象的对齐要求。（**编译器会确保结构体的大小是它最大对齐要求的倍数**）\n**统一释放**： 本身的内存由  管理，当  被销毁时，所有分配的内存会自动释放。\n---\n为什么  高效？\n**减少内存分配调用**：传统分配器需要频繁调用系统分配内存，而  只需要一次性分配大块内存。\n**分配速度快**：分配内存只需简单地增加偏移量。\n**释放简单**：对象的内存无需单独回收，只需释放整个 。\n---",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 9,
    "totalChunks": 14,
    "startPos": 2915,
    "endPos": 3228,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-10",
    "title": "rust Arena内存分配 (第11段)",
    "content": "...简单**：对象的内存无需单独回收，只需释放整个 。\n--- 这个简单的  演示了其核心思想。在实际应用中，比如使用  或  等库，内部实现会更复杂，处理对齐、更高效的内存管理等问题，但基本原理是相似的。\n内存对齐\n 结构体占用 **8 字节** 而不是 **7 字节**，是因为**内存对齐和填充 (padding)** 的原因。计算结构体大小时，编译器会确保结构体的大小是它最大对齐要求的倍数。(每种数据类型在内存中的地址必须是其对齐要求的倍数。)\n---\n回顾  的定义\n逐字段布局\n****\n占用地址 。\n起始地址是 0，符合对齐要求（4 的倍数）。\n****\n紧接着 ，理论上起始地址是 4，但需要满足  的对齐要求（2 的倍数）。\n地址 ，符合对齐要求。\n****\n紧接着 ，理论上起始地址是 6。\n地址 ，对  没有特殊对齐要求。",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 10,
    "totalChunks": 14,
    "startPos": 3228,
    "endPos": 3570,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-11",
    "title": "rust Arena内存分配 (第12段)",
    "content": "...，理论上起始地址是 6。\n地址 ，对  没有特殊对齐要求。 **填充 (padding)**：\n由于  的最大对齐要求是 （由  决定），整个结构体的大小必须是  的倍数。\n当前结构体占用了  共 7 字节。\n为了满足对齐要求，编译器会在末尾填充 1 个字节，使总大小达到 8 字节。\n---\n为什么要填充？\n填充是为了让结构体的每个实例在数组或内存中都符合其对齐要求。如果不填充，数组的第一个元素对齐了，第二个元素可能会错位，从而导致性能问题或未定义行为。\n示例\n如果没有填充， 的大小是 7 字节，而不是 8 字节：\n第一个元素占用 。\n第二个元素的起始地址是 ，但  的对齐要求是 ，地址  不符合要求。\n这种情况下，程序会崩溃或性能受损。\n通过填充使结构体大小变为 8 字节：\n第一个元素占用 。\n第二个元素从地址  开始，满足  的对齐要求。\n---",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 11,
    "totalChunks": 14,
    "startPos": 3570,
    "endPos": 3921,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-12",
    "title": "rust Arena内存分配 (第13段)",
    "content": "...。\n第二个元素从地址  开始，满足  的对齐要求。\n--- 如何验证结构体大小和对齐？\n可以通过以下代码验证：\n---\n小结\n1. **最大对齐要求**： 的最大对齐要求是 （由  决定）。\n2. **结构体大小必须是最大对齐要求的倍数**：为了使结构体对齐，编译器在末尾填充 1 字节，使总大小变为 8。\n3. **原因**：填充的目的是为了保证结构体实例在数组中对齐，避免跨平台问题和性能下降。\n--- \n如果想手动优化内存布局，可以尝试调整字段顺序。例如：\n调整后，结构体的布局如下：\n-> 。\n-> 。\n-> 。\n此时  的大小仍然是 8 字节，但没有额外的填充。\nArena vs 动态数组区别",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 12,
    "totalChunks": 14,
    "startPos": 3921,
    "endPos": 4194,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust Arena内存分配#chunk-13",
    "title": "rust Arena内存分配 (第14段)",
    "content": "...字节，但没有额外的填充。\nArena vs 动态数组区别 当 Arena 的内存不足时，它不会自动扩容，而是通过新的大块内存来继续分配对象：Arena 会分配一块新的内存区域，原有的对象依然保留，新的对象被分配到新区域中。\n这和动态数组扩容时需要移动已有数据的方式不同。\nArena 是批量分配与集中释放，而动态数组是按需分配与按需释放。\n参考\ngpt",
    "url": "/blog/rust Arena内存分配",
    "chunkIndex": 13,
    "totalChunks": 14,
    "startPos": 4194,
    "endPos": 4341,
    "originalTitle": "rust Arena内存分配"
  },
  {
    "chunkId": "/blog/rust 作用域规则#chunk-0",
    "title": "作用域规则",
    "content": "作用域规则\nRust 的作用域规则是其内存安全性的基础之一，主要围绕**所有权**、**借用**和**生命周期**来确保内存的管理安全且高效。以下通过几个简单例子说明 Rust 的作用域规则。\n所有权\n例 2：所有权的转移（Move）\n的所有权被转移给  后， 在作用域内被标记为无效。\n这种设计避免了两者指向同一内存而导致潜在的错误。\n---\n借用\n---\n例 3：借用（Borrowing）\n通过  借用一个变量，借用不会转移所有权。\n作用域结束后，借用结束，原变量仍然有效。\n---\n例 4：可变借用\n一个变量在同一时间只能有一个可变借用，避免数据竞争。\n可变借用结束后，变量才能被再次使用。\n---\n例 5：不可变和可变借用的冲突",
    "url": "/blog/rust 作用域规则",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 320,
    "originalTitle": "作用域规则"
  },
  {
    "chunkId": "/blog/rust 作用域规则#chunk-1",
    "title": "作用域规则 (第2段)",
    "content": "...量才能被再次使用。\n---\n例 5：不可变和可变借用的冲突 Rust 禁止同时存在不可变借用和可变借用，防止并发修改的错误。\n---\n例 6：作用域嵌套解决借用冲突\n通过作用域嵌套，解决不可变借用和可变借用的冲突。\n---\n生命周期\n1. **基础概念：生命周期标注**\n生命周期（）表示引用的作用域，Rust 编译器通过生命周期标注检查引用是否有效。  \n示例：\n的生命周期只存在于内层作用域， 的生命周期更长。\nRust 编译器不允许引用超出被引用对象的作用域，避免悬垂指针。\n---\n2. **函数中的生命周期**\n当函数涉及引用参数时，需要显式标注生命周期，表示引用的有效范围。\n示例：显式标注生命周期\n**解读：**\n1.  表示  和  的生命周期有关联，并且返回值的生命周期与它们相同。",
    "url": "/blog/rust 作用域规则",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 320,
    "endPos": 641,
    "originalTitle": "作用域规则"
  },
  {
    "chunkId": "/blog/rust 作用域规则#chunk-2",
    "title": "作用域规则 (第3段)",
    "content": "...和  的生命周期有关联，并且返回值的生命周期与它们相同。 2. 编译器确保  的生命周期不超过  和  中较短的那一个。\n---\n3. **生命周期不相同的情况**\n如果参数的生命周期不同，Rust 会限制返回值的引用。\n示例：不同生命周期导致错误\n---\n4. **结合结构体的生命周期**\n如果结构体包含引用，必须显式声明生命周期，表明其有效性。\n示例：结构体中的生命周期\n**解读：**\n约束  的生命周期，确保  的引用有效。\n---\n5. **静态生命周期（）**\n静态生命周期表示引用在程序整个运行期间都有效（例如，字符串字面值）。\n示例：静态生命周期\n---\n6. **省略规则（生命周期省略）**\n在某些情况下，编译器能自动推断生命周期，无需显式标注。\n示例：无需显式标注\n**推断规则：**\n1. 每个引用参数都分配一个生命周期。",
    "url": "/blog/rust 作用域规则",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 641,
    "endPos": 987,
    "originalTitle": "作用域规则"
  },
  {
    "chunkId": "/blog/rust 作用域规则#chunk-3",
    "title": "作用域规则 (第4段)",
    "content": "...**推断规则：**\n1. 每个引用参数都分配一个生命周期。 2. 如果只有一个引用参数，返回值与该参数共享生命周期。\n3. 如果有多个引用参数且返回值使用其中一个，编译器无法推断时需要显式标注。\n---\n7. **复杂例子：多个生命周期**\n当涉及多个引用参数时，需要明确区分生命周期。\n示例：多个生命周期标注\n**解读：**\n表示  和  可能有不同的生命周期。\n返回值不涉及引用，因而无需与  或  关联。\n---\n总结\n1. **生命周期的核心目标**：确保引用在有效范围内安全使用。\n2. **常用规则**：\n返回值的生命周期不能超过参数的生命周期。\n多个参数涉及时，明确生命周期关系非常重要。\n3. **场景分类**：\n函数参数与返回值。\n结构体中的引用。\n静态生命周期或复杂引用场景。",
    "url": "/blog/rust 作用域规则",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 987,
    "endPos": 1306,
    "originalTitle": "作用域规则"
  },
  {
    "chunkId": "/blog/rust 作用域规则#chunk-4",
    "title": "作用域规则 (第5段)",
    "content": "...与返回值。\n结构体中的引用。\n静态生命周期或复杂引用场景。 Rust 的生命周期机制虽然看起来复杂，但通过明确的规则和编译器检查，确保了内存安全。\n参考\nRust 所有权与生命周期\ngpt",
    "url": "/blog/rust 作用域规则",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1306,
    "endPos": 1370,
    "originalTitle": "作用域规则"
  },
  {
    "chunkId": "/blog/rust 智能指针与可变性#chunk-0",
    "title": "参考",
    "content": "Rust 的智能指针是一种封装了指针行为的数据结构，它不仅能像普通指针那样访问数据，还附加了更多的功能，比如所有权管理、引用计数或内存自动回收。常见的智能指针有 、、 和 。下面通过具体例子讲解这些智能指针及其使用场景。\n智能指针\n2. : 单线程下的引用计数智能指针\n（Reference Counted）允许在单线程中多个所有者共享数据。它通过引用计数来跟踪数据的所有权。\n**使用场景**：\n当需要共享不可变数据，且数据的生命周期不明确时（如在图或树结构中多个节点共享数据）。\n---\n3. : 多线程下的引用计数智能指针\n（Atomic Reference Counted）是线程安全的引用计数智能指针，适合多线程环境。\n**使用场景**：\n当需要在多线程之间共享数据时使用。\n---",
    "url": "/blog/rust 智能指针与可变性",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 347,
    "originalTitle": "参考"
  },
  {
    "chunkId": "/blog/rust 智能指针与可变性#chunk-1",
    "title": "参考 (第2段)",
    "content": "...使用场景**：\n当需要在多线程之间共享数据时使用。\n--- 4. : 单线程下的内部可变性\n 提供了一种“内部可变性”机制，即即使外部不可变，也能在运行时借用可变引用（动态检查）。\n**使用场景**：\n当你需要在不可变数据结构中修改数据，但无法使用可变引用时。\n**注意**： 只适用于单线程，且在运行时借用规则违反时会触发 panic。\n---\n组合使用示例\n在实际项目中，常常需要将这些智能指针组合使用。例如，使用  创建一个共享的、可变的树节点。\n---\n总结\n****：堆上存储单一所有者的数据。\n****：单线程下共享不可变数据。\n****：多线程下共享不可变数据。\n****：单线程中提供内部可变性。\n**组合使用**：例如  用于共享和修改数据。",
    "url": "/blog/rust 智能指针与可变性",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 347,
    "endPos": 648,
    "originalTitle": "参考"
  },
  {
    "chunkId": "/blog/rust 智能指针与可变性#chunk-2",
    "title": "参考 (第3段)",
    "content": "...部可变性。\n**组合使用**：例如  用于共享和修改数据。 选择合适的智能指针取决于具体的需求：是否需要多线程支持？是否需要可变性？是否需要共享？根据这些因素进行决策即可。\n参考\ngpt",
    "url": "/blog/rust 智能指针与可变性",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 648,
    "endPos": 711,
    "originalTitle": "参考"
  },
  {
    "chunkId": "/blog/rust 的 trait#chunk-0",
    "title": "rust 的 trait",
    "content": "Rust 中的  是一种抽象机制，它定义了某些类型必须实现的**行为集合**。 的核心思想是**通过行为定义接口，并实现面向接口编程**，从而实现灵活性、可扩展性和类型安全。\n我们通过几个例子来讲解 Rust 中  的核心思想。\n核心思想 2：**静态分发**\nRust 中的  是**静态分发**的。这意味着编译器在编译时会根据具体类型生成特定的实现代码，从而避免运行时开销。\n示例：静态分发的打印功能\n**核心思想体现**：\n**静态分发**：编译器在  函数中内联了  的  方法，没有运行时成本。\n**泛型约束**：通过 ，确保传入的类型必须实现 。\n---\n核心思想 3：**动态分发**",
    "url": "/blog/rust 的 trait",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 300,
    "originalTitle": "rust 的 trait"
  },
  {
    "chunkId": "/blog/rust 的 trait#chunk-1",
    "title": "rust 的 trait (第2段)",
    "content": "...的类型必须实现 。\n---\n核心思想 3：**动态分发** 通过 ，我们可以在运行时动态决定使用哪个类型的实现。动态分发使用指针（如  或 ），并带有一定的运行时开销。\n示例：使用动态分发\n**核心思想体现**：\n**动态分发**：使用 ，使得程序在运行时通过虚表查找调用正确的方法。\n**扩展性**： 中可以容纳任意实现了  的类型。\n**灵活性与性能的权衡**：相比静态分发，动态分发更灵活，但有运行时开销。\n---\n核心思想 4：**组合与扩展**\nRust 的  支持组合和扩展，通过将多个  组合，或者定义继承关系，创建更强大的接口。\n示例：组合多个 \n**核心思想体现**：\n**组合**： 由  和  组合而成，定义了更多的行为。\n**扩展**：通过实现 ，自动继承了  和  的能力。\n---\n核心思想 5：**默认实现**",
    "url": "/blog/rust 的 trait",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 300,
    "endPos": 641,
    "originalTitle": "rust 的 trait"
  },
  {
    "chunkId": "/blog/rust 的 trait#chunk-2",
    "title": "rust 的 trait (第3段)",
    "content": "...和  的能力。\n---\n核心思想 5：**默认实现** 可以为方法提供默认实现，类型在实现  时可以选择覆盖这些默认实现。\n示例：默认实现的 \n**核心思想体现**：\n**默认实现**：减少了重复代码， 可以直接使用默认实现。\n**灵活覆盖**： 通过重载提供了自定义实现。\n---\n总结\nRust 中  的核心思想包括：\n1. **定义行为接口**：通过  明确类型必须实现的功能。\n2. **静态与动态分发**：提供零成本的静态分发，或支持灵活的动态分发。\n3. **组合与扩展**：通过组合或继承构建强大的接口。\n4. **默认实现**：为通用功能提供默认实现，减少重复代码。\n 是 Rust 实现类型安全、多态性和灵活扩展的关键机制，同时保持了性能的高效性。\n参考\ngpt",
    "url": "/blog/rust 的 trait",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 641,
    "endPos": 954,
    "originalTitle": "rust 的 trait"
  },
  {
    "chunkId": "/blog/rust 的泛型#chunk-0",
    "title": "rust 的泛型",
    "content": "Rust 泛型的核心思想是 **“编写与类型无关的代码，同时保留类型的安全性和性能”**。通过泛型，我们可以实现代码复用，而不用牺牲 Rust 的零成本抽象原则。\n下面通过几个例子深入讲解这一思想。\n核心思想 2：**泛型 + trait 约束**\n泛型不仅可以表示任意类型，还可以通过**trait 约束**限定类型的行为。例如，我们可以要求某些泛型类型必须实现特定的接口。\n示例：实现一个比较函数\n我们定义一个函数，接受两个参数并返回较大的那个值。这个函数需要比较操作，只有实现了 （支持比较操作）的类型才能使用它：\n**核心思想体现**：\n**泛型与行为绑定**： 表示泛型  必须实现 ，这样函数中才可以安全地使用比较操作。",
    "url": "/blog/rust 的泛型",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 317,
    "originalTitle": "rust 的泛型"
  },
  {
    "chunkId": "/blog/rust 的泛型#chunk-1",
    "title": "rust 的泛型 (第2段)",
    "content": "...示泛型  必须实现 ，这样函数中才可以安全地使用比较操作。 **灵活性和安全性兼顾**：虽然  函数适用于任意类型，但通过  限制，避免了不支持比较的类型（如复杂对象）导致编译错误。\n---\n核心思想 3：**零成本抽象**\nRust 的泛型通过**单态化**，在编译时为每种具体类型生成特定实现，从而消除运行时的类型检查或多态分派。\n示例：通过反汇编观察泛型的单态化\n如果查看生成的汇编代码，会发现编译器生成了两个独立的实现：\n一个处理  的  函数。\n一个处理  的  函数。\n**结果**：\n泛型函数的性能等同于手动为每种类型编写函数。\n泛型提供了零成本的灵活性，无需运行时的开销。\n---\n核心思想 4：**组合与复用**\n泛型可以与其他 Rust 特性（如枚举、trait 等）结合，创建高度抽象、灵活的代码。\n示例：泛型与",
    "url": "/blog/rust 的泛型",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 317,
    "endPos": 656,
    "originalTitle": "rust 的泛型"
  },
  {
    "chunkId": "/blog/rust 的泛型#chunk-2",
    "title": "rust 的泛型 (第3段)",
    "content": "...it 等）结合，创建高度抽象、灵活的代码。\n示例：泛型与 Rust 标准库的  就是一个泛型枚举，用于表示一个可能有值或无值的类型：\n**核心思想体现**：\n使用泛型 ，可以适用于任意类型。\n通过 ，我们可以表达 “值可能为空”的语义，而无需每种类型都重新设计逻辑。\n---\n总结\nRust 泛型的核心思想在于：\n1. **参数化类型**：将类型作为参数，使代码逻辑独立于具体类型。\n2. **类型安全**：通过 trait 约束明确泛型的行为边界。\n3. **零成本抽象**：在编译时单态化，既保留灵活性又无运行时开销。\n4. **高效复用**：与 Rust 的其他特性结合，简化常见模式的实现。\n泛型使 Rust 在灵活性、类型安全和性能之间取得了很好的平衡。\n参考\ngpt",
    "url": "/blog/rust 的泛型",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 656,
    "endPos": 966,
    "originalTitle": "rust 的泛型"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-0",
    "title": "rust 设计思想",
    "content": "设计理念\nRust 的设计理念贯穿其语言的核心特性，从安全性到性能，再到开发者体验，形成了一个强大且平衡的编程生态。\n0. **零成本抽象**\n泛型：编译器时单态化，编译器为每种具体类型生成特定实现，从而消除运行时的类型检查或多态分派。Rust 的泛型通过**单态化**，在编译时为每种具体类型生成特定实现，从而消除运行时的类型检查或多态分派。\ntrait：在泛型和 trait 静态分发的情况下，Rust 编译器会为每个具体类型生成对应的函数实现。这就是所谓的 单态化（monomorphization）。\n2. **并发安全（Fearless Concurrency）**\nRust 通过编译时检查，防止常见的并发错误（如数据竞争和死锁）。",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 323,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-1",
    "title": "rust 设计思想 (第2段)",
    "content": "...通过编译时检查，防止常见的并发错误（如数据竞争和死锁）。 **设计理念**：通过类型系统在编译阶段确保并发代码的安全。\n**具体实现**：\n**线程安全的所有权**： 和  trait 定义了跨线程传递和共享的能力。\n**不变量保护**：通过锁（如 ）和原子操作（如 ），确保线程安全。\n**意义**：开发者可以编写高效的并发代码，而不必害怕数据竞争和其他隐晦的并发问题。\n**示例**：\n---\n3. **类型安全与表达性（Type Safety and Expressiveness）**\nRust 的类型系统通过静态检查，确保类型正确性，并为开发者提供丰富的表达能力。\n**设计理念**：类型系统不仅用于错误检测，还要提高代码可读性和表达力。\n**具体实现**：",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 323,
    "endPos": 629,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-2",
    "title": "rust 设计思想 (第3段)",
    "content": "...错误检测，还要提高代码可读性和表达力。\n**具体实现**： **枚举（Enum）和模式匹配（Pattern Matching）**：提供强大的分支逻辑控制。\n**泛型和 trait**：实现灵活的代码复用，同时保持类型安全。\n**Option 和 Result 类型**：避免空值和错误处理中的未定义行为。\n**意义**：减少运行时错误，提高代码的鲁棒性和可读性。\n**示例：Option 和模式匹配**：\n---\n4. **性能优先（Performance Focused）**\nRust 的性能接近 C/C++，但不以安全性为代价。\n**设计理念**：提供接近硬件级的性能，同时保持内存和线程安全。\n**具体实现**：\n**无垃圾回收**：通过所有权系统管理内存，避免 GC 带来的延迟。\n**高效的并发模型**：通过零开销抽象，允许开发者实现高性能并发。",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 629,
    "endPos": 980,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-3",
    "title": "rust 设计思想 (第4段)",
    "content": "...的并发模型**：通过零开销抽象，允许开发者实现高性能并发。 **LLVM 优化**：Rust 使用 LLVM 编译器后端生成高效机器代码。\n**意义**：适合系统级开发和性能敏感的场景。\n---\n5. **开发者体验（Developer Experience）**\nRust 通过工具和设计降低了复杂语言的学习成本和开发门槛。\n**设计理念**：即使是复杂的语言，也应尽可能友好。\n**具体实现**：\n**友好的编译器错误信息**：详细的错误信息帮助开发者快速定位问题。\n**Cargo 工具链**：集成包管理、构建、测试和发布功能。\n**社区驱动生态**：官方文档和社区资源齐全。\n**意义**：帮助开发者以更低的心智负担编写高质量代码。\n**示例：编译器的友好提示**：\n**错误信息**：\n---",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 980,
    "endPos": 1302,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-4",
    "title": "rust 设计思想 (第5段)",
    "content": "...*示例：编译器的友好提示**：\n**错误信息**：\n--- 6. **模块化与代码复用（Modularity and Reusability）**\nRust 提供了强大的模块系统和依赖管理工具，方便开发者组织代码和复用现有的解决方案。\n**设计理念**：模块化设计提高可维护性和复用性。\n**具体实现**：\n**模块和包管理**：通过模块和  系统实现代码组织。\n**Cargo**：标准化的包管理器，提供统一的依赖管理和版本控制。\n**trait 和泛型**：实现灵活的代码复用。\n**意义**：减少重复代码，提高团队协作效率。\n---\n7. **安全与灵活的错误处理（Error Handling）**\nRust 强调显式的错误处理，避免隐式失败。\n**设计理念**：通过类型系统强制处理错误，提升程序可靠性。\n**具体实现**：",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1302,
    "endPos": 1640,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-5",
    "title": "rust 设计思想 (第6段)",
    "content": "...类型系统强制处理错误，提升程序可靠性。\n**具体实现**： **Result 类型**：通过  和  明确表示操作成功或失败。\n** 操作符**：简化错误传播。\n**panic! 和不可恢复错误**：用于处理极端情况。\n**意义**：提高错误处理的可读性和安全性。\n**示例：Result 和  操作符**：\n---\n总结\nRust 的核心设计理念是多个方面的综合平衡，它们共同构成了 Rust 的独特性：\n1. **零成本抽象**：高效且灵活的语言特性。\n2. **内存安全**：无 GC 的情况下杜绝内存错误。\n3. **并发安全**：让多线程编程更安全、更高效。\n4. **类型安全与表达性**：静态类型系统提升可靠性和开发体验。\n5. **性能优先**：接近 C/C++ 的性能表现。\n6. **开发者体验**：友好的编译器和工具链。",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1640,
    "endPos": 1982,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 设计思想#chunk-6",
    "title": "rust 设计思想 (第7段)",
    "content": "...能表现。\n6. **开发者体验**：友好的编译器和工具链。 7. **模块化与代码复用**：强大的模块和依赖管理。\n8. **显式错误处理**：类型驱动的错误处理机制。\n这些理念让 Rust 成为一门兼具安全性、性能和开发效率的现代系统级编程语言。\n参考\ngpt",
    "url": "/blog/rust 设计思想",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1982,
    "endPos": 2083,
    "originalTitle": "rust 设计思想"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-0",
    "title": "rust 跨语言调用",
    "content": "rust 与 c 的调用\nRust 能与 C 交互的原因在于它和 C 都可以遵循 C ABI（Application Binary Interface，应用二进制接口）。C ABI 是一种语言无关的标准，规定了函数调用、参数传递、内存对齐等机制，确保不同语言生成的二进制代码能够互操作。\n**一个超简单的例子：让 Rust 调用 C 函数**\n我们先写一个 C 函数，然后用 Rust 调用它。\n**第一步：写 C 的代码**\n然后我们用  把这个 C 文件编译成一个共享库（比如  或 ）：\n**第二步：写 Rust 的代码调用这个 C 函数**\n**运行步骤：**\n1. 用 Rust 编译运行这个文件时，告诉它要链接 （动态库）：\n   输出结果为：。\n---\n**拆解这个过程**",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 0,
    "totalChunks": 10,
    "startPos": 0,
    "endPos": 345,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-1",
    "title": "rust 跨语言调用 (第2段)",
    "content": "...库）：\n   输出结果为：。\n---\n**拆解这个过程** 1. **C 编译器的作用**：\nC 编译器把  函数编译成机器码，并存到共享库里（）。\n这个共享库对外暴露了函数  的地址和调用方式。\n2. **Rust 的作用**：\nRust 通过  语法，告诉编译器：我想调用一个遵循 C ABI 的函数。\nRust 的编译器会在运行时找到这个共享库，并调用  函数。\n3. **C ABI 的作用**：\n确保函数的参数和返回值按约定的方式传递。比如：\n参数  和  被放在固定的寄存器里（或者栈上）。\n返回值被放在另一个固定位置。\n---\n**反过来：让 C 调用 Rust 函数**\n这次我们写一个 Rust 函数给 C 调用。\n**第一步：写 Rust 的代码**\n然后编译成共享库：\n**第二步：写 C 的代码调用这个 Rust 函数**",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 1,
    "totalChunks": 10,
    "startPos": 345,
    "endPos": 689,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-2",
    "title": "rust 跨语言调用 (第3段)",
    "content": "...：\n**第二步：写 C 的代码调用这个 Rust 函数** **运行步骤：**\n1. 编译 C 代码并链接 Rust 的共享库：\n   输出结果为：。\n---\n**总结：为什么能交互？**\n1. **Rust 并不是依赖 C，而是遵循 C 的规则（C ABI）。**\n关键字就是告诉 Rust 编译器，函数调用要遵循 C 的规则。\nC ABI 是一个约定，规定了参数和返回值怎么传递、内存怎么对齐等。\n2. **Rust 和 C 是“直接用机器语言对话”的，不需要翻译成 C 代码。**\nRust 和 C 的交互只发生在编译后的机器代码层。\nRust 编译后的共享库（）和 C 编译的可执行程序用相同的协议调用函数。\n3. **Rust 通过 FFI 提供了跟其他语言交互的能力：**",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 2,
    "totalChunks": 10,
    "startPos": 689,
    "endPos": 1002,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-3",
    "title": "rust 跨语言调用 (第4段)",
    "content": "...*Rust 通过 FFI 提供了跟其他语言交互的能力：** 只要其他语言也遵循 C ABI，比如 Python 的  或 JavaScript 的 ，它们都能和 Rust 互操作。\n这个例子可以看出，C 和 Rust 的交互是靠 ABI 约定，而不是中间语言或运行时的“翻译”。\n---\nrust 与 js 的调用\n**初步理解：napi-rs 将 rust 代码编译成了 N-API 协议能够识别的 .node 文件，所以  js 能够直接加载，如果是 rust 编译出的  .so 文件（遵循 C-ABI ） 则需要 C或者 C++ 编写胶水语言 做成符合 N-API 的 .node 文件，然后 才可以被 js 调用？基于 N-API：注重 跨平台性 和 稳定性，适合长期维护的项目。**\n其他调用方式：",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 3,
    "totalChunks": 10,
    "startPos": 1002,
    "endPos": 1328,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-4",
    "title": "rust 跨语言调用 (第5段)",
    "content": "...台性 和 稳定性，适合长期维护的项目。**\n其他调用方式： rust -> .wasm（跨平台，可以 node 跟浏览器环境，比 .node 性能稍低） -> js\nneon （针对 v8 引擎，跳过 NAPI 抽象层，性能比 napi-rs 转换的代码更高效，但是可维护性也更差），基于 V8 深度绑定：追求 性能极致 和 灵活定制，适合对底层优化要求极高的项目。\n---\n**1. 使用 N-API（如 ）编译出的  文件**\n**关键点**：Rust 代码直接编译成符合 **N-API 标准** 的  文件。\n**工作流程**：\n  1. Rust 使用  或  库，通过 N-API 暴露函数。\n  2.  在编译过程中自动生成符合 N-API 标准的动态库（ 文件）。\n  3. Node.js 加载这个  文件，直接调用 Rust 的函数。",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 4,
    "totalChunks": 10,
    "startPos": 1328,
    "endPos": 1676,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-5",
    "title": "rust 跨语言调用 (第6段)",
    "content": "...de.js 加载这个  文件，直接调用 Rust 的函数。 **特点**：这一过程完全自动化，不需要手写 C/C++ 胶水代码。Rust 代码编译后直接可以被 Node.js 使用，开发体验优良。\n---\n**2. 如果只有 Rust 编译出的  文件**\n**关键点**： 文件是标准的 C ABI 动态库格式，JavaScript 环境（如 Node.js）本身不支持直接加载 C ABI 的库。\n**问题**：\nJavaScript 和  文件之间缺少直接的桥梁。\n需要手写胶水代码，用 C 或 C++ 把  封装成 N-API 模块（ 文件）。\n**手写胶水代码的流程：**\n1. **Rust 编译出  文件**：\n使用  类型的  编译出 C ABI 动态库：\n2. **用 C/C++ 编写 N-API 模块**：",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 5,
    "totalChunks": 10,
    "startPos": 1676,
    "endPos": 2011,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-6",
    "title": "rust 跨语言调用 (第7段)",
    "content": "...：\n2. **用 C/C++ 编写 N-API 模块**： 使用 C/C++ 代码封装  文件的函数为 N-API 模块：\n3. **编译 C++ 胶水代码成  文件**：\n使用  或其他工具链编译生成  文件：\n**特点**：这一过程繁琐，需要编写和维护额外的 C/C++ 代码。\n---\n**3. 两种方式对比**\n| **特点**                  | **使用 **                                      | **使用  + C/C++ 胶水代码**                      |",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 6,
    "totalChunks": 10,
    "startPos": 2011,
    "endPos": 2260,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-7",
    "title": "rust 跨语言调用 (第8段)",
    "content": "...胶水代码**                      | |--------------------------|--------------------------------------------------------|----------------------------------------------------|\n| **开发效率**             | 高：无需手写胶水代码，Rust 直接编译成  文件       | 低：需要手动编写 C/C++ 胶水代码封装  文件      |\n| **依赖性**               | 只需 ，完全用 Rust 开发                            | Rust + C/C++，需要额外工具链                       |",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 7,
    "totalChunks": 10,
    "startPos": 2260,
    "endPos": 2607,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-8",
    "title": "rust 跨语言调用 (第9段)",
    "content": "...额外工具链                       | | **可维护性**             | 高：Rust 和 Node.js 开发者可以直接维护                   | 低：Rust 和 C/C++ 开发需要协作                     |\n| **适用场景**             | 适合绝大多数 Node.js 插件开发场景                       | 适合已有  文件需要快速封装到 N-API 的场景      |\n| **性能**                 | 性能优良，直接生成 N-API 模块                           | 性能同样优良，但手工编写代码可能增加维护成本        |\n---\n**总结**",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 8,
    "totalChunks": 10,
    "startPos": 2607,
    "endPos": 2944,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/rust 跨语言调用#chunk-9",
    "title": "rust 跨语言调用 (第10段)",
    "content": "...码可能增加维护成本        |\n---\n**总结** 如果你的目标是为 Node.js 开发插件，使用 Rust 的 **N-API 工具链**（如 ）是最佳选择，它能让你直接生成  文件，省去了手动编写 C/C++ 胶水代码的麻烦。\n如果你手头已有  文件（比如是用其他语言编写的库），需要编写 C/C++ 胶水代码将其封装成  文件，才能被 Node.js 加载和使用。\n最终，**N-API 是核心桥梁**，Rust 和 C/C++ 都是为了生成能符合 N-API 的模块。\n参考资料\ngpt",
    "url": "/blog/rust 跨语言调用",
    "chunkIndex": 9,
    "totalChunks": 10,
    "startPos": 2944,
    "endPos": 3166,
    "originalTitle": "rust 跨语言调用"
  },
  {
    "chunkId": "/blog/关于node的addon#chunk-0",
    "title": "关于node的addon",
    "content": "关于node的addon\nNode.js 对 native addon 开发侧暴露的是 ABI（In computer software, an application binary interface (ABI) is an interface between two binary program modules）\nAddon方案演化\n***以下是摘抄，还有待琢磨原理***\nNAN（Native Abstractions for Node.js）",
    "url": "/blog/关于node的addon",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 227,
    "originalTitle": "关于node的addon"
  },
  {
    "chunkId": "/blog/关于node的addon#chunk-1",
    "title": "关于node的addon (第2段)",
    "content": "...ive Abstractions for Node.js） NAN 将 v8/libuv 相关的 API 进行了封装，对外是稳定的抽象层 API (但却无法保证是 ABI 稳定)。用 NAN 进行封装的 native addon 几乎无法通过预编译的方式进行分发，因为跨 Node 版本底层 v8/libuv API 变化之后需要对源码进行重新编译才能使用。所以这就是为什么很多 native addon 在 npm install 后还要调用一堆工具链在本地进行编译才能使用，以及为什么有时候 node 版本升级之后之前安装好的 node_modules 就无法直接使用了。\n一句话理解：V8底层的封装，估计需要理解V8才能开发\nN-API",
    "url": "/blog/关于node的addon",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 227,
    "endPos": 519,
    "originalTitle": "关于node的addon"
  },
  {
    "chunkId": "/blog/关于node的addon#chunk-2",
    "title": "关于node的addon (第3段)",
    "content": "...理解：V8底层的封装，估计需要理解V8才能开发\nN-API 自从 Node.js v8.0.0 发布之后，Node.js 推出了全新的用于开发 C++ 原生模块的接口，N-API。本质其实是将 NAN 这层抽象挪到了 node 源码中，在 node 编译的时候就编译好这层对外抽象，这样 N-API 对外就是稳定的 ABI 了。\n一句话理解：v8之上node层的封装，跟随Node编译，独立于操作系统\n应用\nC++扩展\n基本步骤：\n./demo.cc\n模块配置跟编译\n./binding.gyp\n生成.node文件（动态链接库）\n调用.node文件\n思考\nnode扩展方式\n插件开发\nWebAssembly\n哪种更快些？或者分别适用于哪些场景？\nWasm被保证与可以运行您的Electron应用程序的任何操作系统兼容。",
    "url": "/blog/关于node的addon",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 519,
    "endPos": 849,
    "originalTitle": "关于node的addon"
  },
  {
    "chunkId": "/blog/关于node的addon#chunk-3",
    "title": "关于node的addon (第4段)",
    "content": "...与可以运行您的Electron应用程序的任何操作系统兼容。 C，C++和Rust将没有此保证。除了从JavaScript调用的开销之外，它们将更加高效。\n正在积极地处理从JavaScript调用Wasm的开销，并且正在减少或完全消除这种开销。\nReference\nN-API入门\nRust bindings for writing safe and fast native Node.js modules.neon\n用 Rust 和 N-API 开发高性能 Node.js 扩展",
    "url": "/blog/关于node的addon",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 849,
    "endPos": 1058,
    "originalTitle": "关于node的addon"
  },
  {
    "chunkId": "/blog/内存分析#chunk-0",
    "title": "Node内存分析",
    "content": "Node内存分析\n长时间（一般是几天时间）一条内存只增不减的曲线就标志着内存泄露了\n内存泄露分析基本步骤\n0. node引入 require('heapdump')\n1. 启动node, eg: npm run start\n3. lsof -i:8080\n4. kill -USR2 <pid>（第三步查看到的pid）\n5. 根据情况调整压测参数 autocannon -c 10 -a 10 http://localhost:8080\n6. 重复执行3次步骤 4，5\n7. 浏览器打开控制台memory栏目，按照生成顺序载入生产的内存快照  heapdump开头的文件\nReference",
    "url": "/blog/内存分析",
    "chunkIndex": 0,
    "totalChunks": 2,
    "startPos": 0,
    "endPos": 297,
    "originalTitle": "Node内存分析"
  },
  {
    "chunkId": "/blog/内存分析#chunk-1",
    "title": "Node内存分析 (第2段)",
    "content": "...存快照  heapdump开头的文件\nReference https://marmelab.com/blog/2018/04/03/how-to-track-and-fix-memory-leak-with-nodejs.html\nhttps://github.com/aliyun-node/Node.js-Troubleshooting-Guide/blob/master/0x03_%E5%B7%A5%E5%85%B7%E7%AF%87_%E6%AD%A3%E7%A1%AE%E6%89%93%E5%BC%80%20Chrome%20devtools.md",
    "url": "/blog/内存分析",
    "chunkIndex": 1,
    "totalChunks": 2,
    "startPos": 297,
    "endPos": 549,
    "originalTitle": "Node内存分析"
  },
  {
    "chunkId": "/blog/列存储#chunk-0",
    "title": "列存储",
    "content": "什么是列存储？跟传统存储啥区别？为啥列存储能更加快速响应复杂查询？\n列存储（Columnar Storage）是一种数据存储方式，与传统的行存储（Row Storage）有显著区别。列存储在处理分析型工作负载时，尤其是涉及复杂查询的情况下，表现得更加高效。\n列存储（Columnar Storage）\n在列存储中，数据按列存储，而不是按行存储。每一列的数据存储在一起，所有同一列的数据都连续存储在磁盘上。例如，对于一个有四个列（A、B、C、D）的表，数据将按如下方式存储：\n行存储（Row Storage）\n在传统的行存储中，数据按行存储，每一行的数据存储在一起。对于同样的四列表，数据将按如下方式存储：\n区别\n1. **数据存储方式**\n**行存储**：所有列的值按行存储在一起。",
    "url": "/blog/列存储",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 342,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/列存储#chunk-1",
    "title": "列存储 (第2段)",
    "content": "...据存储方式**\n**行存储**：所有列的值按行存储在一起。 **列存储**：同一列的值按列存储在一起。\n2. **适用场景**\n**行存储**：适用于OLTP（在线事务处理）工作负载，例如频繁的插入、更新和删除操作。\n**列存储**：适用于OLAP（在线分析处理）工作负载，例如复杂的查询和报表分析。\n列存储响应复杂查询更快速的原因\n1. **查询效率**\n在分析型查询中，通常只涉及少量的列。例如，计算某个统计数据只需访问特定的列。列存储仅读取需要的列数据，减少了I/O操作。\n行存储则需要读取整行数据，即使只需要其中一两列，也要读取整行，导致不必要的I/O开销。\n2. **数据压缩**",
    "url": "/blog/列存储",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 342,
    "endPos": 608,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/列存储#chunk-2",
    "title": "列存储 (第3段)",
    "content": "...读取整行，导致不必要的I/O开销。\n2. **数据压缩** 列存储的同一列数据类型相同且经常有相似的值，压缩效果更好。例如，一个包含许多重复值的列可以通过RLE（Run-Length Encoding）等压缩算法显著减少存储空间。\n行存储的数据类型混杂在一起，压缩效率低下。\n3. **向量化处理**\n列存储系统可以利用向量化处理技术，同时处理一批列数据，提高CPU使用效率。\n行存储处理每行数据时需要多次加载和存储，效率较低。\n4. **缓存利用**\n由于列存储按列连续存储，缓存命中率高，减少了对磁盘的访问。\n行存储按行存储，缓存命中率较低，需要频繁访问磁盘。\n总结\n列存储通过优化I/O操作、提高压缩效率、利用向量化处理和更好的缓存利用，显著提高了复杂查询的响应速度。因此，它特别适用于需要进行大量读取和分析的场景，如数据仓库、商业智能和实时分析系统。",
    "url": "/blog/列存储",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 608,
    "endPos": 958,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/列存储#chunk-3",
    "title": "列存储 (第4段)",
    "content": "...大量读取和分析的场景，如数据仓库、商业智能和实时分析系统。 示例\n假设有一个大型销售数据表，包含日期、产品ID、销售数量和销售额四个字段：\n**行存储：**\n**列存储：**\n查询总销售额时，列存储只需读取“销售额”列的数据，而行存储则需读取每一行的所有字段，明显增加了I/O开销和处理时间。这就是列存储在复杂查询中表现更高效的原因。",
    "url": "/blog/列存储",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 958,
    "endPos": 1095,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/性能分析#chunk-0",
    "title": "性能分析",
    "content": "性能分析\n最近通过 alinode 的CPU火焰图找出了项目中吞吐率阻塞点，简单分享\nprofile的原理？\n如何对profile结果做可视化？\n火焰图如何分析？\n如何development/production进行profile\nChrome Profiler运行机制\nChrome profiler 为了找到那些耗时最多的代码，Chrome 分析器每 100μs 捕获一个堆栈跟踪。\n这意味着，如果一个函数只需要 50μs 的执行时间，就可能不会在分析器中显示出来！\n当你分析几毫秒以上的时间时，可以准确了解应用程序在何时花费最多的时间。 但是，当你放大 profiler 面板想看更精准的时间时，信息会变得不太准确。",
    "url": "/blog/性能分析",
    "chunkIndex": 0,
    "totalChunks": 9,
    "startPos": 0,
    "endPos": 312,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-1",
    "title": "性能分析 (第2段)",
    "content": "...ofiler 面板想看更精准的时间时，信息会变得不太准确。 分析器也会不一致。 每次运行时，会产生一个稍微不同的结果。 有时可能会记录非常短的函数调用，而在其他时间再次运行这些函数调用信息可能会丢失。\nperformance\nScripting\nRendering\nPainting\nOther\nIdle\njavascript-profiler\nCPU Profiles\ncpu profile种类\n采样 Sampling\n基于对StackTrace的“采样”进行实现，在一时间段内（至少得5min保证样本数足够多）对堆栈做快照采样\n优点: \n>简单，源代码侵入性不大\n劣势: \n>采样数据主要体现在调用次数上，对CPU的占有时间不够精准\n要求：\n>1. 样本必须足够多。\n>2. 程序中所有正在运行的代码点都必须以相同的概率被Profiler采样。",
    "url": "/blog/性能分析",
    "chunkIndex": 1,
    "totalChunks": 9,
    "startPos": 312,
    "endPos": 658,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-2",
    "title": "性能分析 (第3段)",
    "content": "...正在运行的代码点都必须以相同的概率被Profiler采样。 >>JVM 只能在safepoint采样,是否就违背了第二条原则？最终导致profile不太准\n适合场景\n>Sampling由于低开销的特性，更适合用在CPU密集型的应用中，以及不可接受大量性能开销的线上服务中。\n>也是一般Profiler的实现机制，典型的就是alinode\nInstrumentation \nInstrumentation方式对几乎所有方法添加了额外的AOP（Aspect Oriented Programming 中文翻译为面向切面编程）逻辑，这会导致对线上服务造成巨额的性能影响\n这个有点像函数埋点\n优点\n>绝对精准的方法调用次数、调用时间统计。\n缺点\n>性能消耗比较大，侵入性也比较高\n适合场景",
    "url": "/blog/性能分析",
    "chunkIndex": 2,
    "totalChunks": 9,
    "startPos": 658,
    "endPos": 969,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-3",
    "title": "性能分析 (第4段)",
    "content": "...间统计。\n缺点\n>性能消耗比较大，侵入性也比较高\n适合场景 >Instrumentation则更适合用在I/O密集的应用中、对性能开销不敏感以及确实需要精确统计的场景中。\n火焰图\n火焰图统计的是次数，所以属于CPU采样类型\n火焰图svg\n火焰图含义\nsampling\n>y 轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。\n>x 轴表示抽样数，如果一个函数在 x 轴占据的宽度越宽，就表示它被抽到的次数多，即执行的时间长。注意，x 轴不代表时间，而是所有的调用栈合并后，按字母顺序排列的。\n**火焰图就是看顶层的哪个函数占据的宽度最大。只要有\"平顶\"（plateaus），就表示该函数可能存在性能问题。**\n火焰图示例",
    "url": "/blog/性能分析",
    "chunkIndex": 3,
    "totalChunks": 9,
    "startPos": 969,
    "endPos": 1276,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-4",
    "title": "性能分析 (第5段)",
    "content": "...eaus），就表示该函数可能存在性能问题。**\n火焰图示例 上面代码中，start_thread是启动线程，调用了func_a。后者又调用了func_b和func_d，而func_b又调用了func_c。\n合并后\n有了这个调用栈，统计工具就能生成对应的图，灵魂火焰图\n<!-- \n| func_c | a |\n| --- | --- |\n| func_d | func_b |\n| func_a | a |\n| start_thread | a | -->\nProfile实践\n开发测试阶段\n目前v8-profiler在 node12的时候安装构建失败，node12版本自带的node-gypbuild不成功；\n替代方案是选用 v8-profiler-next，步骤：\n1. npm i -D v8-profiler-next",
    "url": "/blog/性能分析",
    "chunkIndex": 4,
    "totalChunks": 9,
    "startPos": 1276,
    "endPos": 1610,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-5",
    "title": "性能分析 (第6段)",
    "content": "...1. npm i -D v8-profiler-next 2. 参照v8-profiler-next文档，在dev启动5分钟左右\n3. 压测（例如：autocannon -c 10 -d 300 -p 1 http://localhost:8080）\n4. 导出结果到chrome就可以看到具体的 cpu占用情况\n在chrome 调试工具里找到 Javascript Profiler即可导入 xx.cpuprofile 文件进行分析，有百分比跟倒立火焰图\n产线\n目前alinode用起来还比较流畅，如果使用的是Docker部署，可以走以下流畅",
    "url": "/blog/性能分析",
    "chunkIndex": 5,
    "totalChunks": 9,
    "startPos": 1610,
    "endPos": 1854,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-6",
    "title": "性能分析 (第7段)",
    "content": "...来还比较流畅，如果使用的是Docker部署，可以走以下流畅 1. 直接使用alinode镜像构建自己的dockerfile **（为了降低Docker镜像的大小，node12 对应的alinode版本看起来基于alpine linux，所以有些需要注意，例如apt需要替换apk）**\n2. 按照官方文档创建 app-config.json 文件\n3. 部署上线，然后进行 cpu在线Profile，转储后在线分析（支持火焰图跟dev tool模式）\n感兴趣的可以参考这里\nDemo\n1. 跳转到 Test 路由\n2. 点击 cpu-profiling\n3. 打开console，点击Javascript Profiler，点击record，6秒后点击stop\n4. 再次点击 cpu-profiling",
    "url": "/blog/性能分析",
    "chunkIndex": 6,
    "totalChunks": 9,
    "startPos": 1854,
    "endPos": 2177,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-7",
    "title": "性能分析 (第8段)",
    "content": "...后点击stop\n4. 再次点击 cpu-profiling 更多精细demo, 本地运行这个工程，修改pages/test/use-test.ts里面的参数，再次走上面流程，看下100微秒的捕获丢失效果，以及最小的时间单元是否是 0.1毫秒（也就是100微秒）\nReference\nhttps://github.com/brendangregg/FlameGraph\nhttps://www.mattzeunert.com/2016/08/06/show-native-functions-in-js-profile.html\nhttps://nodesource.com/blog/diagnostics-in-NodeJS-2\nhttps://www.ruanyifeng.com/blog/2017/09/flame-graph.html",
    "url": "/blog/性能分析",
    "chunkIndex": 7,
    "totalChunks": 9,
    "startPos": 2177,
    "endPos": 2520,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/性能分析#chunk-8",
    "title": "性能分析 (第9段)",
    "content": "...blog/2017/09/flame-graph.html https://tech.meituan.com/2019/10/10/jvm-cpu-profiler.html\nhttps://www.jianshu.com/p/c79c5e02ebe6\n<u>2021-7-28</u>",
    "url": "/blog/性能分析",
    "chunkIndex": 8,
    "totalChunks": 9,
    "startPos": 2520,
    "endPos": 2633,
    "originalTitle": "性能分析"
  },
  {
    "chunkId": "/blog/理解 rust 无 GC#chunk-0",
    "title": "理解 rust 无 GC",
    "content": "自己的理解：**rust 无 GC应该指的是没有集中式的 GC，而是分散式的，随着代码的执行而自动的 回收？**\nRust 中没有传统意义上的 **集中式垃圾回收（Garbage Collector, GC）**，而是通过 **分散式的、编译时静态分析和运行时的引用计数机制** 来管理内存。这种方式避免了传统 GC 的集中式工作方式，回收是随着代码逻辑执行自然发生的。\n**没有集中式 GC 的好处**\n**性能更高**：  \n没有 GC 暂停（GC Pause），因此实时性较好。\n在作用域结束时立即释放内存，不需要等待垃圾回收器触发。\n**内存管理可控**：  \n开发者通过所有权和借用机制对内存管理有更多的明确控制。\n**更小的运行时开销**：",
    "url": "/blog/理解 rust 无 GC",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 329,
    "originalTitle": "理解 rust 无 GC"
  },
  {
    "chunkId": "/blog/理解 rust 无 GC#chunk-1",
    "title": "理解 rust 无 GC (第2段)",
    "content": "...内存管理有更多的明确控制。\n**更小的运行时开销**： Rust 没有语言级别的垃圾回收器，这减少了程序运行时的内存和 CPU 开销。\n---\n**分散式回收**\nRust 的内存回收不是集中管理，而是随着代码执行逐步完成的：\n编译时：分析作用域和所有权，静态确定释放时机。\n运行时：通过引用计数（如  和 ）动态管理共享数据。\n**例子：**\n---\n**与传统 GC 的对比**\n| 特性                  | Rust                     | 传统 GC (如 Java, Go)         |\n|-----------------------|--------------------------|-------------------------------|",
    "url": "/blog/理解 rust 无 GC",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 329,
    "endPos": 658,
    "originalTitle": "理解 rust 无 GC"
  },
  {
    "chunkId": "/blog/理解 rust 无 GC#chunk-2",
    "title": "理解 rust 无 GC (第3段)",
    "content": "...----------------------------| | **回收触发时机**      | 编译时分析，运行时即时回收 | 运行时批量回收（触发时暂停）  |\n| **运行时开销**        | 无集中管理，开销更小      | 需跟踪对象、回收开销较高      |\n| **暂停问题**          | 无 GC 暂停，实时性更好    | 存在 GC 暂停问题              |\n| **内存安全性**        | 编译时强保证             | 运行时依赖语言特性和检查机制 |\n---\n**总结**\nRust 的内存管理依赖 **所有权机制** 和 **引用计数（如果需要）**，在代码执行的同时完成内存的分散式回收，不依赖集中式 GC。它避免了传统 GC 的性能问题，同时提供了强大的内存安全性。",
    "url": "/blog/理解 rust 无 GC",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 658,
    "endPos": 1008,
    "originalTitle": "理解 rust 无 GC"
  },
  {
    "chunkId": "/blog/理解 rust 无 GC#chunk-3",
    "title": "理解 rust 无 GC (第4段)",
    "content": "...避免了传统 GC 的性能问题，同时提供了强大的内存安全性。 Reference\ngpt",
    "url": "/blog/理解 rust 无 GC",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 1008,
    "endPos": 1021,
    "originalTitle": "理解 rust 无 GC"
  },
  {
    "chunkId": "/blog/理解并发#chunk-0",
    "title": "理解并发",
    "content": "如何理解node并发\n同步阻塞\n例如：计算一个\n对于CPU计算类型的，会阻塞单线程\n异步非阻塞\n例如： request请求，数据库处理等异步I/O\n本质上node还是为异步I/O创建了新的线程，例如：对于数据库的非阻塞异步操作，实际上是开启了独立的数据库操作线程去处理，然后把结果返回给主线程\n形象的比喻\n单线程模型（Nodejs）:\n服务员A处理不同顾客的点单请求,多个I/O厨师准备多个订单上的菜肴->然后服务员A端给不同顾客；\n多线程模型（例如GO）:\n里面有许多个厨师，每个厨师的一条龙服务：处理顾客的点单请求->准备菜肴->然后端给顾客\nReference",
    "url": "/blog/理解并发",
    "chunkIndex": 0,
    "totalChunks": 2,
    "startPos": 0,
    "endPos": 284,
    "originalTitle": "理解并发"
  },
  {
    "chunkId": "/blog/理解并发#chunk-1",
    "title": "理解并发 (第2段)",
    "content": "...的点单请求->准备菜肴->然后端给顾客\nReference https://stackoverflow.com/questions/34855352/how-in-general-does-node-js-handle-10-000-concurrent-requests",
    "url": "/blog/理解并发",
    "chunkIndex": 1,
    "totalChunks": 2,
    "startPos": 284,
    "endPos": 390,
    "originalTitle": "理解并发"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-0",
    "title": "Docker 镜像",
    "content": "Docker 镜像\n层次关系\nDocker 镜像的层次关系原理基于联合文件系统（Union File System），这种文件系统允许多个文件系统层次叠加在一起，表现为一个单一的文件系统。Docker 利用这一特性来构建和管理镜像和容器。\n联合文件系统（Union File System）\n联合文件系统（如 AUFS、OverlayFS、btrfs 等）是 Docker 的核心技术之一。它允许多个目录（称为层）叠加在一起，使其看起来像一个单一的目录。每一层都是只读的，只有最顶层是可写的。\nDocker 镜像层次结构\nDocker 镜像由多个只读层组成，每一层对应 Dockerfile 中的一条指令。这些层是增量的，即每一层只包含相对于前一层的变化。镜像层次结构的基本原理如下：",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 0,
    "totalChunks": 9,
    "startPos": 0,
    "endPos": 343,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-1",
    "title": "Docker 镜像 (第2段)",
    "content": "...一层只包含相对于前一层的变化。镜像层次结构的基本原理如下： 1. **基础镜像层**：这是镜像的最底层，通常是一个操作系统的基础镜像（如 、、 等）。它提供了运行应用所需的基本环境。\n2. **中间层**：每一条 Dockerfile 指令（如 、、 等）都会创建一个新的层。每个中间层只包含相对于前一层的变化。例如，安装软件包、复制文件等。\n3. **顶层**：这是镜像的最顶层，通常包含应用程序的代码和配置文件。\n容器层次结构\n当你启动一个容器时，Docker 会在镜像的基础上添加一个可写层，这个可写层称为容器层。容器层是唯一可写的层，所有对文件系统的修改（如创建新文件、修改现有文件等）都会发生在这一层。\n分层存储的优点",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 1,
    "totalChunks": 9,
    "startPos": 343,
    "endPos": 628,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-2",
    "title": "Docker 镜像 (第3段)",
    "content": "...新文件、修改现有文件等）都会发生在这一层。\n分层存储的优点 1. **高效存储**：由于每一层是只读的，并且是增量的，Docker 可以通过共享相同的基础层来节省存储空间。例如，多个基于同一基础镜像的容器可以共享该基础镜像的层。\n2. **快速构建**：构建镜像时，如果某一层已经存在且没有变化，Docker 可以直接重用该层，而不需要重新构建。这大大加快了镜像的构建速度。\n3. **缓存机制**：Docker 使用缓存机制来加速镜像的构建和部署。如果某一层已经存在于缓存中，并且没有变化，Docker 可以直接从缓存中获取该层，而不需要重新执行指令。\n示例：Docker 镜像和容器的层次关系\n假设我们有如下的 Dockerfile：\n构建镜像时，每一条指令都会创建一个新的层：\n1. **基础镜像层**：\n2. **工作目录层**：",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 2,
    "totalChunks": 9,
    "startPos": 628,
    "endPos": 968,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-3",
    "title": "Docker 镜像 (第4段)",
    "content": "...：\n1. **基础镜像层**：\n2. **工作目录层**： 3. **复制依赖文件层**：\n4. **安装依赖层**：\n5. **复制应用程序代码层**：\n6. **暴露端口层**：\n7. **运行应用程序层**：\n当你运行容器时，Docker 会在这些只读层的基础上添加一个可写层。所有对文件系统的修改都会发生在这个可写层中。\n联合文件系统（Union File System）\n联合文件系统（Union File System）如何允许多个文件系统层次叠加在一起，表现为一个单一的文件系统。例子：\n假设我们有三个不同的目录，每个目录代表一个文件系统层：\n1. **Layer 1**：包含基本的操作系统文件\n2. **Layer 2**：包含一些应用程序文件\n3. **Layer 3**：包含用户的数据文件，容器运行时的**可写层**\n目录结构",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 3,
    "totalChunks": 9,
    "startPos": 968,
    "endPos": 1314,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-4",
    "title": "Docker 镜像 (第5段)",
    "content": "...：包含用户的数据文件，容器运行时的**可写层**\n目录结构 **Layer 1**（基础操作系统层）\n**Layer 2**（应用程序层）\n**Layer 3**（用户数据层）\n叠加后的联合文件系统\n当我们使用联合文件系统将这三个层叠加在一起时，它们会表现为一个单一的文件系统：\n具体例子：Docker 镜像和容器\n让我们将这个概念应用到 Docker 镜像和容器上：\n1. **基础镜像（Layer 1）**：假设我们使用一个 Ubuntu 基础镜像，它包含了操作系统的基本文件。\n2. **应用程序层（Layer 2）**：我们在基础镜像上安装了一个应用程序，这会创建一个新的层。\n3. **用户数据层（Layer 3）**：容器运行时，用户在容器内创建或修改文件，这些变化会记录在一个可写层中。\n叠加后的文件系统",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 4,
    "totalChunks": 9,
    "startPos": 1314,
    "endPos": 1644,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-5",
    "title": "Docker 镜像 (第6段)",
    "content": "...修改文件，这些变化会记录在一个可写层中。\n叠加后的文件系统 当我们启动容器时，Docker 会将这些层叠加在一起，表现为一个单一的文件系统：\n用户在容器内看到的文件系统就像是一个完整的文件系统，尽管它实际上是由多个层叠加而成的。\n写时复制\n在写时复制机制（Copy-on-Write, CoW）下，可能存在两份  文件，一份在只读层（lower layer），一份在可写层（upper layer）。但是，从文件系统的视图来看，用户只会看到一份文件。具体来说，这样的设计是为了在保证只读层数据不变的同时允许用户修改文件。以下是更详细的解释：\n联合文件系统视图\n联合文件系统通过叠加多个层来形成一个合并视图，用户只会看到合并后的文件系统视图，而不是底层的具体实现。\n文件叠加机制\n1. **查找文件**：",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 5,
    "totalChunks": 9,
    "startPos": 1644,
    "endPos": 1966,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-6",
    "title": "Docker 镜像 (第7段)",
    "content": "...是底层的具体实现。\n文件叠加机制\n1. **查找文件**： 当用户访问  文件时，联合文件系统首先在可写层（upper layer）中查找。\n如果可写层中找不到该文件，则继续查找只读层（lower layer）。\n2. **写时复制过程**：\n如果用户对  文件进行修改，并且该文件在只读层中存在（可写层中不存在），则联合文件系统会将该文件从只读层复制到可写层。\n所有的修改操作都会在可写层中的副本上进行。\n确保数据完整性\n这种机制确保了只读层的文件不会被直接修改，从而保持了其完整性。同时，用户对文件的修改操作仍然可以进行，只是这些修改会反映在可写层中。\n实际示例\n假设有一个联合文件系统，其中只读层和可写层的初始状态如下：\n**只读层（lower layer）**：\n**可写层（upper layer）**：\n当用户修改  文件时，文件系统执行以下步骤：",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 6,
    "totalChunks": 9,
    "startPos": 1966,
    "endPos": 2317,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-7",
    "title": "Docker 镜像 (第8段)",
    "content": "...er）**：\n当用户修改  文件时，文件系统执行以下步骤： 1. **查找**：\n在可写层中查找 ，未找到。\n在只读层中查找 ，找到该文件。\n2. **复制**：\n将  文件从只读层复制到可写层。\n3. **修改**：\n在可写层中的副本上进行修改。\n修改后的文件系统层次结构如下：\n**只读层（lower layer）**：\n**可写层（upper layer）**：\n用户视图\n用户通过文件系统看到的合并视图如下：\n从用户的角度来看，他们看到的只是一个文件系统，其中  文件已被修改，而不会意识到底层存在两份  文件。\n具体应用\n**Docker容器**：Docker容器的文件系统利用联合文件系统叠加多个只读层（来自Docker镜像的各层）和一个可写层（容器的读写层）。容器启动后，所有对文件的修改都在可写层进行，而镜像层保持不变。",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 7,
    "totalChunks": 9,
    "startPos": 2317,
    "endPos": 2656,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/Docker 的理解#chunk-8",
    "title": "Docker 镜像 (第9段)",
    "content": "...启动后，所有对文件的修改都在可写层进行，而镜像层保持不变。 **Linux Live CD**：Live CD系统通常是只读的，但用户可以在会话期间对文件进行修改。这些修改被写入到一个临时的可写层（如RAM），原始的CD内容不变。\n总结\n在联合文件系统中，通过写时复制机制，文件系统可以在只读层中保持文件的原始状态不变，同时允许用户对文件进行修改。这种机制在保持数据完整性和一致性的同时，提供了灵活的文件管理能力。虽然底层可能存在两份文件（原始和副本），但用户看到的是一个统一的、合并的文件系统视图。",
    "url": "/blog/Docker 的理解",
    "chunkIndex": 8,
    "totalChunks": 9,
    "startPos": 2656,
    "endPos": 2876,
    "originalTitle": "Docker 镜像"
  },
  {
    "chunkId": "/blog/SSR原理浅析#chunk-0",
    "title": "Vue SSR",
    "content": "Vue SSR\nssr hydrate 原理\n基本猜想： \n1. 按照层级匹配，只在不匹配的时候报错，层次正确即可\n2. 只在data-server-rendered=\"true\"的时候hydrate，随后移除data-server-rendered\nserver.html\nwill match client\nbut not match client\n协同的库\nvue-lazy-hydrate原理\n服务端：\n1. hydrate=true -> 根据component 渲染出来的正常 html\n客户端：\n将组件封装成 async component，在条件成熟的时候resolve（浏览器空闲/dom可见/事件触发）\n结论\n原理上不是真实意义上的hydrate，而是异步组件的渲染；",
    "url": "/blog/SSR原理浅析",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 345,
    "originalTitle": "Vue SSR"
  },
  {
    "chunkId": "/blog/SSR原理浅析#chunk-1",
    "title": "Vue SSR (第2段)",
    "content": "...原理上不是真实意义上的hydrate，而是异步组件的渲染； 所以如果一个组件在转换成 async的时候会出问题（例如：会有跟激活的组件的交互），那就不适用这个package\nvue-client-only原理\n原理：vue-client-only 组件的 render 函数简单封装\n服务端返回h(false) 占位\n客户端：根据parent._isMounted 返回正常组件 （在浏览器mounted的时候）\n坑\nin NuxtJs框架\nin dev : true(代表plugin middleware等文件会在每个请求进入的时候重新载入)\nin production: false （代表不会重新载入plugin，只会反复执行返回的函数）\nSSR runInNewContext demo\n1. bundle code\n./vue-ssr.js",
    "url": "/blog/SSR原理浅析",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 345,
    "endPos": 692,
    "originalTitle": "Vue SSR"
  },
  {
    "chunkId": "/blog/SSR原理浅析#chunk-2",
    "title": "Vue SSR (第3段)",
    "content": "...o\n1. bundle code\n./vue-ssr.js reference\nnode vm\nnode module\nnode require解析\nvue ssr in depth\nvue ssr in depth2",
    "url": "/blog/SSR原理浅析",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 692,
    "endPos": 771,
    "originalTitle": "Vue SSR"
  },
  {
    "chunkId": "/blog/SSR工程结构图解#chunk-0",
    "title": "vite/webpack 之 vue ssr 图解",
    "content": "vite/webpack 之 vue ssr 图解\nwebpack + vue ssr图解\n!webpack+vue ssr图解\nvite + vue ssr图解\n!vite + vue ssr图解\nssr框架 webpack + vue ssr图解\n!ssr框架 webpack + vue ssr图解\nssr框架 vite + vue ssr图解\n!ssr框架 vite + vue ssr图解",
    "url": "/blog/SSR工程结构图解",
    "chunkIndex": 0,
    "totalChunks": 1,
    "startPos": 0,
    "endPos": 199,
    "originalTitle": "vite/webpack 之 vue ssr 图解"
  },
  {
    "chunkId": "/blog/Type Array 应用场景#chunk-0",
    "title": "Float32Array 应用场景",
    "content": "Float32Array 应用场景\n 是 JavaScript 中的一种类型数组，它代表平台字节顺序为 32 位的浮点数型数组（对应于 C 浮点数据类型）。让我们探讨一下  的应用场景和特性：\n1. **数值计算和底层二进制数据处理**：\n存储的是单精度浮点数，每个元素占据 4 个字节。这使得它在处理大量数值计算时更加节省内存。\n连续的内存空间存储使得在进行数学运算时效率更高，从而提高性能.\n2. **音频和图像处理**：\n在音频处理中， 可以存储音频样本数据，例如音频波形、频谱分析等。\n图像处理中的像素值也可以使用  存储（利用其高精度），例如图像滤波、变换等。\n3. **WebGL 和 WebGPU**：",
    "url": "/blog/Type Array 应用场景",
    "chunkIndex": 0,
    "totalChunks": 6,
    "startPos": 0,
    "endPos": 309,
    "originalTitle": "Float32Array 应用场景"
  },
  {
    "chunkId": "/blog/Type Array 应用场景#chunk-1",
    "title": "Float32Array 应用场景 (第2段)",
    "content": "...波、变换等。\n3. **WebGL 和 WebGPU**： 在图形渲染领域非常重要。WebGL 和 WebGPU 使用  来处理图形数据，例如顶点坐标、纹理坐标、颜色等。\n在这些图形库中，使用  可以高效地传递数据给 GPU 进行并行计算和渲染。\n4. **二进制数据传输和解析**：\n可以用于处理二进制数据，例如网络传输中的数据包、文件解析等。\n通过  和 ，可以将二进制数据转换为 ，并进行解析。\nFloat32Array 优势\n当然可以。 的优势主要体现在以下几个方面：\n1. 内存效率\n 是固定大小的，并且在内存中是连续存储的。它直接映射到计算机的浮点数表示，这意味着它可以非常高效地使用内存。相比之下，普通的 JavaScript 数组是动态的，可以包含不同类型的元素，因此它们需要更多的内存开销来存储额外的信息，比如元素类型和指针。\n2. 性能优化",
    "url": "/blog/Type Array 应用场景",
    "chunkIndex": 1,
    "totalChunks": 6,
    "startPos": 309,
    "endPos": 660,
    "originalTitle": "Float32Array 应用场景"
  },
  {
    "chunkId": "/blog/Type Array 应用场景#chunk-2",
    "title": "Float32Array 应用场景 (第3段)",
    "content": "...开销来存储额外的信息，比如元素类型和指针。\n2. 性能优化 由于  中的数据是类型化的（即数组中的每个元素都是相同类型的），JavaScript 引擎可以对操作这些数组的代码进行优化。编译器知道数组中的每个元素都是32位浮点数，因此它可以在底层使用更快的算法和指令集来处理这些数据。\n3. 数据一致性\n 保证了数组中的每个元素都是32位浮点数。这种一致性确保了当你处理科学计算、图形渲染或者音频处理等需要精确浮点运算的应用时，数据的表现是可预测的。\n4. 与底层硬件的接近性\n 更接近硬件层面的表示，因为现代计算机硬件通常都是针对固定大小和类型的数据进行优化的。这意味着读取和写入这些数组的操作可以非常迅速，因为它们可以直接映射到硬件操作。\n5. 二进制操作的便利性",
    "url": "/blog/Type Array 应用场景",
    "chunkIndex": 2,
    "totalChunks": 6,
    "startPos": 660,
    "endPos": 964,
    "originalTitle": "Float32Array 应用场景"
  },
  {
    "chunkId": "/blog/Type Array 应用场景#chunk-3",
    "title": "Float32Array 应用场景 (第4段)",
    "content": "...因为它们可以直接映射到硬件操作。\n5. 二进制操作的便利性 使用  可以直接读取和写入二进制数据流，这在处理网络传输和文件 I/O 操作时非常有用。例如，你可以直接从一个  创建一个 ，而不需要进行任何转换。这使得在客户端和服务器之间传输浮点数数据变得更加简单和快速。\n6. 传输效率\n在网络传输中，使用  可以直接发送和接收二进制数据，而不需要将浮点数转换为字符串或其他格式。这减少了数据的大小，因此可以加快传输速度并减少带宽使用。\n7. Web APIs 的兼容性\n许多 Web API 都是围绕类型化数组设计的，这意味着  可以直接用于这些 API，无需额外的转换或包装。这使得在使用 WebGL、Web Audio API 等技术时， 成为处理和传输数据的自然选择。\n实际例子",
    "url": "/blog/Type Array 应用场景",
    "chunkIndex": 3,
    "totalChunks": 6,
    "startPos": 964,
    "endPos": 1277,
    "originalTitle": "Float32Array 应用场景"
  },
  {
    "chunkId": "/blog/Type Array 应用场景#chunk-4",
    "title": "Float32Array 应用场景 (第5段)",
    "content": "...PI 等技术时， 成为处理和传输数据的自然选择。\n实际例子 一个手动创建的二进制序列化过程，它类似于Protocol Buffers（Protobuf）的工作原理；例子：\n从一个二进制WebSocket流中接收数据，这个流包含了一个复合结构的数据包，其中既有字符串也有浮点数。\n假设服务器发送的数据包格式如下：\n4个字节的整数，表示用户ID\n32个字节的字符串，表示用户名\n4个字节的单精度浮点数，表示用户的账户余额\n这个数据包总共占用40个字节，我们的任务是从这个二进制流中解析出这三个字段。\n首先，我们会接收到一个  对象，其中包含了这40个字节的数据。我们需要按照正确的顺序和数据类型来解析这些数据。\n**发送方有以下数据：**\n发送方将执行以下步骤来序列化这些数据：\n**接收方**\n在这个例子中：\n是原始的二进制数据。\n被用来解析整数和浮点数字段。",
    "url": "/blog/Type Array 应用场景",
    "chunkIndex": 4,
    "totalChunks": 6,
    "startPos": 1277,
    "endPos": 1627,
    "originalTitle": "Float32Array 应用场景"
  },
  {
    "chunkId": "/blog/Type Array 应用场景#chunk-5",
    "title": "Float32Array 应用场景 (第6段)",
    "content": "...子中：\n是原始的二进制数据。\n被用来解析整数和浮点数字段。 被用来获取用户名的字节，然后使用  将这些字节解码成字符串。\n没有直接使用，但如果我们有多个浮点数需要处理，我们可以创建一个  视图来直接操作这些浮点数。\n与手动处理二进制数据相比，Protobuf提供了以下优势：\n效率： Protobuf设计用来在网络上高效传输数据，它的编码通常比JSON小很多。\n跨平台： Protobuf支持多种编程语言，可以轻松地在不同的系统和语言之间传输数据。\n可扩展性： Protobuf设计了向后和向前兼容，你可以更改数据结构而不破坏已部署的程序之间的通信。\n自动代码生成： Protobuf提供了代码生成工具，可以自动为多种语言生成序列化和反序列化代码，减少了手动编码的错误和工作量。\nReference\nGPT",
    "url": "/blog/Type Array 应用场景",
    "chunkIndex": 5,
    "totalChunks": 6,
    "startPos": 1627,
    "endPos": 1950,
    "originalTitle": "Float32Array 应用场景"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-0",
    "title": "vite简介与原理",
    "content": "vite简介与原理\n**讲解范围**\n0. 背景\n1. vite是什么\n2. 特征: 冷启动 + 热更新\n3. C/S 基本架构\n3. 预处理: 解决的问题 + 原理\n4. 热替换：如何使用 + 原理\n5. 其它：插件机制 + 竞品走势 + 总结 + QA\n背景\n目前的webpack development 场景也会把所有可能用到的代码全部进行打包构建，这样打包出来的代码是十分庞大的，很多时候其实我们在开发过程中并不需要全部代码的功能，而是一小部分，这个时候大量的构建时间都是多余的，我们需要一个能够真正意义上实现懒加载的开发工具。\nvite 是什么？",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 0,
    "totalChunks": 11,
    "startPos": 0,
    "endPos": 279,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-1",
    "title": "vite简介与原理 (第2段)",
    "content": "...个能够真正意义上实现懒加载的开发工具。\nvite 是什么？ Vite 是一个由原生ESM 驱动的 Web 开发构建工具。在开发环境下基于浏览器原生ES imports 开发，在生产环境下基于Rollup打包。\n在浏览器端使用 export、import 的方式导入和导出模块，在 script 标签里设置 type=\"module\"，浏览器会识别所有添加了type='module'的script标签，对于该标签中的import关键字，浏览器会发起http请求获取模块内容。\n特征\n缓慢的启动\n**vite之前**\n当冷启动开发服务器时，基于打包器的方式启动必须优先抓取并构建你的整个应用，然后才能提供服务。\n!传统bundle\n**vite后**\n!ESM 的构建模式",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 1,
    "totalChunks": 11,
    "startPos": 279,
    "endPos": 585,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-2",
    "title": "vite简介与原理 (第3段)",
    "content": "...传统bundle\n**vite后**\n!ESM 的构建模式 灰色部分是暂时没有用到的路由，甚至完全不会参与构建过程，随着项目里的路由越来越多，构建速度也不会变慢。\n缓慢的更新\n**vite之前**\n第一阶段：\n打包器的开发服务器将构建内容存入内存，修改后重新构建并重载页面（代价很高 + 重新加载页面会消除应用的当前状态）\n第二阶段：\nHMR 热更新（主流的webpack），允许一个模块 “热替换” 它自己，而对页面其余部分没有影响。\n实践中：不过HMR也会随着应用规模的增长而显著下降\n**vite后**\nHMR 是在原生 ESM 上执行的。当编辑一个文件时，Vite 只需要精确地使已编辑的模块与其最近的 HMR 边界之间的链失效（大多数时候只需要模块本身），使 HMR 更新始终快速，无论应用的大小。\n基本架构\n!基本架构图",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 2,
    "totalChunks": 11,
    "startPos": 585,
    "endPos": 922,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-3",
    "title": "vite简介与原理 (第4段)",
    "content": "...R 更新始终快速，无论应用的大小。\n基本架构\n!基本架构图 1. server 预构建 -> 启用服务 node + connect + ws\n2. 浏览器请求 -> server中间件处理 -> server插件调用（（路径改写，hot注入，依赖图生成） -> 返回 client\n预构建\n!预构建图\n基于 esbuild 的**依赖**预打包\n1. 减少模块/请求数量；\n2. 支持 CommonJS 依赖。\n预打包只有在依赖变动时才需要执行，但在有大量依赖的项目中，每次执行还是可能会需要很长时间。Vite 之前是使用 Rollup 来执行这个过程，在 2.0 中切换到了 esbuild，使这个过程加快了几十倍。\nVite 通过在一开始将应用中的模块区分为 依赖 和 源码 两类，改进了开发服务器启动时间。",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 3,
    "totalChunks": 11,
    "startPos": 922,
    "endPos": 1250,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-4",
    "title": "vite简介与原理 (第5段)",
    "content": "...块区分为 依赖 和 源码 两类，改进了开发服务器启动时间。 1. **依赖** 大多为在开发时不会变动的纯 JavaScript，例如 node_modules 等第三方依赖\n2. **源码** 通常包含一些时常被编辑的文件\n场景\nimport { debounce } from 'lodash' 导入一个命名函数的时候，debounce 函数的模块内部又依赖了很多其他函数，形成了一个依赖图。\n当浏览器请求 debounce 的模块时，又会发现内部有 2 个 import，再这样延伸下去，这个函数内部可能带来了几百次请求。\n!优化依赖\n解决方案\n折中",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 4,
    "totalChunks": 11,
    "startPos": 1250,
    "endPos": 1499,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-5",
    "title": "vite简介与原理 (第6段)",
    "content": "...函数内部可能带来了几百次请求。\n!优化依赖\n解决方案\n折中 利用 Esbuild 快速的构建编译速度，在没有感知的情况下在启动的时候预先帮你把 debounce 所用到的所有内部模块全部打包成一个传统的 js bundle（构建好的bundle会放在node_modules/.vite下），后续对 A module的引用都直接返回 .vite/A 文件内容\nEsbuild 使用 Go 编写，并且比以 JavaScript 编写的打包器预构建依赖快 10-100 倍。\n!构建速度对比\nHMR（热替换）\ndemo\n1. self accept\ndemo .vue css\ndemo .vue template\ndemo .vue script\n2. array accept (not self accept)",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 5,
    "totalChunks": 11,
    "startPos": 1499,
    "endPos": 1826,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-6",
    "title": "vite简介与原理 (第7段)",
    "content": "...rray accept (not self accept) demo https://github.com/wizardpisces/lerna-repo/tree/master/packages/mini-vite/template-vue-ts/src/mimic-store\n原理\n!构建HMR图\n!HMR交互图\n**server build moduleGraph**\n分析 源文件 import -> build 父子关系图\n分析 源文件 import.meta.hot -> build 热替换依赖图\n**client build hotModulesMap**\nvite 插件机制\n!插件图例子 vite-plugin-vue",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 6,
    "totalChunks": 11,
    "startPos": 1826,
    "endPos": 2117,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-7",
    "title": "vite简介与原理 (第8段)",
    "content": "...e 插件机制\n!插件图例子 vite-plugin-vue 在 rollup 插件基础上 扩展出 vite 的 plugin API，以及执行机制。好处：一套插件可能在 rollup 跟 vite 同时兼容使用（如果并未使用vite独有的插件hook），扩大 vite的生态圈，直接运行大部分的 rollup插件\n趋势\nsnowpack vs vite\n总结\nvite已经出到版本2，目前spa项目用起来没发现什么特别问题\n内部项目(admin)可以开始先尝试 Vite\nSSR 目前处在实验阶段，还需等待\nQA\n是否会取代 webpack？\n目前看起来不会\n**原因：**\nwebpack能覆盖更多的奇特的场景，生态也更丰富\nvite还有哪些问题？\n1. 服务端渲染 (SSR) 支持还处在实验阶段，产线使用仍需等待",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 7,
    "totalChunks": 11,
    "startPos": 2117,
    "endPos": 2447,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-8",
    "title": "vite简介与原理 (第9段)",
    "content": "...务端渲染 (SSR) 支持还处在实验阶段，产线使用仍需等待 修改 node_modules 源文件是否触发热更新？\n不会\n如何入手 vite 源码\n简化版 vite，供初入坑\n**原因：**\n由于预构建，node_modules里面的源代码已经被打包到 node_modules/.vite下面，目前此路径并未注册到热替换图里面\n**多种构建工具的比对**\n1. webpack :强调对web开发的支持，尤其是内置了HMR的支持，插件系统比较强大，对各种模块系统兼容性最佳(amd,cjs,umd,esm等，兼容性好的有点过分了，这实际上有利有弊,导致面向webpack编程），有丰富的生态，缺点是产物不够干净，产物不支持生成esm格式， 插件开发上手较难，不太适合库的开发。",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 8,
    "totalChunks": 11,
    "startPos": 2447,
    "endPos": 2757,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-9",
    "title": "vite简介与原理 (第10段)",
    "content": "...支持生成esm格式， 插件开发上手较难，不太适合库的开发。 2. rollup: 强调对库开发的支持，基于ESM模块系统，对tree shaking有着良好的支持，产物非常干净，支持多种输出格式，适合做库的开发，插件api比较友好，缺点是对cjs支持需要依赖插件，且支持效果不佳需要较多的hack，不支持HMR，做应用开发时需要依赖各种插件。\n3. esbuild: 强调性能，内置了对css、图片、react、typescript等内置支持，编译速度特别快（是webpack和rollup速度的100倍+),缺点是目前插件系统较为简单（框架作者还在迭代中），生态不如webpack和rollup成熟。\nReference",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 9,
    "totalChunks": 11,
    "startPos": 2757,
    "endPos": 3039,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/Vite简介与原理#chunk-10",
    "title": "vite简介与原理 (第11段)",
    "content": "...不如webpack和rollup成熟。\nReference https://github.com/wizardpisces/lerna-repo/tree/master/packages/mini-vite\nhttps://vitejs.dev/guide/\nhttps://github.com/evanw/esbuild\nhttps://segmentfault.com/a/1190000039264055\n下期预告\nvite ssr简介",
    "url": "/blog/Vite简介与原理",
    "chunkIndex": 10,
    "totalChunks": 11,
    "startPos": 3039,
    "endPos": 3231,
    "originalTitle": "vite简介与原理"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-0",
    "title": "为什么需要隔离",
    "content": "为什么需要隔离\n防止控件之间样式覆盖，特别在微前端应用场景（例如 qiankun ），良好的隔离能够降低样式污染\n几种隔离方案原理\nScoped\nVue 中的  属性是一个特殊的属性，可以添加到  标签上，以确保样式只应用于当前组件的元素，而不泄露到外部。其工作原理基于以下几个步骤：\n1. **唯一属性标识**：当你在  标签上加上  属性后，Vue 会为每个组件生成一个唯一的 data 属性（例如 ）。这个属性是随机的，并且对于每个组件都是独一无二的。",
    "url": "/blog/css 隔离",
    "chunkIndex": 0,
    "totalChunks": 8,
    "startPos": 0,
    "endPos": 230,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-1",
    "title": "为什么需要隔离 (第2段)",
    "content": "...如 ）。这个属性是随机的，并且对于每个组件都是独一无二的。 2. **后处理 CSS**：Vue 通过其构建工具（如 webpack 加上 vue-loader）在编译过程中处理这些  样式。它会自动将上述生成的唯一 data 属性作为选择器添加到所有的 CSS 规则中。这意味着，这些样式只会匹配带有相应 data 属性的元素。\n3. **更新模板**：在编译组件模板时，Vue 会自动将相应的 data 属性添加到所有模板中的元素上。因此，这些元素将与  样式中的选择器匹配。\n4. **防止样式泄露**：由于这些 data 属性是唯一的，因此样式只能匹配到拥有相应 data 属性的元素。这就确保了样式只会应用于当前组件内的元素，而不会影响到其他组件的元素。",
    "url": "/blog/css 隔离",
    "chunkIndex": 1,
    "totalChunks": 8,
    "startPos": 230,
    "endPos": 533,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-2",
    "title": "为什么需要隔离 (第3段)",
    "content": "...式只会应用于当前组件内的元素，而不会影响到其他组件的元素。 这样的处理方式确保了组件样式的封闭性，避免了全局样式污染。但是，这种方法也有它的局限性，比如它不能很好地处理子组件的样式覆盖问题，因为子组件的根节点不会被父组件的 scoped 样式所影响。对于这种情况，Vue 提供了深度选择器  或 （在某些 SCSS 预处理器中使用 ），以便可以强制样式穿透到子组件中。\n总的来说，Vue 的  CSS 功能是通过自动添加唯一的属性选择器到组件的样式规则，并将这些选择器应用于带有对应属性的元素，从而实现样式封装和隔离的。\nCSS Modules\nCSS Modules 是一种 CSS 文件模块化方案，它的主要目标是解决全局 CSS 命名冲突的问题，从而实现样式的局部作用域。这种方法在 React 社区中非常流行。其工作原理基于以下几个步骤：",
    "url": "/blog/css 隔离",
    "chunkIndex": 2,
    "totalChunks": 8,
    "startPos": 533,
    "endPos": 876,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-3",
    "title": "为什么需要隔离 (第4段)",
    "content": "...React 社区中非常流行。其工作原理基于以下几个步骤： 1. **生成唯一类名**：CSS Modules 在构建过程中，会为每个 CSS 类名生成一个唯一的、全局唯一的标识符。这个标识符通常是由原始类名和一些其他信息（如文件名、路径、哈希值等）组成的，确保了在全局范围内的唯一性。\n2. **构建 CSS 文件**：CSS Modules 将修改过的类名写入构建后的 CSS 文件。这样，每个组件的样式都有自己的唯一类名，避免了不同组件间的样式冲突。\n3. **导出类名映射**：CSS Modules 会导出一个 JavaScript 对象，这个对象是原始类名到生成的唯一类名的映射。这就是为什么我们可以使用  这样的语法来导入 CSS Module， 对象就包含了这个映射。",
    "url": "/blog/css 隔离",
    "chunkIndex": 3,
    "totalChunks": 8,
    "startPos": 876,
    "endPos": 1189,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-4",
    "title": "为什么需要隔离 (第5段)",
    "content": "...语法来导入 CSS Module， 对象就包含了这个映射。 4. **使用类名**：在 React 组件中，我们可以使用这个映射来为元素应用样式。例如，，这里的  就是生成的唯一类名。\n这种方法的优点是可以确保样式的封装性，避免了全局样式污染。缺点是需要配置构建工具（如 webpack），并且不支持直接在 CSS 中使用其他组件的样式，因为每个组件的样式都是封装的。\nCSS Modules 的原理就是通过在构建过程中为每个 CSS 类名生成一个全局唯一的标识符，然后在 JavaScript 中使用这个标识符来应用样式，从而实现样式的局部作用域。\n缺陷\n**不方便做样式覆盖**\n例如：需要对 ant-table 做样式覆盖，则需要  的 jsx 显示覆盖，更期望只对外层的 css 做类似 Vue 的 scoped，而不是每个使用的地方都写 ；",
    "url": "/blog/css 隔离",
    "chunkIndex": 4,
    "totalChunks": 8,
    "startPos": 1189,
    "endPos": 1535,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-5",
    "title": "为什么需要隔离 (第6段)",
    "content": "...似 Vue 的 scoped，而不是每个使用的地方都写 ； styled-components\n 是一个在 React 和其他 JavaScript 库中实现 CSS-in-JS 的库。它使用 JavaScript 来编写 CSS，使得组件的样式和逻辑可以在同一个地方定义，而且可以利用 JavaScript 的全部功能来创建动态的样式。 的样式隔离原理基于以下几个步骤：\n1. **创建样式化组件**：首先，你会使用  提供的 API 来创建一个样式化组件。这个 API 接收一个模板字符串，其中包含你的 CSS 规则，然后返回一个新的 React 组件。这个新的组件会将这些 CSS 规则应用到它呈现的元素上。\n2. **生成唯一类名**：当你创建一个样式化组件时， 会为这个组件生成一个唯一的类名。这个类名是全局唯一的，因此不会与其他组件的样式发生冲突。",
    "url": "/blog/css 隔离",
    "chunkIndex": 5,
    "totalChunks": 8,
    "startPos": 1535,
    "endPos": 1886,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-6",
    "title": "为什么需要隔离 (第7段)",
    "content": "...。这个类名是全局唯一的，因此不会与其他组件的样式发生冲突。 3. **插入样式**： 会将你的 CSS 规则插入到一个样式标签中，并且将生成的唯一类名添加到这些规则中。这个样式标签通常被插入到  元素中。\n4. **应用样式**：当你使用样式化组件时，它会将生成的唯一类名添加到呈现的元素的  属性中。这样，这个元素就会接收到你在样式化组件中定义的样式。\n这种方法的优点是，它不仅可以实现样式的封装性，而且可以利用 JavaScript 的全部功能来创建动态的、复杂的样式。它的缺点是，可能会**增加运行时的复杂性**，因为样式是在运行时插入到文档中的，而不是在构建时。此外，它也需要一些学习成本，因为你需要习惯在 JavaScript 中编写 CSS。",
    "url": "/blog/css 隔离",
    "chunkIndex": 6,
    "totalChunks": 8,
    "startPos": 1886,
    "endPos": 2184,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/css 隔离#chunk-7",
    "title": "为什么需要隔离 (第8段)",
    "content": "...，因为你需要习惯在 JavaScript 中编写 CSS。 总的来说， 的原理是通过在 JavaScript 中创建样式化组件，然后为每个组件生成一个唯一的类名，将这个类名和对应的 CSS 规则插入到文档中，从而实现样式的封装和隔离。",
    "url": "/blog/css 隔离",
    "chunkIndex": 7,
    "totalChunks": 8,
    "startPos": 2184,
    "endPos": 2271,
    "originalTitle": "为什么需要隔离"
  },
  {
    "chunkId": "/blog/forwardRef 的思考#chunk-0",
    "title": "为什么 ref 没法直接传递？",
    "content": "为什么 ref 没法直接传递？\n可能原因：\n1. **封装**：React 强调组件的封装，即组件应该管理和控制自己的状态和行为。 是访问组件内部 DOM 节点的一种方式，如果  能够像普通的 prop 那样传递，那么组件的内部节点就可以被外部的父组件随意访问和修改，这破坏了封装性。\n2. **所有权原则**：在 React 中，每个  有一个拥有者 —— 创建它的组件。这个原则确保了  的使用是明确和可控的。如果  能够像普通的 prop 那样自由传递，那么它的所有权就会变得模糊，可能导致不同组件意外地共享对同一个 DOM 节点的引用。",
    "url": "/blog/forwardRef 的思考",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 273,
    "originalTitle": "为什么 ref 没法直接传递？"
  },
  {
    "chunkId": "/blog/forwardRef 的思考#chunk-1",
    "title": "为什么 ref 没法直接传递？ (第2段)",
    "content": "...，可能导致不同组件意外地共享对同一个 DOM 节点的引用。 3. **抽象泄漏**：组件应该暴露出一个明确的 API，而  直接关联到 DOM 节点或组件实例，这意味着组件的内部实现细节被暴露给了父组件。这种抽象泄漏可能会导致父组件过分依赖子组件的内部结构，使得重构变得困难。\n4. **使用  的明确性**：通过  明确地传递 ，组件库的作者可以决定哪些内部元素可以被父组件访问。这样做可以确保  的使用是有意为之，并且对组件的内部结构有清晰的认识。\n总之， 没法直接传递是为了保持组件的封装性，维护组件间清晰的边界，并确保组件的抽象不被破坏。当需要将  传递给子组件时，React 提供了  API 作为一种明确和有控制的方式来实现这一点。\n简单实现",
    "url": "/blog/forwardRef 的思考",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 273,
    "endPos": 571,
    "originalTitle": "为什么 ref 没法直接传递？"
  },
  {
    "chunkId": "/blog/forwardRef 的思考#chunk-2",
    "title": "为什么 ref 没法直接传递？ (第3段)",
    "content": "...API 作为一种明确和有控制的方式来实现这一点。\n简单实现 在这个简化的实现中， 函数返回一个新的组件，这个组件接收一个特殊的属性 。这个属性是父组件传递下来的 。然后， 函数中的类组件将  作为参数传递给  函数。\n在  组件中，我们创建了一个 ref () 并将其作为  属性传递给 。因为  是用我们的简化版  创建的，它能够接收并使用这个 。\n这个简化的实现演示了  的核心概念，但请注意，这并不是 React 实际上如何实现  的。React的实现包含更多的细节和优化，以确保正确处理生命周期方法、hooks 等。如果你想要在生产环境中使用 ，请使用 React 提供的官方  API。",
    "url": "/blog/forwardRef 的思考",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 571,
    "endPos": 839,
    "originalTitle": "为什么 ref 没法直接传递？"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-0",
    "title": "框架设计的思考",
    "content": "（时间：2021-12-2，最后更新时间2022-1-13）\n框架设计的思考\n文章内容主要基于2019 JSConf.Asia - 尤雨溪在框架设计中寻求平衡 + 自身对vue,react-hook,svelte的简单实现后的思考总结\n状态管理\n大致种类：\n1. Mutable vs Immutable\n2. Dependency Tracking vs Dirty Tracking\n3. Reactivity vs Simulated Reactivity\neg:\nvue偏向OOP(Object Oriented Program)编程模型; 驱动视图偏向data mutable tracking",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 0,
    "totalChunks": 9,
    "startPos": 0,
    "endPos": 303,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-1",
    "title": "框架设计的思考 (第2段)",
    "content": "...; 驱动视图偏向data mutable tracking React偏向FP(Functioanl Program)编程模型；驱动视图偏向data immutable快照更新\nAngular Dirty Tracking\nSvelte 偏向编译时的 Dirty Tracking\n渲染机制；Render Mechanism\n大致种类：\n1. JSX vs Template （动态渲染函数和基于静态字符串的复杂的 Vue 表达式）\n2. Expressiveness vs Raw Perf （表现力和原生性能）\n3. Runtime Scheduling vs AOT（运行时调度和提前优化）\nJSX 表现力强，但是没法做静态编译优化\nTemplate 失去了很多表现力，受限于模板语法，但是可以做静态编译优化\neg:",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 1,
    "totalChunks": 9,
    "startPos": 303,
    "endPos": 635,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-2",
    "title": "框架设计的思考 (第3段)",
    "content": "...很多表现力，受限于模板语法，但是可以做静态编译优化\neg: vue jsx/Virtual-DOM + template，编译成render函数\n主要方向是 template 的静态优化\nreact jsx/Virtual-DOM，编译成render函数\n主要方向是 JSX + 运行时调度优化，提升用户**感知性能**，例如：时间切片（调度也耗时）\nangular 基于template的，它们将模板编译成相对较低级别的指令来进行内容渲染，基于Incremental DOM更新（相对Virtual-DOM diff节省内存，同时更费CPU，所以是一个CPU跟内存的取舍）\n主要方向是：待补充\nsvelte（一种编译器框架） 编译生成指令更新，基本无runtime调度",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 2,
    "totalChunks": 9,
    "startPos": 635,
    "endPos": 941,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-3",
    "title": "框架设计的思考 (第4段)",
    "content": "...种编译器框架） 编译生成指令更新，基本无runtime调度 缺点：包大小会随着工程增长而成比较陡峭线性增长；受限于模板语法，所以有很多心智负担？级别越低的编译输出，很难将你的自定义操作与它进行挂钩，就好比你无法使用 C 语言去调试你的汇编代码\n主要方向 AOT优化，缩小编译体积，例如对编译指令大小的优化\n框架层面\nVue\nreact < vue编译时 < svelte\nreact > vue运行时 > svelte\n一句话运行原理\n**运行时模板一次性依赖收集**\n~~运行时**关联变量更新操作与组件的更新函数**，变量变动时触发对应组件的更新函数~~\nAPI：ref vs reactive\n调用方式\n1. reactive只能传入对象，方便数据的访问；",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 3,
    "totalChunks": 9,
    "startPos": 941,
    "endPos": 1243,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-4",
    "title": "框架设计的思考 (第5段)",
    "content": "...方式\n1. reactive只能传入对象，方便数据的访问； 2. ref 能传任意值，会创建一个 ref 对象，主要暴露 .value 属性，对value是Object的情况会用 reactive再次封装；\n所以 ref 可以理解成对 reactive 的再次封装，处理了 primary reactive场景，同时解决了 对象整体替换的烦恼\nimmutable vs mutable\n1. reactive 是 mutable 模式的数据 tracking；\n2. ref 是 immutable 模式的数据 tracking；能传 ref\n开发体验\n细粒度的热更新：在同一组件层面还能区分只对样式、模板或者js逻辑更新\nReact-Hooks\n轻编译重运行时\n一句话运行原理\n**运行时反复依赖处理**",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 4,
    "totalChunks": 9,
    "startPos": 1243,
    "endPos": 1567,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-5",
    "title": "框架设计的思考 (第6段)",
    "content": "...轻编译重运行时\n一句话运行原理\n**运行时反复依赖处理** ~~运行时通过hooks调用顺序**关联hooks(eg:setData)跟函数组件**，做后续hook调用触发对应函数组件更新~~\nSvelte深入\n重编译轻运行时\n一句话运行原理\n**编译时模板一次性依赖收集**\n~~编译时通过**收集模板对变量的引用顺序编译出真实事件函数与更新函数**，做后续事件精准更新~~\n一句话调度原理\n利用浏览器的 microTask 或者 macroTask 做组件树更新的批量处理\n关于调度\n1. 基本调度单元?\n>组件的更新函数\n2. 如何调度父组件更新又触发子组件的更新？\n动态修改调度的数组，保证子组件的update函数能在父组件的更新job中实时push到调度的queue，保证了更新的一致性",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 5,
    "totalChunks": 9,
    "startPos": 1567,
    "endPos": 1886,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-6",
    "title": "框架设计的思考 (第7段)",
    "content": "...job中实时push到调度的queue，保证了更新的一致性 >>坑：queue的遍历不建议通过静态遍历方式，例如：forEach，而需要通关过动态遍历方式来做，例如：\"for let of\"；*（ps:动静指是否实时对数组长度做求值，只有实时计算才能保证动态改变的调度队列也能被执行）*\n进一步思考\n优势可能演变成劣势，缺点也可能演变成某种优势；分久必合合久必分；\nVue跟React最大的不同点可能就在于数据的Reactivity（是Immutable还是Mutable）；后续的演变都离不开这点，例子：\n    1. Vue3的Hooks为了解决.vue文件**更贴近web开发者**却导致逻辑视图割裂问题；顺带有更好的逻辑复用 + 更好的ts\n    2. React fiber为了解决 数据Immutable更安全更好预测却导致的更新性能问题",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 6,
    "totalChunks": 9,
    "startPos": 1886,
    "endPos": 2233,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-7",
    "title": "框架设计的思考 (第8段)",
    "content": "...数据Immutable更安全更好预测却导致的更新性能问题 3. React + Mobx 跟 Vue3 Composition-API如此类似\nReference\nhttps://zhuanlan.zhihu.com/p/35046696\nhttps://zhuanlan.zhihu.com/p/76622839\nhttps://github.com/wizardpisces/experiment/blob/master/packages/mini-react\nhttps://github.com/wizardpisces/experiment/blob/master/packages/mini-svelte",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 7,
    "totalChunks": 9,
    "startPos": 2233,
    "endPos": 2517,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/框架设计的思考#chunk-8",
    "title": "框架设计的思考 (第9段)",
    "content": "...b/master/packages/mini-svelte https://github.com/wizardpisces/experiment/blob/master/packages/mini-vue\nhttps://github.com/vuejs/vue-next\nhttps://github.com/google/incremental-dom",
    "url": "/blog/框架设计的思考",
    "chunkIndex": 8,
    "totalChunks": 9,
    "startPos": 2517,
    "endPos": 2665,
    "originalTitle": "框架设计的思考"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-0",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)",
    "content": "Map\nIntroduction of map\nsourceCode (scanning)-> tokens (parsing)-> syntaxTree(**step3**) (analysis/transform)-> intermediateRepresentation or IR(**step4**) (codeGen)-> machineCode\n**step4** -> (Optimizing **step4**) \n**step4** (codeGen + sourceMap)-> byteCode(virtualMachine run! )",
    "url": "/blog/Compiler简介",
    "chunkIndex": 0,
    "totalChunks": 23,
    "startPos": 0,
    "endPos": 282,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-1",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第2段)",
    "content": "...yteCode(virtualMachine run! ) **step3** -> highLevelLanguage(transpiling) -> **step4**   (short cuts)\nA Map of Territory\nThe-parts-of-a-language\nCompilers and Interpreters\nShort-cuts-and-alternate-routes\nThe-parts-of-a-language\nScanning\nalso known as lexing",
    "url": "/blog/Compiler简介",
    "chunkIndex": 1,
    "totalChunks": 23,
    "startPos": 282,
    "endPos": 510,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-2",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第3段)",
    "content": "...Scanning\nalso known as lexing A scanner (or lexer) takes in the linear stream of characters and chunks them together into a series of something more akin to “words”. \nParsing\nThis is where syntax gets a grammar—the ability to compose larger expressions and statements out of smaller parts. Did you ever diagram sentences in English class?\nStatic analysis",
    "url": "/blog/Compiler简介",
    "chunkIndex": 2,
    "totalChunks": 23,
    "startPos": 510,
    "endPos": 835,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-3",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第4段)",
    "content": "...nglish class?\nStatic analysis The first bit of analysis that most languages do is called binding or resolution. For each identifier we find out where that name is defined and wire the two together. This is where scope comes into play—the region of source code where a certain name can be used to refer to a certain declaration.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 3,
    "totalChunks": 23,
    "startPos": 835,
    "endPos": 1133,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-4",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第5段)",
    "content": "...fer to a certain declaration. **Everything up to this point is considered the front end of the implementation.**\nIntermediate Representation\nThe front end of the pipeline is specific to the source language the program is written in. \nThe back end is concerned with the final architecture where the program will run.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 4,
    "totalChunks": 23,
    "startPos": 1133,
    "endPos": 1419,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-5",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第6段)",
    "content": "...e where the program will run. In the middle, the code may be stored in some intermediate representation (or IR) that isn’t tightly tied to either the source or destination forms (hence “intermediate”). \nInstead, the IR acts as an interface between these two languages.\nOptimization\neg:\nConstant folding\npennyArea = 3.14159 * (0.75 / 2) * (0.75 / 2);\n->\npennyArea = 0.4417860938;",
    "url": "/blog/Compiler简介",
    "chunkIndex": 5,
    "totalChunks": 23,
    "startPos": 1419,
    "endPos": 1768,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-6",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第7段)",
    "content": "...->\npennyArea = 0.4417860938; Code Generation\nwhere “code” here usually refers to the kind of primitive assembly-like instructions a CPU runs and not the kind of “source code” a human might want to read.\nVirtual Machine",
    "url": "/blog/Compiler简介",
    "chunkIndex": 6,
    "totalChunks": 23,
    "startPos": 1768,
    "endPos": 1958,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-7",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第8段)",
    "content": "...want to read.\nVirtual Machine virtual machine (VM), a program that emulates a hypothetical chip supporting your virtual architecture at runtime. Running B in a VM is slower than translating it to native code ahead of time because every instruction must be simulated at runtime each time it executes.\nIn return, you get simplicity and portability.\nRuntime",
    "url": "/blog/Compiler简介",
    "chunkIndex": 7,
    "totalChunks": 23,
    "startPos": 1958,
    "endPos": 2283,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-8",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第9段)",
    "content": "...city and portability.\nRuntime In, say, Go, each compiled application has its own copy of Go’s runtime directly embedded in it. If the language is run inside an interpreter or VM, then the runtime lives there. This is how most implementations of languages like Java, Python, and JavaScript work.\nShort-cuts-and-alternate-routes\nSingle pass compiler",
    "url": "/blog/Compiler简介",
    "chunkIndex": 8,
    "totalChunks": 23,
    "startPos": 2283,
    "endPos": 2601,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-9",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第10段)",
    "content": "...e-routes\nSingle pass compiler Some simple compilers interleave parsing, analysis, and code generation so that they produce output code directly in the parser, without ever allocating any syntax trees or other IRs.\nPascal and C were designed around this limitation.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 9,
    "totalChunks": 23,
    "startPos": 2601,
    "endPos": 2836,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-10",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第11段)",
    "content": "...igned around this limitation. At the time, memory was so precious that a compiler might not even be able to hold an entire source file in memory, much less the whole program. \nTree-walk interpreters\nTranspilers\n**source-to-source compiler or transcompiler**\ntreated some other source language as if it were an intermediate representation",
    "url": "/blog/Compiler简介",
    "chunkIndex": 10,
    "totalChunks": 23,
    "startPos": 2836,
    "endPos": 3144,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-11",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第12段)",
    "content": "...n intermediate representation run that resulting code through the output language’s existing compilation pipeline and you’re good to go.\neg: coffee -> javascript, sass -> css\nC compilers were available everywhere UNIX was and produced efficient code, so targeting C was a good way to get your language running on a lot of architectures.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 11,
    "totalChunks": 23,
    "startPos": 3144,
    "endPos": 3451,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-12",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第13段)",
    "content": "...ng on a lot of architectures. Web browsers are the “machines” of today, and their “machine code” is JavaScript, so these days it seems almost every language out there has a compiler that targets JS since that’s the main way to get your code running in a browser.\nJust-in-time compilation",
    "url": "/blog/Compiler简介",
    "chunkIndex": 12,
    "totalChunks": 23,
    "startPos": 3451,
    "endPos": 3709,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-13",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第14段)",
    "content": "...ser.\nJust-in-time compilation The fastest way to execute code is by compiling it to machine code, but you might not know what architecture your end user’s machine supports. What to do?",
    "url": "/blog/Compiler简介",
    "chunkIndex": 13,
    "totalChunks": 23,
    "startPos": 3709,
    "endPos": 3865,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-14",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第15段)",
    "content": "...machine supports. What to do? You can do the same thing that the HotSpot JVM, Microsoft’s CLR and most JavaScript interpreters do. On the end user’s machine, when the program is loaded—either from source in the case of JS, or platform-independent bytecode for the JVM and CLR—you compile it to native for the architecture their computer supports.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 14,
    "totalChunks": 23,
    "startPos": 3865,
    "endPos": 4182,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-15",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第16段)",
    "content": "...cture their computer supports. Naturally enough, this is called just-in-time compilation.\n The most sophisticated JITs insert profiling hooks into the generated code to see which regions are most performance critical and what kind of data is flowing through them. Then, over time, they will automatically recompile those hot spots with more advanced optimizations.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 15,
    "totalChunks": 23,
    "startPos": 4182,
    "endPos": 4516,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-16",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第17段)",
    "content": "...more advanced optimizations. Compilers-and-Interpreters\nWhat’s the difference between a fruit and a vegetable？\nbut actually “fruit” is a botanical（植物学） term and “vegetable” is culinary（烹饪）.There are fruits that aren’t vegetables (apples) and vegetables that are not fruits (carrots), but also edible plants that are both fruits and vegetables, like tomatoes.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 16,
    "totalChunks": 23,
    "startPos": 4516,
    "endPos": 4846,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-17",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第18段)",
    "content": "...nd vegetables, like tomatoes. What’s the difference between a compiler and an interpreter?\nCompiling is an implementation technique that involves translating a source language to some other—usually lower-level—form. When you generate bytecode or machine code, you are compiling. When you transpile to another high-level language you are compiling too.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 17,
    "totalChunks": 23,
    "startPos": 4846,
    "endPos": 5168,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-18",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第19段)",
    "content": "...nguage you are compiling too. When we say a language implementation “is a compiler”, we mean it translates source code to some other form but doesn’t execute it. The user has to take the resulting output and run it themselves.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 18,
    "totalChunks": 23,
    "startPos": 5168,
    "endPos": 5365,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-19",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第20段)",
    "content": "...output and run it themselves. Conversely, when we say an implementation “is an interpreter”, we mean it takes in source code and executes it immediately. It runs programs “from source”.\nGCC and Clang take your C code and compile it to machine code. An end user runs that executable directly and may never even know which tool was used to compile it. So those are compilers for C.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 19,
    "totalChunks": 23,
    "startPos": 5365,
    "endPos": 5715,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-20",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第21段)",
    "content": "...So those are compilers for C. eg:\nIf you run go build, it compiles your Go source code to machine code and stops. If you type go run, it does that then immediately executes the generated executable.",
    "url": "/blog/Compiler简介",
    "chunkIndex": 20,
    "totalChunks": 23,
    "startPos": 5715,
    "endPos": 5884,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-21",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第22段)",
    "content": "...tes the generated executable. So go is a compiler (you can use it as a tool to compile code without running it), is an interpreter (you can invoke it to immediately run a program from source), and also has a compiler (when you use it as an interpreter, it is still compiling internally).\nReference\nhttp://craftinginterpreters.com/a-map-of-the-territory.html#transpilers",
    "url": "/blog/Compiler简介",
    "chunkIndex": 21,
    "totalChunks": 23,
    "startPos": 5884,
    "endPos": 6224,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/Compiler简介#chunk-22",
    "title": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png) (第23段)",
    "content": "...he-territory.html#transpilers https://justinmeiners.github.io/lc3-vm/",
    "url": "/blog/Compiler简介",
    "chunkIndex": 22,
    "totalChunks": 23,
    "startPos": 6224,
    "endPos": 6263,
    "originalTitle": "[Map](http://craftinginterpreters.com/image/a-map-of-the-territory/mountain.png)"
  },
  {
    "chunkId": "/blog/QRCode#chunk-0",
    "title": "二维码的纠错原理",
    "content": "二维码的纠错原理\nReed-Solomon 算法简介\nReed-Solomon 算法是一种基于多项式插值的纠错编码技术。它的主要功能是通过加入冗余信息（纠错码），在部分数据损坏的情况下恢复原始数据。\n以下是 Reed-Solomon 的工作流程与简单例子，帮助理解其原理和应用。\n二、简单例子\n场景描述\n1. **原始数据**：3个数据点 \\( [1, 3, 5] \\)。  \n2. **目标**：通过 Reed-Solomon，添加 2 个校验点，使其在损坏的情况下可以恢复。  \n3. **有限域**：采用有限域 GF(7)（简单的模 7 运算）。\n---\n1. 构造多项式\n根据原始数据 \\( [1, 3, 5] \\)，构造一个二次多项式：  \n\\[",
    "url": "/blog/QRCode",
    "chunkIndex": 0,
    "totalChunks": 8,
    "startPos": 0,
    "endPos": 329,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-1",
    "title": "二维码的纠错原理 (第2段)",
    "content": "...[1, 3, 5] \\)，构造一个二次多项式：  \n\\[ f(x) = a_0 + a_1x + a_2x^2\n\\]\n将数据点 \\( (x, y) \\) 填入：\n当 \\( x = 0 \\), \\( y = 1 \\): \\( a_0 = 1 \\)\n当 \\( x = 1 \\), \\( y = 3 \\): \\( 1 + a_1 + a_2 = 3 \\)\n当 \\( x = 2 \\), \\( y = 5 \\): \\( 1 + 2a_1 + 4a_2 = 5 \\)\n解方程得到系数：\n\\[\nf(x) = 1 + 2x + x^2\n\\]\n---\n2. 生成校验点\n计算 \\( f(x) \\) 的额外点值：\n\\( f(3) = 1 + 2(3) + (3)^2 = 16 \\mod 7 = 2 \\)",
    "url": "/blog/QRCode",
    "chunkIndex": 1,
    "totalChunks": 8,
    "startPos": 329,
    "endPos": 644,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-2",
    "title": "二维码的纠错原理 (第3段)",
    "content": "...3) + (3)^2 = 16 \\mod 7 = 2 \\) \\( f(4) = 1 + 2(4) + (4)^2 = 25 \\mod 7 = 4 \\)\n完整数据变为：  \n原始数据 \\( [1, 3, 5] \\) 和校验数据 \\( [2, 4] \\)。\n---\n3. 数据损坏\n假设传输中，数据 \\( [1, ?, 5, ?, 4] \\) 被部分损坏（两个未知）。  \n需要恢复完整数据。\n---\n4. 数据恢复（多项式插值）\n已知：\n数据点 \\( (0, 1), (2, 5), (4, 4) \\)\n两个损坏的数据点 \\( (1, ?), (3, ?) \\)\n插值恢复：\n通过插值法恢复 \\( f(x) = 1 + 2x + x^2 \\)，重新计算缺失点：\n\\( f(1) = 1 + 2(1) + (1)^2 = 3 \\)",
    "url": "/blog/QRCode",
    "chunkIndex": 2,
    "totalChunks": 8,
    "startPos": 644,
    "endPos": 978,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-3",
    "title": "二维码的纠错原理 (第4段)",
    "content": "...(1) = 1 + 2(1) + (1)^2 = 3 \\) \\( f(3) = 1 + 2(3) + (3)^2 = 16 \\mod 7 = 2 \\)\n恢复完整数据：  \n\\[ [1, 3, 5, 2, 4] \\]\n---\n三、应用场景\n1. **光盘存储**：\n数据分块存储，利用 Reed-Solomon 校验码修复划痕损坏的数据。\n2. **二维码**：\n部分二维码模块被污损或遮挡，利用冗余信息恢复完整数据。\n3. **通信系统**：\n在噪声干扰的信道中传输数据，校验码用于纠正传输错误。\n---\n四、总结\n**核心思想**：将数据映射到多项式，通过添加校验点增强容错能力。\n**纠错能力**：已知错误位置，最多修复 n-k 个错误点。（n 是数据点数量，k 是原始数据点数量, n-k 是校验点数量），纠错率 (n-k)/n",
    "url": "/blog/QRCode",
    "chunkIndex": 3,
    "totalChunks": 8,
    "startPos": 978,
    "endPos": 1316,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-4",
    "title": "二维码的纠错原理 (第5段)",
    "content": "...据点数量, n-k 是校验点数量），纠错率 (n-k)/n **实际意义**：保证在部分数据丢失或损坏的情况下，仍能准确恢复原始信息。\n二维码的应用场景中，大多数损坏属于**位置已知**的错误，这使得二维码非常适合使用 Reed-Solomon 算法 的纠错功能。\n二维码的形变恢复\n二维码的形变恢复主要依赖于功能区域（如定位图形、对齐图形和时间图案）来校正二维码的几何形态，将其还原为标准的矩阵形式。以下是二维码形变校正的具体步骤和原理：\n---\n**1. 形变类型**\n二维码的形变主要分为以下几类：\n**旋转变形：** 二维码被旋转。\n**透视变形：** 二维码拍摄时不是正面拍摄，导致图像呈现梯形或菱形。\n**弯曲变形：** 二维码印刷在曲面上或因物理原因导致形状弯曲。\n---\n**2. 功能区域的作用**",
    "url": "/blog/QRCode",
    "chunkIndex": 4,
    "totalChunks": 8,
    "startPos": 1316,
    "endPos": 1645,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-5",
    "title": "二维码的纠错原理 (第6段)",
    "content": "...理原因导致形状弯曲。\n---\n**2. 功能区域的作用** 二维码的功能区域（尤其是定位图形和对齐图形）起到了关键作用：\n1. **定位图形：**  \n三个大方块位于二维码的左上角、右上角和左下角。\n它们的相对位置用于确定二维码的整体方向、大小和形变。\n2. **对齐图形：**  \n多个小方块位于二维码的内部，帮助校正非线性形变（如弯曲或局部拉伸）。\n3. **时间图案：**  \n位于二维码顶部和左侧的黑白相间线条，用于确定网格的行列数量，帮助解码器找到数据模块的准确位置。\n---\n**3. 校正形变的步骤**\n**步骤 1：检测定位图形**\n解码器扫描图像，寻找二维码的三个定位图形。\n根据定位图形的几何特性（黑白模块的固定比例和形状），确定它们在图像中的位置。\n**步骤 2：估计透视变换矩阵**",
    "url": "/blog/QRCode",
    "chunkIndex": 5,
    "totalChunks": 8,
    "startPos": 1645,
    "endPos": 1969,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-6",
    "title": "二维码的纠错原理 (第7段)",
    "content": "...定它们在图像中的位置。\n**步骤 2：估计透视变换矩阵** 利用定位图形的相对位置，计算实际图像中的四个顶点（包括隐含的右下角）。\n将实际顶点与标准二维码的顶点位置对应，生成一个 **透视变换矩阵**。\n透视变换矩阵是一个 3x3 的矩阵，能够将任何透视变形的图像还原为平面图像。\n**步骤 3：应用透视变换**\n使用计算出的透视变换矩阵，对二维码图像进行仿射变换或透视变换，恢复为标准的矩形。\n**步骤 4：细化校正**\n检测对齐图形，进一步校正非线性变形（如弯曲）。\n对齐图形通过测量变形后的位置与预期位置的偏差，调整内部模块的位置。\n**步骤 5：提取网格**\n根据时间图案的黑白间隔，确定二维码的行列数量。\n将恢复后的图像划分为标准的网格矩阵，准备解码。\n---\n**6. 总结**\n二维码形变恢复的核心是：",
    "url": "/blog/QRCode",
    "chunkIndex": 6,
    "totalChunks": 8,
    "startPos": 1969,
    "endPos": 2298,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/QRCode#chunk-7",
    "title": "二维码的纠错原理 (第8段)",
    "content": "...码。\n---\n**6. 总结**\n二维码形变恢复的核心是： 利用功能区域（定位图形、对齐图形、时间图案）识别变形。\n计算透视变换矩阵，将形变二维码恢复为标准矩形。\n细化校正，确保内部数据模块的位置精确无误。",
    "url": "/blog/QRCode",
    "chunkIndex": 7,
    "totalChunks": 8,
    "startPos": 2298,
    "endPos": 2371,
    "originalTitle": "二维码的纠错原理"
  },
  {
    "chunkId": "/blog/Source-Map原理及其应用#chunk-0",
    "title": "Source-Map原理及其应用",
    "content": "什么是 source-map?\n广义解释：\n溯源\n前端开发\n“A source map provides a way of mapping code within a compressed file back to it’s original position in a source file”\nV3 spec example:\n为什么使用 source-map?(debug)\n前端模块打包发布基本流程：\nModules -> compilers -> assets\n代码转换类型：\n编译（TypeScript)\n转译（Babel）\n压缩混淆（UglifyJS）\n合并多个文件，减少带宽请求。(Webpack, Rollup)\n1. dev 环境如何定位调试？\n2. 产线出错如何定位调试？",
    "url": "/blog/Source-Map原理及其应用",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 348,
    "originalTitle": "Source-Map原理及其应用"
  },
  {
    "chunkId": "/blog/Source-Map原理及其应用#chunk-1",
    "title": "Source-Map原理及其应用 (第2段)",
    "content": "...dev 环境如何定位调试？\n2. 产线出错如何定位调试？ source-map 如何映射\nmappings: \"输出文件列位置|输入文件名|输入文件行号|输入文件列号,.....\"\n优化措施：\n文件名提取\n可符号化字符的提取\n记录相对位置\nVLQ编码\n详细参考\nsouce-map 生成基本步骤\n1) Transform code and note the new generated source location\n2) Check for a difference in location between the original and generated code\n3) Using these mapping build a source map\n具体参照这里\nsource-map 映射可视化",
    "url": "/blog/Source-Map原理及其应用",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 348,
    "endPos": 672,
    "originalTitle": "Source-Map原理及其应用"
  },
  {
    "chunkId": "/blog/Source-Map原理及其应用#chunk-2",
    "title": "Source-Map原理及其应用 (第3段)",
    "content": "...e map\n具体参照这里\nsource-map 映射可视化 online source-map visualization\nsource-map test case 写法\n一种写法\n参考资料\n1. https://indepth.dev/source-maps-from-top-to-bottom/\n2. https://juejin.im/post/6844903869928079373\n3. https://www.npmjs.com/package/source-map\n4. https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/",
    "url": "/blog/Source-Map原理及其应用",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 672,
    "endPos": 952,
    "originalTitle": "Source-Map原理及其应用"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-0",
    "title": "JsBridge引发的思考",
    "content": "JsBridge引发的思考\nRN跟微信小程序算是JsBridge最经典的实践\n疑问\n1. 为什么js能够调用android或者IOS系统的方法？\n2. 不同语言之间如何做到相互调用？\nJsBridge原理\nWeb端和Native可以类比于Client/Server模式，Web端调用原生接口时就如同Client向Server端发送一个请求类似，JSB在此充当类似于HTTP协议的角色，实现JSBridge主要是两点：\n将Native端原生接口封装成JavaScript接口\n将Web端JavaScript接口封装成原生接口\nNative调用JS\n原理：直接用JS引擎执行（IOS的 WebView 容器采用 WKWebView 内核+JavascriptCore引擎 etc）",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 0,
    "totalChunks": 9,
    "startPos": 0,
    "endPos": 339,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-1",
    "title": "JsBridge引发的思考 (第2段)",
    "content": "...View 内核+JavascriptCore引擎 etc） 场景：Native input绑定 Native 事件，在事件代码里通过调用js将结果反应到 Webview\nJS调用Native方式\n拦截式\n标准的URL格式：，APP有专属的Scheme，eg：微信的 URL Scheme 就是 weixin://\n原理：Native拦截 Webview Sheme 请求，分析是否为JSB请求格式\n场景：Webview按钮打开Native相册，构造Scheme并发送，传递特定参数给Native去唤起相册；或者执行某些函数获取值后，再次通过执行js把结果返回给webview实现闭环通信\n兼容性：无兼容性问题\n性能：URL request 创建请求有一定的耗时（一般通过webview创建iframe方式发送），Android比较差",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 1,
    "totalChunks": 9,
    "startPos": 339,
    "endPos": 676,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-2",
    "title": "JsBridge引发的思考 (第3段)",
    "content": "...bview创建iframe方式发送），Android比较差 局限：URL 字符串长度有限制\n注入式（主流）\n原理：通过 WebView 提供的接口向 JS 全局上下文对象（window）中注入对象或者方法，当 JS 调用时，可直接执行相应的 Native 代码逻辑，从而达到 Web 调用 Native 的目的。\n>Native端\n>web端\n场景：各种系统API的直接调动（存储等）\n兼容性：安卓4.2+ 和 iOS 7+以上可用\n性能：较好\n串联双端通信\nWebViewJavascriptBridge\nAn iOS/OSX bridge for sending messages between Obj-C and JavaScript in UIWebViews/WebViews\n如何处理安全问题",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 2,
    "totalChunks": 9,
    "startPos": 676,
    "endPos": 1000,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-3",
    "title": "JsBridge引发的思考 (第4段)",
    "content": "...UIWebViews/WebViews\n如何处理安全问题 在 APP 内 JsBridge 可以实现 Web 和 Native 的通信，但是如果 APP 打开一个恶意的页面，页面可以任意调用 JsBridge 方法，获取各种隐私的数据，就会引起安全问题。\n限定域名白名单，只允许指定域名调用\nJSI\nRN 在0.59 版本使用JSI 取代了先前的JSBridge 。\nReact Native JSI (JavaScript Interface) 可以使 JavaScript 和 原生模块 更快、更简单的通信。它也是React Native 新的架构体系中Fabric UI层 和 Turbo 模块的核心部分。\nJSI有什么不同",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 3,
    "totalChunks": 9,
    "startPos": 1000,
    "endPos": 1287,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-4",
    "title": "JsBridge引发的思考 (第5段)",
    "content": "...UI层 和 Turbo 模块的核心部分。\nJSI有什么不同 JSI 移除了原生代码和JavaScript代码之间的桥接（bridge），同时也省去了两端相互调用时大量的JSON序列化和反序列化操作。JSI为原生和JS交互打开了新的大门。下面是一些JSI的特点：\nJavaScript Interface 允许我们向JavaScript 运行时注册方法。这些方法在js环境中可以通过 global对象获取并调用。\n我们完全可以使用C++或者在iOS里使用OC ，在Android里使用Java实现这些注册方法。\n原先使用bridge 的方式实现的原生模块可以通过增加一层C++，快速转化为通过JSI实现。\n在iOS端实现非常简单，因为C++和OC 可以方便的实现混编。\n在Android中，我们需要通过JNI 做一些转化。",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 4,
    "totalChunks": 9,
    "startPos": 1287,
    "endPos": 1618,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-5",
    "title": "JsBridge引发的思考 (第6段)",
    "content": "...编。\n在Android中，我们需要通过JNI 做一些转化。 这些方法可以是完全同步的，这意味着不必强制使用async。await。\n其他角度分析\nJavascript的编译器V8是C++实现，C++编译器是C，所以Javascript的编译器是C语言实现\nJava编译器被编写为Java程序，然后使用C编写的Java编译器（第一个Java编译器）进行编译，所以Java的编译器是C语言实现\nObjective-C是一种通用、高级、面向对象的编程语言。它扩展了标准的ANSI C编程语言\n其他：LLVM是构架编译器(compiler)的框架系统，以C++编写而成，所以编译的IR为LLVM的编程语言（例如Rust）是C语言实现",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 5,
    "totalChunks": 9,
    "startPos": 1618,
    "endPos": 1901,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-6",
    "title": "JsBridge引发的思考 (第7段)",
    "content": "...编译的IR为LLVM的编程语言（例如Rust）是C语言实现 总结：这些高级语言底层都是C的衍生；API：\"C\" 部分定义了外部函数所使用的 应用二进制接口（application binary interface，ABI） —— ABI 定义了如何在汇编语言层面调用此函数。\"C\" ABI 是最常见的，并遵循 C 编程语言的 ABI。\n推导：\n1. 这些语言能在编译层面互通，不同语言如果都实现C语言提供的bridge interface，那就能直接在代码编译后通信（API层面？）？Foreign_function_interface？\n其他跨语言通信，例如协议（独立于语言层面的标准）：RPC等\n应用\n实现过一个简单的SASS编译器，使用js实现；所以可以在编译过程中协商注入js函数，实现后就是plugin系统，应用的Demo代码\nReference",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 6,
    "totalChunks": 9,
    "startPos": 1901,
    "endPos": 2250,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-7",
    "title": "JsBridge引发的思考 (第8段)",
    "content": "...是plugin系统，应用的Demo代码\nReference tiny-sass-compiler Plugin\nReact Native原理与实践\nNativeScript的工作原理：用JavaScript调用原生API实现跨平台 \nReact Native JSI：实现RN与原生通信\nhttps://tsejx.github.io/cross-platform-guidebook/hybird/jsbridge/\nhttps://juejin.cn/post/6844903585268891662\nRust程序语言设计之不安全的Rust\nhttps://en.wikipedia.org/wiki/Foreign_function_interface",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 7,
    "totalChunks": 9,
    "startPos": 2250,
    "endPos": 2550,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/jsbridge引发的思考#chunk-8",
    "title": "JsBridge引发的思考 (第9段)",
    "content": "...ki/Foreign_function_interface https://blog.risingstack.com/how-to-use-rust-with-node-when-performance-matters/\nhttps://www.teqng.com/2021/08/01/jsbridge-%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/#JSB_yuan_li\n***本文属于个人的见解，酌情观看***",
    "url": "/blog/jsbridge引发的思考",
    "chunkIndex": 8,
    "totalChunks": 9,
    "startPos": 2550,
    "endPos": 2752,
    "originalTitle": "JsBridge引发的思考"
  },
  {
    "chunkId": "/blog/《系统之美》#chunk-0",
    "title": "《系统之美》思考",
    "content": "《系统之美》思考\n一艘船 -> 个人 -> 一个组织 -> 一个国家\n系统的基本结构\n1. 要素\n最明显，重要性最低\n随时可以被替换\n例如 船的木板，组织的人或者物\n2. 连接\n隐藏，改版后对系统会产生重大变化\n例如 船的结构，组织的结构\n3. 功能\n隐藏，决定系统的最关键因素\n例如 船在水上航行能力，组织提供的功能\n推导的结论\n1. 忒修斯之船（换掉每块木板的船还是之前的船么？）还是之前船，只要木板结构跟功能未变\n2. 换了员工的公司还是之前的公司，只要企业文化跟制度还在\n系统的变化\n1. 增强回路，调节回路等调节关系决定\n增强回路\n例如 组织发展好，就会吸引更优质的要素（人或者资源），从而加速组织的发展\n调节回路",
    "url": "/blog/《系统之美》",
    "chunkIndex": 0,
    "totalChunks": 2,
    "startPos": 0,
    "endPos": 313,
    "originalTitle": "《系统之美》思考"
  },
  {
    "chunkId": "/blog/《系统之美》#chunk-1",
    "title": "《系统之美》思考 (第2段)",
    "content": "...引更优质的要素（人或者资源），从而加速组织的发展\n调节回路 例如 发展到一定规模，新增的资源为组织赋能能力持续走低，达到某个节点就会成为累赘从而拖累组织的发展，开启调节回路\n2. 多因多果，非线性\n关键特征\n1. 反馈延迟\n表现形式（对系统施加的影响往往是一段是时间后才会显现）\n例如：大学报考的当时热门专业可能毕业后就过时了；零售商为应对一时的需求囤积的货物；国家对很多商品价格的宏观调控效果（持续疯涨的商品可能远远背离了实际的价值）\n应对方案\n>对环境信号反应适当放慢，确认变化趋势稳定后再决策\n例如 等待人员稳定后再看是否缺人，不然可能会招入远大于实际需求的人；报考专业前贴近国家的五年规划啥的；\n>缩短反馈延迟时间\n例如 跟同事的交流尽量能面对面，缩短反馈回路保证信息的及时性；零售商的零库存等；大数据按需定制；",
    "url": "/blog/《系统之美》",
    "chunkIndex": 1,
    "totalChunks": 2,
    "startPos": 313,
    "endPos": 643,
    "originalTitle": "《系统之美》思考"
  },
  {
    "chunkId": "/blog/一些DSL应用#chunk-0",
    "title": "Domain Specific Language",
    "content": "Domain Specific Language\nVirtual-dom\n虚拟dom操作集合\n1. creat VNode-A （简称 v-a）\n2. create Dom-A (简称 d-a) from v-a\n3. change v-a to v-b\n4. diff v-a and v-b to patches\n5. patch d-a from patches\n6. continue 3\nTools\nhtml2hscript - Parse HTML into hyperscript \nhtml2hscript.herokuapp.com - Online Tool that converts html snippets to hyperscript",
    "url": "/blog/一些DSL应用",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 333,
    "originalTitle": "Domain Specific Language"
  },
  {
    "chunkId": "/blog/一些DSL应用#chunk-1",
    "title": "Domain Specific Language (第2段)",
    "content": "...html snippets to hyperscript html2hyperscript - Original commandline utility to convert legacy HTML markup into hyperscript\nReference\nhyperscript\nvirtual-dom\nsnabbdom\nHTML Manipulation\nEcosystem\n| Name                                                          | Description                                             |",
    "url": "/blog/一些DSL应用",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 333,
    "endPos": 623,
    "originalTitle": "Domain Specific Language"
  },
  {
    "chunkId": "/blog/一些DSL应用#chunk-2",
    "title": "Domain Specific Language (第3段)",
    "content": "...| | ------------------------------------------------------------- | ------------------------------------------------------- |\n| htmlparser2            | Fast & forgiving HTML/XML parser                        |\n| domhandler              | Handler for htmlparser2 that turns documents into a DOM |",
    "url": "/blog/一些DSL应用",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 623,
    "endPos": 918,
    "originalTitle": "Domain Specific Language"
  },
  {
    "chunkId": "/blog/一些DSL应用#chunk-3",
    "title": "Domain Specific Language (第4段)",
    "content": "...turns documents into a DOM | | domutils                  | Utilities for working with domhandler's DOM             |\n| css-select              | CSS selector engine, compatible with domhandler's DOM   |\n| cheerio               | The jQuery API for domhandler's DOM                     |\n| dom-serializer | Serializer for domhandler's DOM                         |\nWebpack\n总结",
    "url": "/blog/一些DSL应用",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 918,
    "endPos": 1264,
    "originalTitle": "Domain Specific Language"
  },
  {
    "chunkId": "/blog/一些DSL应用#chunk-4",
    "title": "Domain Specific Language (第5段)",
    "content": "...|\nWebpack\n总结 一般compiler操作集合：\n1. parse raw string to VNode\n2. traverse VNode (visitor hooks with manipulation: insert , remove, modify, replace etc )\n3. code generation or Serialize VNode to string",
    "url": "/blog/一些DSL应用",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1264,
    "endPos": 1447,
    "originalTitle": "Domain Specific Language"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-0",
    "title": "关于程序跨端",
    "content": "关于程序跨端\n背景\n为什么需要跨端？\n一套代码跑多端，省时省力\n发展方向？\n开发体验：复用现有生态，追求热更新\n运行环境：代码执行适配，渲染引擎适配\n性能：追求原生\n包大小（冷热启动速度）\n小程序上层框架（跨APP）\n简介：基于web技术的一套代码跑在各个APP小程序：微信/支付宝/抖音等\n代表框架: taro1/2（类React语法，ps：taro3后可以同时支持RN/React/Vue）,uniapp（类Vue语法）\n原理\n主要分两种：渲染pipeline的重组优化，尽可能提出平台无关的IR？\n框架耦合，重编译时\n代表：uniapp、nanachi、taro1/2；分别支持某一个种框架：Vue或者React；",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 0,
    "totalChunks": 13,
    "startPos": 0,
    "endPos": 311,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-1",
    "title": "关于程序跨端 (第2段)",
    "content": "...aro1/2；分别支持某一个种框架：Vue或者React； 简介：使用工具把代码语法分析一遍，把其中的 JSX 部分和逻辑部分抽取出来，分别生成小程序的静态模板和 小程序页面的定义。运行时并没有 React/Vue 的存在，实际运行的是静态编译转换之后的小程序代码。\n运行环境：同下面介绍的原生小程序（主要是一个翻译器，运行时比较少）\n视图渲染：类React/Vue模板**编译**（AST转换）成对应APP小程序模板树（eg：微信小程序模板），再被原生小程序编译渲染\n问题\n编译：复杂的AST转化可能会丢失SourceMap导致Debug困难\n编译：框架（Vue或者React）DSL强绑定限制使用范围\n编译：JSX的模板过于灵活，导致编译成特定平台困难\n运行时：各个小程序平台升级（BUG或者新增特效）会导致跨端框架被迫跟进升级",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 1,
    "totalChunks": 13,
    "startPos": 311,
    "endPos": 648,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-2",
    "title": "关于程序跨端 (第3段)",
    "content": "...序平台升级（BUG或者新增特效）会导致跨端框架被迫跟进升级 API层面：把各端API **proxy**成统一的API调用（生命周期映射，系统模块调用等）\n组件：各自框架语法封装了一套\n框架独立，重运行时\n代表：taro3 支持 Vue、React等框架；仿照React-Dom跟 RN中的 Yoga，在小程序中模拟实现 DOM 以及 BOM 的 API（或者称为Taro-Dom？），从而实现直接将 React 运行到小程序环境中的目的\n运行环境：同上\n视图渲染：同上\n框架独立原因：框架编译作为Plugin接入，最终会编译成 Taro VNode？，然后通过统一API映射\nAPI层面：同上\n组件：用web-components；优势：框架独立；劣势：是否会有更多的坑？\n思考",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 2,
    "totalChunks": 13,
    "startPos": 648,
    "endPos": 959,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-3",
    "title": "关于程序跨端 (第4段)",
    "content": "...nents；优势：框架独立；劣势：是否会有更多的坑？\n思考 为什么跨端框架不直接调用native原生渲染，而是先编译到微信小程序等原生的代码？\n推测：原生小程序只对原生目录结构的代码开放API，双线程渲染？\n原生小程序（跨操作系统）\n双线程+1个native线程\n简介：基于web技术的一套代码跑在 IOS ，Android，开发者工具上\n代表框架：微信小/支付宝等原生小程序\n原理\n运行环境：各大支持小程序的APP：微信，支付宝等（IOS-JavascriptCore-WKWebView，Android-V8-chromium内核，开发者工具-NWJS-chromeWebview）\n视图渲染：原生+webview混合（内置组件类型），模板会转为语法树，然后跟内置组件映射渲染\n使用原生组件的地方会被先用DOM节点占位，然后再用原生组件覆盖占位点",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 3,
    "totalChunks": 13,
    "startPos": 959,
    "endPos": 1305,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-4",
    "title": "关于程序跨端 (第5段)",
    "content": "...件的地方会被先用DOM节点占位，然后再用原生组件覆盖占位点 问题：导致原生组件层级会更高，DOM样式没法应用上去\n优势：体验更好（input键盘控制力；减轻webview渲染压力，比如map直接给原生线程渲染了）\nAPI（本地存储，网络请求等）：JSBridge\n包大小：看系统是否自带了 JS Engine\nHMR：蹩脚；***小程序IDE检测到目录文件发生变动时会自动重新渲染。***，渲染管道比较长，中间转换比较多，能支持也是比较慢；一般使用uniapp或者taro上层框架开发，然后转成原生小程序，再通过原生小程序转换由App渲染\n关于双线程\n安全管控\n沙箱可控\n限制 DOM 和 BOM 能力\n各种API限制\n性能（UI跟逻辑分离，互不阻塞）\n引发的问题：逻辑层与渲染层之间通信延迟，异步->运行时序->生命周期（解决方案）\n发展方向：提升通信速度？",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 4,
    "totalChunks": 13,
    "startPos": 1305,
    "endPos": 1656,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-5",
    "title": "关于程序跨端 (第6段)",
    "content": "...运行时序->生命周期（解决方案）\n发展方向：提升通信速度？ 天生延迟：由于是不同线程之前的调用，所以对原生API的调用也是异步，所以会出现各种callback？\nApp（跨操作系统）\n简介：基于或者不基于web技术的一套代码跑在IOS跟Android系统\n代表框架：React Native（类React语法），Flutter（Dart widget）\n原理\nReact Native（三线程）\n iOS Android 的原生渲染管线都是 保留渲染模式（Retained Mode GUI） 范式，那么总是有相似点的，比如说 UI 都是树状嵌套布局，都有事件回调等等。React或者Vue虚拟DOM可很好转换过去（RN跟Weex的基石）。\n运行环境：js代码交由JS Engine（JavascriptCore，Hermes，V8 etc）执行",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 5,
    "totalChunks": 13,
    "startPos": 1656,
    "endPos": 2000,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-6",
    "title": "关于程序跨端 (第7段)",
    "content": "...vascriptCore，Hermes，V8 etc）执行 API调用（本地存储，定位，网络请求等）：Native <-> js代码通过**JsBridge**实现\n视图渲染：通过 UI Manager 来创建视图的（基于 Virtual DOM ，RN 把不同平台创建视图的逻辑封装了一层，不同平台通过 Bridge 调用 UI Manager 来创建不同的 Native 视图）；依赖原生渲染层，纯 Native 渲染；（类比:在浏览器 React 可以调用 DOM API 完成创建 UI 的工作，依赖原生渲染层）\n包大小：看系统是否自带了 Skia 引擎\n发展：平台关联性较强，所以跨端（PC，web等）速度可能会比较慢\nHMR：有\n>三线程",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 6,
    "totalChunks": 13,
    "startPos": 2000,
    "endPos": 2296,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-7",
    "title": "关于程序跨端 (第8段)",
    "content": "...端（PC，web等）速度可能会比较慢\nHMR：有\n>三线程 JS thread： 负责 JS 和原生代码的交互线程，因为 JS 是单线程模型，所以需要一个单独的线程来驱动，并且 JS 和 Native 交互是异步的。\nShadow thread: 这个线程是负责 Native 布局，提供给 yoga 引擎使用。\nUI thread：这个可以看作是主线程，可以看作是 UI Manager 线程，负责页面的交互和控件绘制逻辑。\n总结：JIT模式，需要频繁地在JavaScript与Native之间进行通信，从而会有一定的性能损耗影响，导致体验上与原生会有一些差异。",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 7,
    "totalChunks": 13,
    "startPos": 2296,
    "endPos": 2549,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-8",
    "title": "关于程序跨端 (第9段)",
    "content": "...从而会有一定的性能损耗影响，导致体验上与原生会有一些差异。 ***开发者编写的js代码，通过 react native 的中间层转化为原生控件和操作，Bridge 的作用就是给 React Native 内嵌的 JS Engine 提供原生接口的扩展供 JS 调用***\nFlutter\n重写了一整套包括底层渲染逻辑和上层开发语言的完整解决方案\n运行环境：dart语言\nDev阶段 JIT + Dart VM，保证开发效率\nProdution阶段 AOT编译成原生，保证产线运行效率\nAPI调用：dart可以AOT编译成平台原生代码，所以不需要bridge进行交互",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 8,
    "totalChunks": 13,
    "startPos": 2549,
    "endPos": 2802,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-9",
    "title": "关于程序跨端 (第10段)",
    "content": "...以AOT编译成平台原生代码，所以不需要bridge进行交互 视图渲染：flutter不使用平台原生控件（那是不是小程序/web这些端也能完美跨起来？），而是使用自身渲染引擎（skia）绘制widget，依赖平台的canvas能力（所以Flutter把Canvas这种立即渲染模式转换成了保留渲染模式？）\n问题：那视频播放会不会是问题？\n方向：会在 Native 控件上发力？\n发展：平台关联性较弱，在其他端的支持上可能会更快\nHMR：有（APP）\nKraken\n结合前端生态跟Flutter渲染引擎，声称更精简的渲染管线\n非js语言运行在js环境（跨语言）\nnode addons 机制可以让非js语言编译成 .node 文件，被 node 调用",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 9,
    "totalChunks": 13,
    "startPos": 2802,
    "endPos": 3096,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-10",
    "title": "关于程序跨端 (第11段)",
    "content": "...以让非js语言编译成 .node 文件，被 node 调用 WebAssembly 很多语言都可以编译成 .wasm，被 WebAssembly instantiate 后在浏览器或者node环境运行；实际还是需要编译成机器码\n是一个基于栈的虚拟机 (stack machine)，所以跨平台能力一流。类似 JVM？\nWebAssembly 字节码是一种抹平了不同 CPU 架构的机器码，WebAssembly 字节码不能直接在任何一种 CPU 架构上运行， 但由于非常接近机器码，可以非常快的被翻译为对应架构的机器码，因此 WebAssembly 运行速度和机器码接近，类似 Java 字节码。\n优势",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 10,
    "totalChunks": 13,
    "startPos": 3096,
    "endPos": 3368,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-11",
    "title": "关于程序跨端 (第12段)",
    "content": "...ly 运行速度和机器码接近，类似 Java 字节码。\n优势 体积小：由于浏览器运行时只加载编译成的字节码，一样的逻辑比用字符串描述的 JS 文件体积要小很多；(按道理JS源码会更小；其他语言编译的 .wasm 会大很多，信息里面需要包含除了逻辑代码外的信息；这里的更小是相对于下发相同逻辑的同一种语言？)\n加载快：由于文件体积小，再加上无需解释执行，WebAssembly 能更快的加载并实例化，减少运行前的等待时间；\n兼容性问题少：WebAssembly 是非常底层的字节码规范，制订好后很少变动，就算以后发生变化,也只需在从高级语言编译成字节码过程中做兼容。可能出现兼容性问题的地方在于 JS 和 WebAssembly 桥接的 JS 接口。\n拓展",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 11,
    "totalChunks": 13,
    "startPos": 3368,
    "endPos": 3665,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/关于程序跨端#chunk-12",
    "title": "关于程序跨端 (第13段)",
    "content": "...S 和 WebAssembly 桥接的 JS 接口。\n拓展 LLVM 实现了 LLVM IR 到 WebAssembly 字节码的编译功能，也就是能编译到 LLVM 的高级语言都能编译成 WebAssembly（eg：Rust）\n是否能重新写 React 的更新？以及 SSR 的 renderToString\nReference\n移动端跨平台开发的深度解析\nRN原理分析\nTaro3跨端跨框架原理初探\n双线程模型)\nFlutter 与 React Native 深入对比分析\nReact 和 IMGUI 有何联系和区别？\n关于JSBridge\n揭秘浏览器远程调试技术\nWebAssembly 简介及原理\n***本文属于个人的见解，酌情观看***",
    "url": "/blog/关于程序跨端",
    "chunkIndex": 12,
    "totalChunks": 13,
    "startPos": 3665,
    "endPos": 3958,
    "originalTitle": "关于程序跨端"
  },
  {
    "chunkId": "/blog/列存储#chunk-0",
    "title": "列存储",
    "content": "什么是列存储？跟传统存储啥区别？为啥列存储能更加快速响应复杂查询？\n列存储（Columnar Storage）是一种数据存储方式，与传统的行存储（Row Storage）有显著区别。列存储在处理分析型工作负载时，尤其是涉及复杂查询的情况下，表现得更加高效。\n列存储（Columnar Storage）\n在列存储中，数据按列存储，而不是按行存储。每一列的数据存储在一起，所有同一列的数据都连续存储在磁盘上。例如，对于一个有四个列（A、B、C、D）的表，数据将按如下方式存储：\n行存储（Row Storage）\n在传统的行存储中，数据按行存储，每一行的数据存储在一起。对于同样的四列表，数据将按如下方式存储：\n区别\n1. **数据存储方式**\n**行存储**：所有列的值按行存储在一起。",
    "url": "/blog/列存储",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 342,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/列存储#chunk-1",
    "title": "列存储 (第2段)",
    "content": "...据存储方式**\n**行存储**：所有列的值按行存储在一起。 **列存储**：同一列的值按列存储在一起。\n2. **适用场景**\n**行存储**：适用于OLTP（在线事务处理）工作负载，例如频繁的插入、更新和删除操作。\n**列存储**：适用于OLAP（在线分析处理）工作负载，例如复杂的查询和报表分析。\n列存储响应复杂查询更快速的原因\n1. **查询效率**\n在分析型查询中，通常只涉及少量的列。例如，计算某个统计数据只需访问特定的列。列存储仅读取需要的列数据，减少了I/O操作。\n行存储则需要读取整行数据，即使只需要其中一两列，也要读取整行，导致不必要的I/O开销。\n2. **数据压缩**",
    "url": "/blog/列存储",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 342,
    "endPos": 608,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/列存储#chunk-2",
    "title": "列存储 (第3段)",
    "content": "...读取整行，导致不必要的I/O开销。\n2. **数据压缩** 列存储的同一列数据类型相同且经常有相似的值，压缩效果更好。例如，一个包含许多重复值的列可以通过RLE（Run-Length Encoding）等压缩算法显著减少存储空间。\n行存储的数据类型混杂在一起，压缩效率低下。\n3. **向量化处理**\n列存储系统可以利用向量化处理技术，同时处理一批列数据，提高CPU使用效率。\n行存储处理每行数据时需要多次加载和存储，效率较低。\n4. **缓存利用**\n由于列存储按列连续存储，缓存命中率高，减少了对磁盘的访问。\n行存储按行存储，缓存命中率较低，需要频繁访问磁盘。\n总结\n列存储通过优化I/O操作、提高压缩效率、利用向量化处理和更好的缓存利用，显著提高了复杂查询的响应速度。因此，它特别适用于需要进行大量读取和分析的场景，如数据仓库、商业智能和实时分析系统。",
    "url": "/blog/列存储",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 608,
    "endPos": 958,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/列存储#chunk-3",
    "title": "列存储 (第4段)",
    "content": "...大量读取和分析的场景，如数据仓库、商业智能和实时分析系统。 示例\n假设有一个大型销售数据表，包含日期、产品ID、销售数量和销售额四个字段：\n**行存储：**\n**列存储：**\n查询总销售额时，列存储只需读取“销售额”列的数据，而行存储则需读取每一行的所有字段，明显增加了I/O开销和处理时间。这就是列存储在复杂查询中表现更高效的原因。",
    "url": "/blog/列存储",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 958,
    "endPos": 1095,
    "originalTitle": "列存储"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-0",
    "title": "可视化编程",
    "content": "可视化编程\n(lowcode)\n当前局限\n可视化编程停滞不前的一个主要原因是，它过于关注“形式”（即节点-连线范式、图形化界面等），而忽视了底层的功能设计。为什么这种关注“形式”的方式无法成就可视化编程？主要有以下几个原因：  \n1. **形式不是本质，功能才是关键**  \n可视化编程往往强调如何直观地表现代码，比如用方块和箭头代替文本编程语言的语法。但如果底层逻辑设计不够强大，光靠改变表现形式（比如不同的节点布局）无法真正提升编程的表达能力和效率。  \n2. **复杂性没有减少，甚至增加了**  \n许多可视化编程工具试图用图形化方式替代代码，但在面对复杂逻辑时，图形界面往往变得凌乱且难以管理。相较于精简的代码，复杂的可视化界面反而可能降低可读性和维护性。",
    "url": "/blog/可视化编程",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 335,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-1",
    "title": "可视化编程 (第2段)",
    "content": "...简的代码，复杂的可视化界面反而可能降低可读性和维护性。 3. **界面限制了表达能力**  \n当前的可视化编程框架往往受限于固定的交互方式，比如拖拽、节点连接等，而这些方式并不一定比文本编程更直观或高效。对于某些任务，强行适应这种交互方式反而降低了开发效率。  \n4. **忽视了可视化编程的真正潜力**  \n如果只是在“如何让代码变得可视化”上下功夫，而不是在“如何利用可视化带来新的编程范式”上做创新，那么可视化编程就只是在模仿传统编程，而不是开辟新的可能性。例如，真正强大的可视化编程应该让人更直观地操作数据流、调试和优化，而不仅仅是把文本编程转换成图形界面。  \n演进方向\n要解决可视化编程停滞不前的问题，核心在于从“**功能驱动**”而非“**形式驱动**”的角度出发。以下是几个可能的方向：  \n**2. 以数据流为核心，而非代码块**",
    "url": "/blog/可视化编程",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 335,
    "endPos": 682,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-2",
    "title": "可视化编程 (第3段)",
    "content": "...可能的方向：  \n**2. 以数据流为核心，而非代码块** **问题**：当前大部分可视化编程工具依赖“节点-连线”模式，但这种方式容易导致复杂的 spaghetti（意大利面条）式图形，变得难以阅读和维护。  \n**改进方向**：  \n采用**数据驱动**的方式，而不是基于“代码块”组织逻辑。例如，TensorFlow 或者 Unreal Engine 的蓝图系统就是基于数据流的可视化工具，它们的成功在于数据的流向清晰，而不是简单地拼接代码块。  \n引入**自动化布局算法**，优化界面，使得逻辑关系更清晰，而不是让用户手动整理节点。  \n📌 **案例**：工程设计软件 Grasshopper 采用“数据流”的方式，而不是“代码块”的形式，使得复杂几何建模更直观。  \n---\n**3. 结合自然语言和可视化**",
    "url": "/blog/可视化编程",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 682,
    "endPos": 1014,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-3",
    "title": "可视化编程 (第4段)",
    "content": "...模更直观。  \n---\n**3. 结合自然语言和可视化** **问题**：完全基于可视化的方式并不适合所有编程任务，尤其是逻辑复杂的情况。  \n**改进方向**：  \n让可视化编程工具支持**自然语言交互**，用户可以用文本描述部分逻辑，而不必完全依赖拖拽操作。  \n允许**文本代码与可视化编程共存**，比如在复杂逻辑部分可以直接写代码，而简单部分可以用可视化的方式调整。  \n📌 **案例**：  \n**Jupyter Notebook** 结合了可视化、代码和自然语言描述，成为数据科学领域的标配。  \n**GPT-4 代码解释器** 能够让用户用自然语言描述需求，再自动生成代码和可视化结果。  \n---\n**4. 增强可视化调试和探索能力**\n**问题**：许多可视化编程工具的调试能力较弱，用户很难在出错时快速定位问题。",
    "url": "/blog/可视化编程",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 1014,
    "endPos": 1354,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-4",
    "title": "可视化编程 (第5段)",
    "content": "...编程工具的调试能力较弱，用户很难在出错时快速定位问题。 **改进方向**：  \n提供**可视化调试工具**，比如让用户可以点击数据流中的某一步，直接查看输入和输出。  \n用动画或动态图表展示代码执行过程，而不仅仅是静态节点连接。  \n📌 **案例**：  \n**Observable**（可视化数据编程平台）允许用户实时调整数据并看到即时变化。  \n**Unreal Engine 的蓝图** 允许开发者在运行时“冻结”某个节点，查看其输入输出数据。  \n---\n**5. 让可视化编程成为“领域专用工具”，而不是通用编程语言**\n**问题**：可视化编程试图取代传统编程语言，但事实证明，通用编程任务往往更适合文本编写，而可视化更适用于特定领域。  \n**改进方向**：",
    "url": "/blog/可视化编程",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1354,
    "endPos": 1666,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-5",
    "title": "可视化编程 (第6段)",
    "content": "...写，而可视化更适用于特定领域。  \n**改进方向**： 让可视化编程专注于**特定领域**（如游戏开发、数据分析、机器学习）而非通用编程。  \n针对不同领域，设计合适的可视化交互方式，而不是用同一种模式去解决所有问题。  \n📌 **案例**：  \n**Blender 的节点编辑器** 适用于材质和特效编辑，而不适合写一般逻辑代码。  \n**Unity Visual Scripting** 主要用于游戏开发，针对性较强，而不是取代所有编程语言。  \n---\n**总结**\n可视化编程要突破瓶颈，关键在于：  \n✅ 让可视化编程真正“直觉化”，而不是仅仅把代码变成图形化界面。  \n✅ 以**数据流**为核心，而不是死守“节点-连线”范式。  \n✅ 结合自然语言，使得复杂逻辑可以用文字描述，而不是全靠拖拽。",
    "url": "/blog/可视化编程",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1666,
    "endPos": 1996,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/可视化编程#chunk-6",
    "title": "可视化编程 (第7段)",
    "content": "...自然语言，使得复杂逻辑可以用文字描述，而不是全靠拖拽。 ✅ 强化**可视化调试和探索能力**，减少黑箱问题。  \n✅ **专注于特定领域**，不要试图做成通用编程语言。  \n思考\n形式与功能，跟声明式与命令式有些类似；但是明显编程语言发展更偏向于声明式，所以形式并不是不好，而是过于抽象了，导致限制过多，思维负担过重了？\n形式应该通过理解功能需求而自然演化出来。比如，设计一个UI工具时，工具的界面应该根据用户任务和数据流自动调整，而不是由开发者手动设置每个组件的连接方式。\nReference\nvisual-programming-is-stuck-on-the-form\ngpt-4o",
    "url": "/blog/可视化编程",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1996,
    "endPos": 2262,
    "originalTitle": "可视化编程"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-0",
    "title": "图像压缩质量评估",
    "content": "图像压缩质量评估\n压缩后的图像质量是评估压缩算法的重要指标。常用的图像质量评估方法包括主观评估和客观评估。这里只进行客观评估的讨论\n客观评估：\n峰值信噪比（PSNR）\n结构相似性指数（SSIM）\n峰值信噪比（PSNR）\n公式中最大像素值（MAX）的作用对于全面理解 PSNR 的计算过程至关重要。让我们详细解释一下这个概念。\n1. PSNR 公式\nPSNR 的计算公式为：\n$$\n\\text{PSNR} = 10 \\cdot \\log_{10} \\left( \\frac{\\text{MAX}^2}{\\text{MSE}} \\right)\n$$\n其中：\n\\(\\text{MSE}\\) 是均方误差，表示原始图像和压缩图像之间的平均像素差异。\n\\(\\text{MAX}\\) 是图像的最大像素值。",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 0,
    "totalChunks": 10,
    "startPos": 0,
    "endPos": 346,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-1",
    "title": "图像压缩质量评估 (第2段)",
    "content": "...差异。\n\\(\\text{MAX}\\) 是图像的最大像素值。 2. MAX 的定义\nMAX 是图像中像素值的最大可能值。对于不同的图像类型，MAX 的值不同：\n对于 8 位灰度图像，像素值范围是 0 到 255，因此 MAX = 255。\n对于 16 位图像，像素值范围是 0 到 65535，因此 MAX = 65535。\n3. MAX 在 PSNR 公式中的作用\n3.1 标准化误差\nMAX 的主要作用是标准化均方误差（MSE），使得 PSNR 值可以在不同图像类型之间进行比较。直接使用 MSE 可能会导致不同图像类型之间的比较不公平，因为它们的像素值范围不同。\n3.2 无量纲化\n通过将 MSE 除以 MAX 的平方，PSNR 公式消除了像素值范围的影响，使得计算结果无量纲化。这意味着无论图像的像素值范围如何，PSNR 值都可以在相同的尺度上进行解释。",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 1,
    "totalChunks": 10,
    "startPos": 346,
    "endPos": 697,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-2",
    "title": "图像压缩质量评估 (第3段)",
    "content": "...像素值范围如何，PSNR 值都可以在相同的尺度上进行解释。 3.3 对数尺度\nPSNR 使用对数尺度来表示误差，这使得它对人类感知更直观。对数变换可以压缩大范围的误差值，使得较小的误差变化更容易被察觉。\n4. 举例说明\n假设我们有两张 8 位灰度图像，原始图像和压缩图像，其 MSE 为 100。计算 PSNR 的步骤如下：\n4.1 计算 MSE\n$$\n\\text{MSE} = 100\n$$\n4.2 计算 MAX 的平方\n对于 8 位灰度图像：\n$$\n\\text{MAX} = 255\n$$\n$$\n\\text{MAX}^2 = 255^2 = 65025\n$$\n4.3 计算 PSNR\n$$\n\\text{PSNR} = 10 \\cdot \\log_{10} \\left( \\frac{65025}{100} \\right)\n$$\n$$",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 2,
    "totalChunks": 10,
    "startPos": 697,
    "endPos": 1036,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-3",
    "title": "图像压缩质量评估 (第4段)",
    "content": "...rac{65025}{100} \\right)\n$$\n$$ \\text{PSNR} = 10 \\cdot \\log_{10} (650.25)\n$$\n$$\n\\text{PSNR} \\approx 10 \\cdot 2.813 = 28.13 \\text{ dB}\n$$\n5. 总结\n通过引入 MAX，PSNR 公式能够：\n标准化误差，使得不同图像类型之间的比较成为可能。\n无量纲化误差，使得 PSNR 值在同一尺度上进行解释。\n使用对数尺度，使得较小的误差变化更容易被察觉。\nMAX 的引入确保了 PSNR 是一个可靠且一致的图像质量评估指标，无论图像的像素值范围如何，它都能提供一个直观的质量度量。\n结构相似性指数（SSIM）",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 3,
    "totalChunks": 10,
    "startPos": 1036,
    "endPos": 1321,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-4",
    "title": "图像压缩质量评估 (第5段)",
    "content": "...它都能提供一个直观的质量度量。\n结构相似性指数（SSIM） 结构相似性指数（SSIM，Structural Similarity Index）是一种用于衡量两幅图像之间相似性的指标，特别适用于评估图像质量。与峰值信噪比（PSNR）不同，SSIM 更加注重图像的结构信息，因此在反映人类视觉感知方面更为有效。以下是详细说明：\n1. SSIM 的基本原理\nSSIM 通过比较图像的亮度、对比度和结构来评估图像质量。其公式如下：\n$$\n\\text{SSIM}(x, y) = \\frac{(2 \\mu_x \\mu_y + C_1)(2 \\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}\n$$\n其中：",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 4,
    "totalChunks": 10,
    "startPos": 1321,
    "endPos": 1641,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-5",
    "title": "图像压缩质量评估 (第6段)",
    "content": "...2 + \\sigma_y^2 + C_2)}\n$$\n其中： \\( \\mu_x \\) 和 \\( \\mu_y \\) 分别是图像 \\( x \\) 和 \\( y \\) 的平均值。\n\\( \\sigma_x^2 \\) 和 \\( \\sigma_y^2 \\) 分别是图像 \\( x \\) 和 \\( y \\) 的方差。\n\\( \\sigma_{xy} \\) 是图像 \\( x \\) 和 \\( y \\) 的协方差。\n\\( C_1 \\) 和 \\( C_2 \\) 是为了稳定分母而引入的小常数。\n2. SSIM 的三个组成部分\n2.1 亮度比较（Luminance Comparison）\n$$\nl(x, y) = \\frac{2 \\mu_x \\mu_y + C_1}{\\mu_x^2 + \\mu_y^2 + C_1}\n$$\n亮度比较部分衡量两幅图像的平均亮度差异。",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 5,
    "totalChunks": 10,
    "startPos": 1641,
    "endPos": 1982,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-6",
    "title": "图像压缩质量评估 (第7段)",
    "content": "...C_1}\n$$\n亮度比较部分衡量两幅图像的平均亮度差异。 2.2 对比度比较（Contrast Comparison）\n$$\nc(x, y) = \\frac{2 \\sigma_x \\sigma_y + C_2}{\\sigma_x^2 + \\sigma_y^2 + C_2}\n$$\n对比度比较部分衡量两幅图像的对比度差异。\n2.3 结构比较（Structure Comparison）\n$$\ns(x, y) = \\frac{\\sigma_{xy} + C_3}{\\sigma_x \\sigma_y + C_3}\n$$\n结构比较部分衡量两幅图像的结构相似性。",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 6,
    "totalChunks": 10,
    "startPos": 1982,
    "endPos": 2231,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-7",
    "title": "图像压缩质量评估 (第8段)",
    "content": "...+ C_3}\n$$\n结构比较部分衡量两幅图像的结构相似性。 局限性：协方差衡量的是两个数据集（在这里是两幅图像的像素值）之间的共同变化程度。但是，协方差的值会受到数据集的尺度影响。例如，对于两个数据集，如果它们的值都很大，协方差的值也会很大；如果它们的值都很小，协方差的值也会很小。因此，协方差的绝对值并不能直接反映两个数据集之间的相似性，需要进行标准化处理。\n处理方式：用协方差值除去标准差做标准化\n其他标准化：机器学习中的图像训练中的像素预处理归一化（x/255 [0, 1]）\n3. 为什么 SSIM 能表示图片压缩效果\n3.1 考虑人类视觉系统\nSSIM 模拟了人类视觉系统的感知特性，通过亮度、对比度和结构三个方面进行比较。这使得 SSIM 能更好地反映图像在视觉上的质量，而不仅仅是像素级别的差异。\n3.2 综合评估图像质量",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 7,
    "totalChunks": 10,
    "startPos": 2231,
    "endPos": 2570,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-8",
    "title": "图像压缩质量评估 (第9段)",
    "content": "...质量，而不仅仅是像素级别的差异。\n3.2 综合评估图像质量 SSIM 不仅考虑了像素值的差异，还考虑了图像的整体结构和纹理信息。这使得 SSIM 能够更全面地评估图像的质量，特别是在评估压缩算法的效果时。\n3.3 更加鲁棒\n由于 SSIM 是基于局部窗口计算的，它对图像的局部失真（如边缘、纹理等）更加敏感，这些失真往往是压缩算法引入的。因此，SSIM 能更准确地反映压缩对图像质量的影响。\n5. 结论\n**高 SSIM 值（接近 1）**：表示压缩图像与原始图像在亮度、对比度和结构上非常相似，图像质量较好。\n**低 SSIM 值（接近 0）**：表示压缩图像与原始图像在亮度、对比度和结构上差异较大，图像质量较差。\n总结",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 8,
    "totalChunks": 10,
    "startPos": 2570,
    "endPos": 2853,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图像压缩评估#chunk-9",
    "title": "图像压缩质量评估 (第10段)",
    "content": "...始图像在亮度、对比度和结构上差异较大，图像质量较差。\n总结 SSIM 通过综合考虑图像的亮度、对比度和结构信息，能够更全面地评估图像的质量，特别是在反映人类视觉感知方面具有优势。相比于只关注像素差异的 PSNR，SSIM 更加适合用于评估图像压缩效果，因为它能够更准确地反映压缩对图像整体视觉质量的影响。",
    "url": "/blog/图像压缩评估",
    "chunkIndex": 9,
    "totalChunks": 10,
    "startPos": 2853,
    "endPos": 2975,
    "originalTitle": "图像压缩质量评估"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-0",
    "title": "Introduction",
    "content": "Introduction\n理解计算机图形的基本概念\n问题\n浏览器如何调用显卡功能，运行 AI 和网页渲染？\n渲染图形的基本构建块为啥是三角形？\n原因主要包括以下几点：\n1. **几何稳定性**：\n三角形是最基本的多边形，任何多边形都可以通过分割成三角形来表示。\n三角形在二维和三维空间中都始终保持平面性，不会因顶点位置的改变而变形。这种性质使三角形在计算机图形学中非常稳定。\n2. **计算简单**：\n渲染三角形涉及的计算较为简单，易于进行光栅化、投影和纹理映射。\n光照计算（如Phong着色模型）和其他着色算法也能高效地应用在三角形上。\n3. **硬件优化**：\n现代图形处理单元（GPU）和渲染管线对三角形进行了专门优化。三角形光栅化是GPU的基本操作，硬件加速可以显著提高渲染速度和效率。",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 348,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-1",
    "title": "Introduction (第2段)",
    "content": "...化是GPU的基本操作，硬件加速可以显著提高渲染速度和效率。 三角形可以方便地利用顶点着色器和片元着色器来进行并行处理。\n4. **顶点和边缘管理**：\n三角形只有三个顶点和三条边，管理起来相对简单，便于进行顶点处理、边缘检测和背面剔除。\n在进行复杂形状的模型化时，使用三角形可以减少算法复杂度。\n5. **数据表示**：\n使用三角形网格（triangular mesh）可以有效地表示和处理复杂的几何形状。任意复杂的表面都可以通过三角形网格近似表示。\n示例说明\n几何稳定性\n考虑一个四边形（四个顶点）：\n如果四个顶点不共面，四边形就会“扭曲”，不再是一个平面多边形。\n而任何三个点都一定在一个平面上，因此三角形总是稳定的。\n硬件优化\n现代GPU的设计就是为了高效处理大量三角形。如下简化的渲染管线展示了如何处理三角形：",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 348,
    "endPos": 678,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-2",
    "title": "Introduction (第3段)",
    "content": "...效处理大量三角形。如下简化的渲染管线展示了如何处理三角形： 1. **顶点处理**：顶点着色器处理每个顶点的变换和光照计算。\n2. **图元组装**：顶点组合成三角形。\n3. **光栅化**：将三角形转换成片元（像素），进行逐片元操作（如着色、深度测试）。\n数据表示\n一个复杂模型可以通过三角形网格表示。假设一个立方体模型：\n每个面是一个四边形，可以分成两个三角形。\n因此，立方体可以由12个三角形（6个面，每个面2个三角形）表示。\n三角形易于进行光栅化、投影和纹理映射的原因？\n例子说明：\n光栅化\n光栅化是将几何图形转换为屏幕上的像素。三角形在光栅化过程中表现得非常好，主要原因如下：\n1. **边界确定性**：\n三角形只有三条边，确定其覆盖的像素范围非常简单。\n使用边缘函数（Edge Function），可以高效判断一个像素是否在三角形内。",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 678,
    "endPos": 1022,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-3",
    "title": "Introduction (第4段)",
    "content": "...Function），可以高效判断一个像素是否在三角形内。 2. **扫描线算法**：\n扫描线算法可以轻松应用于三角形。沿着y轴从顶到底逐行扫描，通过插值计算每行的起点和终点。\n对于每一行，简单地填充从起点到终点的像素。\n示例：\n考虑一个简单的三角形，其顶点为(10, 10), (50, 20), (30, 60)，通过扫描线算法，我们可以轻松地计算出每一行的填充像素范围。\n投影\n投影是将三维坐标转换为二维屏幕坐标。三角形的投影计算非常简便：\n1. **顶点投影**：\n三角形只有三个顶点，每个顶点的投影变换可以独立计算，然后再连接这些投影后的顶点即可。\n2. **透视变换**：\n透视变换涉及到将3D坐标乘以一个投影矩阵，对于每个顶点都进行相同的操作。\n变换后的三角形顶点仍然保持线性关系，确保变换后的形状是正确的。\n示例：",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 1022,
    "endPos": 1358,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-4",
    "title": "Introduction (第5段)",
    "content": "...形顶点仍然保持线性关系，确保变换后的形状是正确的。\n示例： 假设一个三角形在3D空间中的顶点为(1, 2, 3), (4, 5, 6), (7, 8, 9)，通过投影矩阵可以计算出这三个顶点在2D平面上的投影点，然后绘制出投影后的三角形。\n纹理映射\n纹理映射是将二维图像（纹理）应用到三维模型表面。三角形的纹理映射容易处理，主要是因为其线性插值性质：\n1. **线性插值**：\n在三角形内部，任何一点都可以通过三个顶点的线性插值计算得到。\n对于纹理坐标（u, v），通过顶点的纹理坐标进行插值，可以高效地计算出三角形内部任意点对应的纹理坐标。\n2. **Barycentric坐标（重心坐标）**：\n重心坐标是一种坐标系统，其中每个点的坐标都是基于三角形顶点的加权平均。重心坐标满足以下条件：\n$$",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1358,
    "endPos": 1678,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-5",
    "title": "Introduction (第6段)",
    "content": "...都是基于三角形顶点的加权平均。重心坐标满足以下条件：\n$$ \\lambda_1 + \\lambda_2 + \\lambda_3 = 1\n$$\n示例：\n如果P是三角形ABC的重心（即三条中位线的交点），那么P的Barycentric坐标就是(1/3, 1/3, 1/3)，因为重心到三个顶点的距离是相等的，所以权重也相等。\n为什么使用 Barycentric坐标 会让纹理计算得到的效果更加细致跟真实？\n因为 Barycentric 坐标提供了对三角形内部位置的精确描述，从而实现了更准确的纹理坐标插值和采样：\n1. 精确的位置描述：Barycentric 坐标通过权重值准确地描述了点在三角形内的位置关系。它不仅考虑了点与三个顶点之间的距离，还考虑了点与三角形内的边界之间的关系。这种精确的位置描述使得纹理计算可以更准确地确定每个点对应的纹理坐标。",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1678,
    "endPos": 2023,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/图形学中的三角形#chunk-6",
    "title": "Introduction (第7段)",
    "content": "...位置描述使得纹理计算可以更准确地确定每个点对应的纹理坐标。 2. 光滑的插值：Barycentric 坐标可以在三角形内进行线性插值，这意味着纹理坐标可以根据点在三角形内的位置平滑地过渡。相邻点之间的纹理坐标也会进行平滑的插值，从而在渲染时产生连续、无缝的纹理效果。\n3. 保持纹理特征：Barycentric 坐标的使用可以确保纹理特征在三角形内的点之间保持一致。这意味着如果一个三角形上的某个区域在纹理中具有特定的图案或纹理细节，那么通过 Barycentric 坐标计算得到的纹理坐标也会在该区域内保持相应的特征，从而保持纹理的连贯性和真实感。",
    "url": "/blog/图形学中的三角形",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 2023,
    "endPos": 2268,
    "originalTitle": "Introduction"
  },
  {
    "chunkId": "/blog/惰性求值与宏#chunk-0",
    "title": "惰性求值与宏",
    "content": "延迟求值和宏是两个经典的元编程概念，特别是在 Lisp 等语言中，通过这些机制可以让程序员灵活控制代码的执行顺序和代码生成。用 JavaScript 实现它们的基本示例可以帮助理解这些概念。\n1. 延迟求值（Lazy Evaluation）\n延迟求值是一种策略，即在真正需要值时才进行计算，而不是在表达式定义时立即求值。这种策略有助于提高效率、避免不必要的计算，并且可以处理无穷数据结构。\n在 JavaScript 中，我们可以通过闭包和函数来实现基本的延迟求值机制：\n解释\n**delay** 函数接受一个表达式，并返回一个闭包（函数），此时不会执行表达式。\n**force** 函数接受一个延迟表达式（闭包）并立即执行它，从而得到实际结果。",
    "url": "/blog/惰性求值与宏",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 323,
    "originalTitle": "惰性求值与宏"
  },
  {
    "chunkId": "/blog/惰性求值与宏#chunk-1",
    "title": "惰性求值与宏 (第2段)",
    "content": "...接受一个延迟表达式（闭包）并立即执行它，从而得到实际结果。 这种延迟求值的方式可以让我们控制何时执行表达式，尤其在处理惰性数据结构（如流）时非常有用。\n延迟求值在流中的应用\n可以将延迟求值应用于流式数据结构，创建一个惰性列表（stream）：\n解释\n**cons** 函数创建一个流节点，其中  是一个闭包函数，只有在访问时才会递归生成下一个元素。\n创建一个从指定值开始的自然数流，使用延迟求值确保每次访问  时才生成下一个数字。\n通过这种方式，我们可以构建无限数据结构并逐步生成值。\n2. 宏（Macros）",
    "url": "/blog/惰性求值与宏",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 323,
    "endPos": 549,
    "originalTitle": "惰性求值与宏"
  },
  {
    "chunkId": "/blog/惰性求值与宏#chunk-2",
    "title": "惰性求值与宏 (第3段)",
    "content": "...以构建无限数据结构并逐步生成值。\n2. 宏（Macros） 宏是元编程中重要的工具，允许我们在代码运行之前生成和操作代码片段。虽然 JavaScript 不支持 Lisp 那种经典的宏（编译时代码生成），我们可以通过函数模拟一些基本的宏行为，特别是可以用 JavaScript 的高阶函数来实现一些简单的“语法扩展”。\n以下是一个模拟宏展开的例子：\n解释\n**defineMacro** 函数用于定义一个宏，将宏名称与其展开函数关联。\n**expandMacro** 函数用于递归地对表达式进行宏展开。当遇到宏名时，会调用相应的展开函数，将其替换为展开后的代码。\n通过这种方式，我们创建了一个简单的宏系统，可以在运行前替换代码模式。这虽然不是真正的宏（编译时生成代码），但模拟了一些宏的基本行为，例如生成条件语句  的模式。\n3. 宏与延迟求值的结合",
    "url": "/blog/惰性求值与宏",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 549,
    "endPos": 895,
    "originalTitle": "惰性求值与宏"
  },
  {
    "chunkId": "/blog/惰性求值与宏#chunk-3",
    "title": "惰性求值与宏 (第4段)",
    "content": "...为，例如生成条件语句  的模式。\n3. 宏与延迟求值的结合 宏和延迟求值可以结合在一起，实现更复杂的控制结构。以下是一个  宏的例子（只有在条件为假时才执行某个表达式）：\n解释\n宏将条件取反，只在条件为假时才执行代码块。\n宏生成一个逻辑非的表达式。\n总结\n**延迟求值**通过闭包来延迟计算，常用于惰性数据结构。\n**宏**可以定义代码生成模式，使代码更具可读性和扩展性，模拟一些条件控制和逻辑结构。\n这些概念在函数式编程和元编程中十分强大，让我们能灵活控制代码的执行顺序和生成逻辑结构，从而实现更强大的语言功能。",
    "url": "/blog/惰性求值与宏",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 895,
    "endPos": 1122,
    "originalTitle": "惰性求值与宏"
  },
  {
    "chunkId": "/blog/编程语言的发展#chunk-0",
    "title": "关于编程语言的发展",
    "content": "关于编程语言的发展\n一开始\n运行环境：OS\n语言\n汇编 -> C（FP, OS) -> C++（C +OOP）\n托管时代\n运行环境：受托管的执行环境上\n特征：自动的垃圾收集，类型安全等\n语言\nJava（C++ -FP +OOP, JVM）-> Scala（Java +FP, JVM）\n命令式/声明式编程(DSL+函数式)\n命令式（Imperative）\n特征：做什么（What） + 如何（How）（最终目的跟如何达成混在一起）\n例子：for循环，i += 1等等，部分细节会掩盖了“最终目标”，后面可能多往What方向演进\n优势：更加精细化控制，但需要手动\n问题：并行执行程序变得困难，因为像“执行目的”这样更高层次的信息已经丢失\n声明式\n外部DSL",
    "url": "/blog/编程语言的发展",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 328,
    "originalTitle": "关于编程语言的发展"
  },
  {
    "chunkId": "/blog/编程语言的发展#chunk-1",
    "title": "关于编程语言的发展 (第2段)",
    "content": "...“执行目的”这样更高层次的信息已经丢失\n声明式\n外部DSL 描述：针对特定的领域设计，独立性强（主要被编译解析，不强依赖特定语言，例如：Dart-SASS等编译工具）\n特征：做什么（What）（只是表现出最终的目的，而不是明确指定做事的方式）\n例子：XML、HTML、SASS、SQL等\n发展：利用既有DSL的方言（附带成熟工具链）\n内部DSL\n描述：在既有语言上做一系列特别的API及使用模式\n例子：Jquery（伪装成一种DSL把一系列操作通过\".\"流畅连接）\n函数式\n特征：容易并行（因为运行时不会修改任何状态，因此无论多少线程在运行时都可以观察到正确的结果。）\n动态语言/静态语言\n动态语言：JIT，源码发布，运行时动态解释执行，例如JS\n静态语言：特征：AOT，提前编译成目标代码，例如C\n汇总\n抽象级别越来越高（下一个抽象级别？）",
    "url": "/blog/编程语言的发展",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 328,
    "endPos": 670,
    "originalTitle": "关于编程语言的发展"
  },
  {
    "chunkId": "/blog/编程语言的发展#chunk-2",
    "title": "关于编程语言的发展 (第3段)",
    "content": "...标代码，例如C\n汇总\n抽象级别越来越高（下一个抽象级别？） 构建于现有的工具上（Rust以LLVM为目标编译，Scala在JVM的运行）\n多范式（FP，OOP）\n更多声明式，更少的命令式：让代码包含更多的“What”，而不是“How”；执行环境便可以更加聪明地去适应当前的执行要求。\nAOT+JIT？元编程：用代码生成（操纵）代码？\n组合是未来？（Rust 的编程建模模式更像是组合（Composition） 而不是继承（Inheritance）？类似 Vue3 选择 Composition-API 代替 Class Option（更好的逻辑组合复用，更好的支持TS））\nReference\n编程语言的发展趋势和未来方向\n怎样理解元编程\nhttps://www.zhihu.com/question/32304837/answer/275204204",
    "url": "/blog/编程语言的发展",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 670,
    "endPos": 1016,
    "originalTitle": "关于编程语言的发展"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-0",
    "title": "References",
    "content": "Structure and Interpretation of Computer\n第一章：构建抽象过程（Building Abstractions with Procedures）\n第二章：构建数据抽象（Building Abstractions with Data）\n第三章：模块化、对象和状态（Modularity, Objects, and State）\n第四章：元语言抽象（Metalinguistic Abstraction）\n《计算机程序的构造与解释》第4章中的**元循环求值器**和**嵌套求值器**是关于解释器的构造及其扩展的经典话题。我们可以使用 JavaScript 来实现一些简化版的示例，帮助你理解这些概念。",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 0,
    "totalChunks": 7,
    "startPos": 0,
    "endPos": 317,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-1",
    "title": "References (第2段)",
    "content": "...Script 来实现一些简化版的示例，帮助你理解这些概念。 1. 元循环求值器（Meta-circular Evaluator）\n元循环求值器是一个解释器，它使用自身语言来解释和执行代码。在这个例子中，我们将实现一个简单的表达式求值器，可以解析和计算类似于 Lisp 的表达式，例如  或 。\n以下是一个使用 JavaScript 实现的简单元循环求值器：\n解释\n**parse** 函数将类似  的字符串转换为一个嵌套的数组结构 。\n**evaluate** 函数是核心的元循环求值器。它使用递归来解析表达式并调用相应的操作函数。\n如果表达式是一个数字，直接返回。\n如果是一个字符串（变量名或操作符），则从环境  中查找。\n如果是一个嵌套数组，它会递归地求值操作符和参数，并将参数应用到操作符上。",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 1,
    "totalChunks": 7,
    "startPos": 317,
    "endPos": 637,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-2",
    "title": "References (第3段)",
    "content": "...数组，它会递归地求值操作符和参数，并将参数应用到操作符上。 这个解释器就是所谓的“元循环”的，因为它在 JavaScript 中解释了一个微型的 Lisp 式语言，而 JavaScript 本身也在运行解释器。这种结构非常适合理解解释器的原理。\n2. 嵌套求值器与组合语言\n在元循环求值器的基础上，我们可以进一步扩展，让解释器支持更复杂的嵌套求值和新的语言特性，比如延迟求值或条件表达式。\n这里，我们添加一个新的  语法和  语法，实现条件求值和变量绑定：\n解释\n**define**：实现了变量绑定，将变量名和值存储到当前环境中，使得后续的表达式可以访问这些定义。\n**if**：实现了条件分支，只有满足条件的分支会被求值。\n通过这种方式，我们构造了一个嵌套求值器，支持更复杂的组合语言结构，允许我们在表达式中进行条件判断和变量定义。\n总结",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 2,
    "totalChunks": 7,
    "startPos": 637,
    "endPos": 979,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-3",
    "title": "References (第4段)",
    "content": "...语言结构，允许我们在表达式中进行条件判断和变量定义。\n总结 **元循环求值器**是一个基础解释器，用于直接求值基本表达式。\n**嵌套求值器**则在元循环求值器之上扩展，支持条件、变量绑定等结构，使得语言更强大和灵活。\n这些概念展示了如何逐步构建出一个解释器，并通过扩展使解释器支持更复杂的语言特性，逐步达到现代编程语言的复杂度。\n第五章：寄存器机器模型（Computing with Register Machines）\nSICP 第五章介绍了“寄存器机器和编译”的概念，主要涉及如何设计和实现寄存器机器模型以及编译的基本思想。这些概念在现代计算机架构和编译器设计中广泛应用。借鉴其中的思想，我们可以在 JavaScript 中实现一些简单的模拟，理解寄存器机器的工作机制和编译的过程。",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 3,
    "totalChunks": 7,
    "startPos": 979,
    "endPos": 1293,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-4",
    "title": "References (第5段)",
    "content": "...实现一些简单的模拟，理解寄存器机器的工作机制和编译的过程。 以下是一些 JavaScript 示例，展示寄存器机器和编译在编程中的启发性应用。\n2. 编译简单的表达式\n编译器的核心任务之一是将高级语言的表达式编译为更底层的指令。以下示例展示了一个简单的编译器，它将 JavaScript 表达式编译为寄存器机器的指令。\n在这个例子中，我们编写了一个简单的编译器函数 ，它将一个 JavaScript 表达式转换为寄存器机器的指令。这个编译器支持加法和减法，并生成了相应的“MOV”、“ADD”和“SUB”指令。\n---\n3. 虚拟寄存器机器的解释器\n寄存器机器可以看作一种“虚拟机”，它需要解释器来解释执行指令。以下是一个解释器，它可以解析并运行由编译器生成的寄存器指令。",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 4,
    "totalChunks": 7,
    "startPos": 1293,
    "endPos": 1600,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-5",
    "title": "References (第6段)",
    "content": "...下是一个解释器，它可以解析并运行由编译器生成的寄存器指令。 在这个示例中， 类是一个寄存器机器的解释器。它加载由编译器生成的指令，并按照这些指令一步一步执行，更新寄存器的状态。通过这种方式，我们可以看到如何在寄存器机器和编译器的基础上构建出一个简化的计算系统。\n---\n4. 优化：常量折叠\n编译器中一个常见的优化是常量折叠，即在编译时计算表达式的常量部分。以下是一个简单的常量折叠优化，帮助减少指令数量，提高运行效率。\n在这个优化中，我们在编译阶段提前计算常量表达式 ，将其结果  替换掉。这样在编译生成的代码中，只需处理最终的 ，从而减少了不必要的指令。\n---\n总结\nSICP 第五章关于寄存器机器和编译的思想为 JavaScript 编程提供了很多启发：\n1. **寄存器模拟**：寄存器机器模型帮助我们理解计算如何基于指令和寄存器来存储和操作数据。",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 5,
    "totalChunks": 7,
    "startPos": 1600,
    "endPos": 1950,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/计算机程序的构造与解释 - js#chunk-6",
    "title": "References (第7段)",
    "content": "...模型帮助我们理解计算如何基于指令和寄存器来存储和操作数据。 2. **编译原理**：编译的过程将高级表达式转化为低级指令，让我们更清晰地理解表达式求值的底层机制。\n3. **解释执行**：通过虚拟机解释器的设计，我们能看到计算机如何一步步执行编译后的指令。\n4. **编译优化**：常量折叠等优化技术在编译器中常用，能在运行前提升代码效率。\nReferences\n计算机程序的构造与解释\ngpt",
    "url": "/blog/计算机程序的构造与解释 - js",
    "chunkIndex": 6,
    "totalChunks": 7,
    "startPos": 1950,
    "endPos": 2117,
    "originalTitle": "References"
  },
  {
    "chunkId": "/blog/世界趋同#chunk-0",
    "title": "世界趋同",
    "content": "世界趋同\n**2. 互联网 & 软件设计趋同**\n✅ **社交媒体 UI**\n早期：Facebook、Twitter、Instagram、TikTok 界面各有不同。\n现在：几乎所有 App 都有**短视频推荐流**（Instagram Reels、YouTube Shorts、微博 Story）。\n各大社交平台开始采用类似的“推荐+算法”机制。\n✅ **编辑器与 AI 集成**\n过去，VS Code、JetBrains、Vim、Emacs 等编辑器风格各异。\n现在，几乎所有主流编辑器都支持：\n**AI 补全（Copilot, Tabnine, Cursor）**\n**Agent 交互**\n**GitHub 代码搜索集成**\n✅ **搜索引擎的 AI 化**",
    "url": "/blog/世界趋同",
    "chunkIndex": 0,
    "totalChunks": 6,
    "startPos": 0,
    "endPos": 334,
    "originalTitle": "世界趋同"
  },
  {
    "chunkId": "/blog/世界趋同#chunk-1",
    "title": "世界趋同 (第2段)",
    "content": "...Hub 代码搜索集成**\n✅ **搜索引擎的 AI 化** 过去：搜索引擎主要是基于关键字索引的传统网页搜索。\n现在：所有搜索引擎（Google, Bing, 百度等）都在转向**AI 搜索+摘要生成+对话式回答**，最终形态趋同。\n---\n**3. 商业模式趋同**\n✅ **游戏收费模式**\n过去：游戏有单机买断制、点卡制、免费试玩等多种商业模式。\n现在：越来越多游戏采用**免费+内购（微交易）**模式，例如：\n《英雄联盟》《王者荣耀》《原神》等。\n甚至许多原本卖断制的游戏（如 FIFA、使命召唤）都转向**“战斗通行证”+ 赛季收费**模式。\n✅ **短视频和直播**\n过去：短视频和直播是分开的，如 YouTube 主要是长视频，Twitch 主要是游戏直播。\n现在：所有平台都在做**短视频+直播+带货**，比如：\n抖音和快手直播带货",
    "url": "/blog/世界趋同",
    "chunkIndex": 1,
    "totalChunks": 6,
    "startPos": 334,
    "endPos": 679,
    "originalTitle": "世界趋同"
  },
  {
    "chunkId": "/blog/世界趋同#chunk-2",
    "title": "世界趋同 (第3段)",
    "content": "...在做**短视频+直播+带货**，比如：\n抖音和快手直播带货 B 站加了短视频、直播\nYouTube Shorts\n✅ **流媒体模式**\n过去：电影和电视剧在电影院、电视台播放。\n现在：Netflix、Disney+、HBO Max、爱奇艺等平台都采用**订阅制+独家内容**，形成趋同。\n---\n**4. 文化 & 影视内容趋同**\n✅ **电影 & 电视剧续集化**\n过去：电影往往是独立作品，系列较少。\n现在：几乎所有大 IP 都在拍续集、重启、宇宙化，比如：\n漫威宇宙、DC 宇宙、星战宇宙、哈利波特宇宙\n国产剧也开始流行“季播化”（《庆余年》《隐秘的角落》）\n✅ **K-Pop 影响全球流行音乐**\n过去：欧美流行音乐占据主流，各国风格迥异。",
    "url": "/blog/世界趋同",
    "chunkIndex": 2,
    "totalChunks": 6,
    "startPos": 679,
    "endPos": 977,
    "originalTitle": "世界趋同"
  },
  {
    "chunkId": "/blog/世界趋同#chunk-3",
    "title": "世界趋同 (第4段)",
    "content": "...球流行音乐**\n过去：欧美流行音乐占据主流，各国风格迥异。 现在：K-Pop 影响力扩大，全球流行音乐逐渐向 K-Pop 的**舞蹈+视觉包装+团体模式**靠拢，比如：\n中国、日本的偶像团体开始模仿 K-Pop 练习生制度。\n欧美流行歌手（如 Lady Gaga, BTS 合作）借鉴 K-Pop 营销方式。\n✅ **美剧和国产剧风格趋同**\n过去：美剧更快节奏，国产剧更慢热。\n现在：国产剧越来越采用**“快节奏+美剧式叙事”**，例如：\n《开端》《隐秘的角落》借鉴美剧的紧凑叙事。\n《三体》剧版采用好莱坞式的制作水准。\n---\n**5. 生活方式 & 审美趋同**\n✅ **全球建筑风格趋同**\n过去：不同国家的建筑风格迥异（如中国四合院、日本町屋、欧洲哥特式建筑）。\n现在：现代建筑越来越趋同，高楼大厦以**玻璃幕墙+极简线条**为主，如：",
    "url": "/blog/世界趋同",
    "chunkIndex": 3,
    "totalChunks": 6,
    "startPos": 977,
    "endPos": 1321,
    "originalTitle": "世界趋同"
  },
  {
    "chunkId": "/blog/世界趋同#chunk-4",
    "title": "世界趋同 (第5段)",
    "content": "...越来越趋同，高楼大厦以**玻璃幕墙+极简线条**为主，如： 迪拜、上海、纽约的摩天大楼风格越来越像。\n连国内的住宅小区也趋向统一的现代风格（高层+玻璃窗）。\n✅ **服装潮流趋同**\n过去：不同国家的流行趋势差异大。\n现在：\n全球流行的**极简风、机能风（Techwear）、复古 Y2K**几乎同步。\n运动品牌风潮全球一致，如 Nike、Adidas、New Balance 在全球大热。\n✅ **饮食习惯趋同**\n过去：不同国家的饮食文化差异很大。\n现在：\n全球范围内**咖啡文化**流行，星巴克、瑞幸等品牌让咖啡成为日常饮品。\n各国快餐文化趋同，麦当劳、肯德基的菜单全球相似，甚至出现“亚洲风味汉堡”等融合趋势。\n---\n**总结：世界趋同的核心原因**\n1. **市场竞争** → 低成本、高效率的解决方案会成为行业标准（如黑色汽车、电动车设计）。",
    "url": "/blog/世界趋同",
    "chunkIndex": 4,
    "totalChunks": 6,
    "startPos": 1321,
    "endPos": 1670,
    "originalTitle": "世界趋同"
  },
  {
    "chunkId": "/blog/世界趋同#chunk-5",
    "title": "世界趋同 (第6段)",
    "content": "...高效率的解决方案会成为行业标准（如黑色汽车、电动车设计）。 2. **技术进步** → 开源技术、算法驱动，导致产品功能和设计趋同（如 AI 补全、搜索 AI 化）。\n3. **全球化与信息传播** → 互联网让流行趋势迅速传播，导致文化、审美趋同（如 K-Pop、建筑设计）。\n4. **用户习惯养成** → 习惯一旦形成，厂商不愿意冒险改变（如短视频 UI、推荐算法）。\n5. **路径依赖** → 过去的成功模式容易被复用，如战斗通行证、流媒体订阅、电影续集化。\n世界趋同是一种**效率最大化**的结果，但也会带来**创新空间受限**的问题，因此有时候“逆趋同”的小众创新（如赛博朋克风格、复古科技）反而会成为新的趋势突破点。\nReference\ngpt-4o",
    "url": "/blog/世界趋同",
    "chunkIndex": 5,
    "totalChunks": 6,
    "startPos": 1670,
    "endPos": 1973,
    "originalTitle": "世界趋同"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-0",
    "title": "显示器",
    "content": "显示器\n人眼分辨率与 8K\n>整体上人眼的分辨率大约相当于 7K-8K，但在中央视野的分辨率要高于 8K。意味着 8K 是显示器发展的极限？\n可以用一些物理和感知上的衡量标准来估计人眼的“分辨率”。\n1. **角分辨率 (Angular Resolution)**\n人眼的分辨率通常用“角分辨率”来衡量，它指的是眼睛能分辨的最小角度。正常视力（20/20 视力）下，典型的角分辨率是 **1 弧分**（1 arcminute），也就是 1/60 度。\n这意味着，人眼能分辨出 1 弧分的两个点之间的差别。\n2. **像素换算**",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 0,
    "totalChunks": 13,
    "startPos": 0,
    "endPos": 265,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-1",
    "title": "显示器 (第2段)",
    "content": "...辨出 1 弧分的两个点之间的差别。\n2. **像素换算** 要将角分辨率转化为类似显示器的“像素”概念，我们可以进行一些估算。如果假设视角宽度为 120 度，视场高度为 60 度，并且视距约为 25 cm（阅读距离），以下是简单的计算：\n**水平分辨率**：人眼水平视角为 120 度，每度 60 弧分，因此眼睛的理论水平分辨率是 120 × 60 = 7200 弧分。\n**像素等效**：如果用像素来衡量，可以假设每弧分为一像素。这样，视野宽度约为 **7200 像素**。同理，垂直视野为 60 度，分辨率约为 **3600 像素**。\n所以，从分辨率角度看，整个人眼的视野大约相当于 **7200 × 3600 像素**，约等于 **26 兆像素（MP）**。\n3. **中央凹 (Fovea) 的精度**",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 1,
    "totalChunks": 13,
    "startPos": 265,
    "endPos": 592,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-2",
    "title": "显示器 (第3段)",
    "content": "...MP）**。\n3. **中央凹 (Fovea) 的精度** 然而，人眼并非在整个视野上都有均匀的分辨率。中央凹是视网膜上分辨率最高的区域，位于眼睛的中心，用于处理精细的视觉信息。在中央凹区域，视网膜上的感光细胞（视锥细胞）密度极高，分辨率也更高。\n在中央凹，视力最高的部分可以达到大约 **500-600 PPI（像素每英寸）** 的感知精度。因此，尽管人眼的总分辨率可能在 26 MP 左右，但在最集中的区域分辨率更高。\n4. **动态分辨率与大脑的处理**\n人眼和大脑协同工作，通过眼睛的快速移动（称为“扫视”）和大脑的感知机制，将局部高分辨率的图像拼接在一起。这意味着人眼并不总是以固定的分辨率“拍摄”世界，而是通过快速聚焦和大脑补偿形成清晰的感知。\n总结：\n**角分辨率**：1 弧分（1/60 度）。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 2,
    "totalChunks": 13,
    "startPos": 592,
    "endPos": 918,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-3",
    "title": "显示器 (第4段)",
    "content": "...知。\n总结：\n**角分辨率**：1 弧分（1/60 度）。 **像素等效**：大约相当于 **7200 x 3600 像素**（约 26 MP）。(8K 是 7680 x 4320)\n**中央凹**：中央视野分辨率较高，达到 500-600 PPI。\n**大脑处理**：大脑通过感知和整合提高视觉精度。\n扫视比盯着一个地方更耗费能量？\n意味着带鱼屏比 16:9 的屏幕更耗费眼睛？\n1. **大脑的视觉处理非常耗能**\n视觉系统是大脑中最复杂的系统之一，大约消耗了大脑整体能量的 **30%**。处理视觉信息需要大脑整合来自视网膜的信号，进行识别、分析、和解码。因此，大脑为了处理复杂的视觉输入，确实需要大量能量来支持：",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 3,
    "totalChunks": 13,
    "startPos": 918,
    "endPos": 1199,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-4",
    "title": "显示器 (第5段)",
    "content": "...因此，大脑为了处理复杂的视觉输入，确实需要大量能量来支持： **信息处理**：眼睛捕捉的每一个视觉场景都会生成大量的信息，大脑需要通过视觉皮层和其他认知功能区域进行处理。这包括边缘检测、颜色识别、深度感知等复杂任务。\n**补偿机制**：大脑不仅处理即时的视觉输入，还需要进行复杂的推测、模式识别、补偿盲点等操作，这进一步增加了能量需求。\n2. **扫视与视觉更新的能量消耗**\n扫视（saccades）是眼睛快速跳动的过程，大约每秒发生3-4次。每次扫视都会让眼睛重新获取新信息，并让大脑重新处理这些新输入。相比长时间盯着一个地方，频繁的扫视会增加以下方面的能量消耗：\n**眼部肌肉活动**：扫视需要眼部肌肉的持续运动，而长时间保持不动的凝视（fixation）则相对耗费更少的肌肉能量。眼睛的快速移动本身需要动用一系列眼外肌来控制方向和焦点。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 4,
    "totalChunks": 13,
    "startPos": 1199,
    "endPos": 1542,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-5",
    "title": "显示器 (第6段)",
    "content": "...。眼睛的快速移动本身需要动用一系列眼外肌来控制方向和焦点。 **大脑视觉处理负荷**：每次扫视时，大脑都要重新处理新的视觉输入，并整合之前的信息。这增加了视觉皮层的处理负担。而当我们固定盯着某个地方时，大脑只需维持当前视觉图像的稳定性，而无需处理大量的新信息。\n**抑制机制**：在扫视期间，视觉输入会被短暂抑制（称为**扫视抑制**，Saccadic Suppression），以防止大脑处理模糊或跳跃的画面。这种抑制机制也是大脑额外的工作，并需要一定的能量。\n因此，**频繁的扫视相比固定注视，确实更耗费能量**，因为它不仅需要眼部肌肉的运动，还会给大脑带来更多处理负荷。\n3. **注视固定 vs. 扫视的能量比较**\n**长时间注视一个点**：\n眼睛的肌肉活动最小，只需维持轻微的聚焦。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 5,
    "totalChunks": 13,
    "startPos": 1542,
    "endPos": 1860,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-6",
    "title": "显示器 (第7段)",
    "content": "...注视一个点**：\n眼睛的肌肉活动最小，只需维持轻微的聚焦。 大脑不需要处理太多新信息，只需维持当前视觉图像的稳定性，降低信息处理量。\n整体能量消耗较低。\n**频繁扫视**：\n每次扫视都会涉及眼部肌肉的剧烈运动，消耗更多能量。\n每次扫视会带来大量新视觉信息，大脑需要不断重新处理、分析和整合，增加能量消耗。\n需要视觉抑制机制来避免画面模糊，大脑需要进一步协调视觉皮层的活动。\n4. **大脑的高效处理机制**\n虽然扫视会消耗更多能量，但大脑也有一些高效的机制来节省资源。比如，在固定注视的过程中，大脑会将不太重要的部分模糊化或降低处理优先级，集中精力处理感兴趣或重要的区域。**在不需要大量精细处理的情况下，大脑可以调整资源分配，节省能量**。\n5. **注意力与能量消耗**",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 6,
    "totalChunks": 13,
    "startPos": 1860,
    "endPos": 2168,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-7",
    "title": "显示器 (第8段)",
    "content": "...整资源分配，节省能量**。\n5. **注意力与能量消耗** 此外，**注意力的集中也会增加能量消耗**。当你盯着一个特定的点或物体时，大脑需要调动更多的资源来处理该区域的细节，这也可能导致能量消耗增加。但如果注意力较低或视觉任务较简单，盯着一个地方的能量消耗仍然比频繁扫视低。\n总结\n**扫视比固定注视更耗能**：由于眼球运动和大脑处理新信息的复杂性，扫视会比盯着一个地方消耗更多能量。\n**大脑的视觉处理耗费大量能量**：即便是静止不动，大脑也需要持续处理视觉输入，并维持视觉的稳定。\n**补偿机制进一步增加能量消耗**：大脑通过整合、预测和填补视觉信息来优化感知，这些复杂的处理过程也增加了能量需求。\n视觉残留与刷新率（90Hz-120Hz）\n当刷新率达到某个高水平后，比如超过 144Hz，视觉系统很难再区分帧与帧之间的差异",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 7,
    "totalChunks": 13,
    "startPos": 2168,
    "endPos": 2504,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-8",
    "title": "显示器 (第9段)",
    "content": "...，比如超过 144Hz，视觉系统很难再区分帧与帧之间的差异 **视觉残留**（**Persistence of Vision**）是指当物体的图像在视网膜上消失后，**图像的感知会在短时间内继续保留**，大脑会对该图像的印象延续数毫秒。这个现象帮助我们将一系列快速切换的静态图像感知为连续运动。\n具体理解：\n1. **视网膜滞留**：当光线刺激眼睛时，视网膜上的感光细胞会产生电信号，传递到大脑。然而，光线消失后，这些信号并不会立即停止，而是持续一小段时间（通常是几毫秒）。这意味着，**即使物体不再被直接看到，它的图像仍会在视网膜上“停留”片刻**。\n2. **运动感知**：视觉残留是我们感知**连续运动**的基础。比如在电影或动画中，每秒只展示24帧静态图片，但由于视觉残留，我们会感知到流畅的连续画面，而不是一帧一帧的闪动。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 8,
    "totalChunks": 13,
    "startPos": 2504,
    "endPos": 2841,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-9",
    "title": "显示器 (第10段)",
    "content": "...觉残留，我们会感知到流畅的连续画面，而不是一帧一帧的闪动。 3. **视觉补偿**：大脑利用视觉残留来弥补快速运动或切换的画面空隙，让我们感知到一个连贯的世界。这是大脑补偿机制的一部分，有助于避免画面跳动或断裂感。\n常见例子：\n**电影和电视**：电影通常播放速度为每秒24帧。视觉残留让这些帧不会显得分散，而是形成平滑的运动效果。\n**光迹现象**：在夜晚挥舞光源时，会看到光的轨迹，这是因为光的图像在视网膜上残留了一段时间。\n总结：\n**视觉残留**是人眼和大脑的一种生理现象，帮助我们将快速切换的静态图像整合为连续的运动感知。它在视频、动画以及现实世界的运动感知中起到关键作用，避免了我们看到闪烁的画面或不连续的影像。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 9,
    "totalChunks": 13,
    "startPos": 2841,
    "endPos": 3124,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-10",
    "title": "显示器 (第11段)",
    "content": "...知中起到关键作用，避免了我们看到闪烁的画面或不连续的影像。 人体的残留现象不仅限于视觉和听觉，还涉及触觉、嗅觉、味觉、运动及情绪等多个方面。这些现象反映了身体感官系统在处理信息时的复杂性，以及我们如何整合和体验感知世界。\n为什么听觉残留更加短暂\n听觉残留是一种声音在消失后仍能被感知的现象，类似于视觉残留，它对我们理解语言、欣赏音乐和维持听觉流畅性具有重要作用。\n听觉残留比视觉残留更加短暂，并非完全因为**信息量**的不同，而是由于以下几个因素：\n1. **感官处理机制的差异**\n视觉和听觉在信息处理上存在本质差异。**视觉**通常以较大的空间分辨率接收大量的静态或动态图像，且每个视觉帧包含丰富的细节。相比之下，**听觉**处理的是**时间维度**上的连续波形，这种信息的传递和感知速度比视觉更快。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 10,
    "totalChunks": 13,
    "startPos": 3124,
    "endPos": 3447,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-11",
    "title": "显示器 (第12段)",
    "content": "...维度**上的连续波形，这种信息的传递和感知速度比视觉更快。 视觉通常需要大脑更长时间来整合和处理图像，因此视觉残留时间稍长。\n听觉需要实时、精确地处理声音，尤其在语音和音乐中，音频信号必须被快速解析和传递给大脑，这使得听觉残留时间更短，以避免混淆连续的声音信号。\n2. **时间敏感性**\n**听觉是一个极为敏感的时间依赖感官**。声音的频率、节奏和持续时间决定了我们如何理解语言和音乐，因此需要快速、精准的处理。\n听觉残留时间较短，避免产生音符或语言音节间的混淆。\n如果听觉残留时间过长，可能会导致声音重叠或延迟感，影响听觉感知的清晰度和流畅性。\n3. **大脑的感知优化**\n为了处理不同类型的感知信息，大脑对听觉和视觉信号采取了不同的优化策略：\n**视觉**可以容忍较大的时间延迟，特别是在电影、动画等领域，通过残留现象让画面流畅。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 11,
    "totalChunks": 13,
    "startPos": 3447,
    "endPos": 3787,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/人眼 - 晕3D#chunk-12",
    "title": "显示器 (第13段)",
    "content": "...间延迟，特别是在电影、动画等领域，通过残留现象让画面流畅。 **听觉**必须保持精确的时间节奏。短暂的残留允许听觉系统在快速接收新的声音信号的同时保持信息传递的连贯性。\n4. **信息结构的差异**\n虽然声音在时间维度上是动态的，但它的**信息密度**通常低于视觉。例如，一幅静态图像可能包含数百万像素的信息，而一段音频信号在相同时间内传递的细节较少。因此，听觉系统的处理时间较短。\n结论\n听觉残留较短并非仅仅因为信息量较小，而更多是由于**感官处理机制、时间敏感性、大脑优化策略**等多方面的因素共同作用。听觉系统需要快速准确地处理声音，以确保信息传递的清晰和连贯性。",
    "url": "/blog/人眼 - 晕3D",
    "chunkIndex": 12,
    "totalChunks": 13,
    "startPos": 3787,
    "endPos": 4042,
    "originalTitle": "显示器"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-0",
    "title": "因果思维型与目标导向型",
    "content": "因果思维型与目标导向型\n比如说今天中午得少吃点，A 同学问是因为肚子不舒服么，B 同学问是因为下午有团建得留肚子吃大餐么；\n| **思维方式** | **核心区别** |\n|---|---|\n| **因果型思维（A 同学）** | 关注 **「过去或当前的原因」**，试图找出导致某个事件发生的**根本原因**。 |\n| **目标导向思维（B 同学）** | 关注 **「未来的目的或影响」**，试图理解某个行为背后的**目标或意图**。 |\n|---|---|\n| **思考方向** | 从**已发生的事实**出发，推导其原因。 | 从**未来的目标**出发，推导当前行为的目的。 |\n| **关注点** | 过去和当前：为什么会这样？ | 未来：接下来会怎样？ |",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 0,
    "totalChunks": 10,
    "startPos": 0,
    "endPos": 335,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-1",
    "title": "因果思维型与目标导向型 (第2段)",
    "content": "...过去和当前：为什么会这样？ | 未来：接下来会怎样？ | | **典型问题** | 「为什么你今天中午吃得少？是不是肚子不舒服？」 | 「你是不是为了下午团建少吃点？」 |\n| **应用场景** | 追根溯源、问题分析（如故障排查、历史复盘）。 | 规划目标、预判趋势（如产品设计、市场战略）。 |\n| **思维特点** | 以**事实和数据**为依据，强调因果关系。 | 以**可能性和目的**为依据，强调行动的意义。 |\n| **优点** | **严谨可靠**，有助于理解过去和当前的问题。 | **前瞻性强**，有助于做出面向未来的决策。 |\n| **缺点** | 容易局限在**已有经验**，缺乏创新性。 | 可能**忽视现实条件**，导致计划不切实际。 |\n---\n类似思维  \n---\n**1. 归纳思维 vs. 演绎思维**",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 1,
    "totalChunks": 10,
    "startPos": 335,
    "endPos": 676,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-2",
    "title": "因果思维型与目标导向型 (第3段)",
    "content": "...思维  \n---\n**1. 归纳思维 vs. 演绎思维** 🔹 **归纳思维（Inductive Thinking）** → 从具体案例总结一般规律  \n🔹 **演绎思维（Deductive Thinking）** → 从一般规律推导具体结论  \n| 维度 | **归纳思维** | **演绎思维** |\n|---|---|---|\n| **核心逻辑** | 从**个别事实**推导出**普遍结论** | 从**已有规则**推导出**具体结论** |\n| **思考方向** | 具体 → 抽象 | 抽象 → 具体 |\n| **例子** | 看到很多公司因 AI 转型成功，推测 AI 会是大趋势 | 知道 AI 是大趋势，所以建议公司投资 AI |\n| **优点** | 适用于创新、发现新趋势 | 适用于逻辑推理、系统性决策 |",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 2,
    "totalChunks": 10,
    "startPos": 676,
    "endPos": 1014,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-3",
    "title": "因果思维型与目标导向型 (第4段)",
    "content": "...适用于创新、发现新趋势 | 适用于逻辑推理、系统性决策 | | **缺点** | 可能得出**错误的普遍结论**（以偏概全） | 依赖**前提的正确性**，如果基础假设错了，结论也错 |\n✅ **应用**：数据分析（归纳），法律推理（演绎）  \n🎯 **最佳策略**：归纳找规律，演绎验证推理  \n---\n**2. 第一性原理思维 vs. 类比思维**\n🔹 **第一性原理思维（First Principles Thinking）** → 追本溯源，拆解问题到最基本的事实  \n🔹 **类比思维（Analogical Thinking）** → 通过已有经验和案例进行推测  \n| 维度 | **第一性原理思维** | **类比思维** |\n|---|---|---|",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 3,
    "totalChunks": 10,
    "startPos": 1014,
    "endPos": 1322,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-4",
    "title": "因果思维型与目标导向型 (第5段)",
    "content": "...** | **类比思维** |\n|---|---|---| | **核心逻辑** | **拆解问题到最基本的事实和原理**，再从底层重新构建 | **借鉴已有经验**，通过相似案例推测 |\n| **思考方式** | 重新发明轮子 | 改良已有轮子 |\n| **例子** | 造电动汽车时，重新思考汽车的本质，优化能源结构（特斯拉） | 造电动汽车时，借鉴燃油车的设计逻辑（传统车企） |\n| **优点** | 适用于**突破性创新** | 适用于**快速决策和优化** |\n| **缺点** | 需要较高的**认知成本** | 可能受到**路径依赖**，限制创新 |\n✅ **应用**：创业创新（第一性原理），产品优化（类比思维）  \n🎯 **最佳策略**：创新时用第一性原理，执行时用类比思维  \n---\n**3. 发散思维 vs. 聚合思维**",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 4,
    "totalChunks": 10,
    "startPos": 1322,
    "endPos": 1668,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-5",
    "title": "因果思维型与目标导向型 (第6段)",
    "content": "...思维  \n---\n**3. 发散思维 vs. 聚合思维** 🔹 **发散思维（Divergent Thinking）** → 追求多种可能性，强调创造力  \n🔹 **聚合思维（Convergent Thinking）** → 追求最佳解决方案，强调逻辑性  \n| 维度 | **发散思维** | **聚合思维** |\n|---|---|---|\n| **核心逻辑** | 产生**多个不同的解决方案** | 从多个选项中选择**最优解** |\n| **思考方向** | 横向拓展 | 纵向收敛 |\n| **例子** | 头脑风暴：如何提高产品用户体验？（不限方案） | 评估所有方案，选出最可行的执行方案 |\n| **优点** | 适用于**创新和创造性问题** | 适用于**优化和执行** |",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 5,
    "totalChunks": 10,
    "startPos": 1668,
    "endPos": 1989,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-6",
    "title": "因果思维型与目标导向型 (第7段)",
    "content": "...**创新和创造性问题** | 适用于**优化和执行** | | **缺点** | 可能缺乏可行性 | 可能局限于已有的方案，错失创新 |\n✅ **应用**：设计思维（发散），决策分析（聚合）  \n🎯 **最佳策略**：**先发散，再聚合**，即先创造多个方案，再筛选出最佳方案  \n---\n**4. 快思考 vs. 慢思考（系统 1 vs. 系统 2 思维）**\n🔹 **快思考（System 1 Thinking）** → 直觉反应，依赖经验和情绪  \n🔹 **慢思考（System 2 Thinking）** → 深度分析，依赖逻辑和理性  \n| 维度 | **快思考（直觉）** | **慢思考（理性）** |\n|---|---|---|\n| **核心逻辑** | **自动化、直觉判断**，快速决策 | **深度思考、逻辑推理**，慢速决策 |",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 6,
    "totalChunks": 10,
    "startPos": 1989,
    "endPos": 2339,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-7",
    "title": "因果思维型与目标导向型 (第8段)",
    "content": "...*，快速决策 | **深度思考、逻辑推理**，慢速决策 | | **特点** | 省时省力，但容易受偏见影响 | 精确严谨，但耗费认知资源 |\n| **例子** | 突然看到蛇，会立刻躲开（本能） | 评估投资策略，需要计算收益风险 |\n| **优点** | 适用于**日常决策、紧急情况** | 适用于**复杂决策、需要深度分析的情况** |\n| **缺点** | 可能受到**情绪、偏见影响** | 可能**决策过慢，消耗精力** |\n✅ **应用**：驾驶、对话（快思考），战略决策、科学研究（慢思考）  \n🎯 **最佳策略**：大部分决策用快思考，关键决策用慢思考  \n---\n**总结**\n| **对比维度** | **思维方式 1** | **思维方式 2** | **适用场景** |\n|---|---|---|---|",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 7,
    "totalChunks": 10,
    "startPos": 2339,
    "endPos": 2678,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-8",
    "title": "因果思维型与目标导向型 (第9段)",
    "content": "...**适用场景** |\n|---|---|---|---| | **因果 vs. 目标** | 关注「原因」（过去） | 关注「目的」（未来） | 问题分析 vs. 目标规划 |\n| **归纳 vs. 演绎** | 具体 → 规律 | 规律 → 具体 | 数据分析 vs. 逻辑推理 |\n| **第一性原理 vs. 类比** | 追本溯源，重构思维 | 借鉴经验，优化方案 | 突破创新 vs. 快速执行 |\n| **发散 vs. 聚合** | 产生新想法 | 筛选最佳方案 | 创意构思 vs. 方案落地 |\n| **快思考 vs. 慢思考** | 直觉、快速决策 | 逻辑、深度思考 | 日常判断 vs. 复杂问题 |\n**如何运用这些思维方式？**  \n🔹 **解决问题时**，结合 **因果分析 + 目标导向**",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 8,
    "totalChunks": 10,
    "startPos": 2678,
    "endPos": 3012,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/因果思维型与目标导向型#chunk-9",
    "title": "因果思维型与目标导向型 (第10段)",
    "content": "...*解决问题时**，结合 **因果分析 + 目标导向** 🔹 **创新时**，用 **第一性原理** 思考，再用 **类比思维** 执行  \n🔹 **做决策时**，先 **发散思维** 产生选项，再 **聚合思维** 选择最优方案  \n🔹 **日常决策用快思考**，但面对**重要决策时要切换慢思考**",
    "url": "/blog/因果思维型与目标导向型",
    "chunkIndex": 9,
    "totalChunks": 10,
    "startPos": 3012,
    "endPos": 3137,
    "originalTitle": "因果思维型与目标导向型"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-0",
    "title": "行为决定思想",
    "content": "行为决定思想\n津巴多心理学\n斯坦福监狱实验：一个人的行为和心态，并不是完全由自己说的算；所处情境对行为的塑造，比我们想象中的更加深刻；外部环境，也许会让人背弃很多他曾经的价值观\n洞见\n    1. 人对一个东西的态度，不是想法决定的，而是行为决定的。一旦有了一个持续的行为，他就会觉得这个行为是对的。\n    2. 选择性注意：人们只会留意那些自己原本就认同的信息。这也是为什么改变一人那么难。\n    3. 想法无法改变想法，环境才能改变想法。\n结论\n人不是先有想法，才有行为，而是先有行为，进而产生支持这种行为的想法。\n不要低估环境对你的影响，它有时可以决定你是谁；更不要低估你自己对自己的影响，别让别人决定你是谁。\n案例：",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 0,
    "totalChunks": 8,
    "startPos": 0,
    "endPos": 315,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-1",
    "title": "行为决定思想 (第2段)",
    "content": "...更不要低估你自己对自己的影响，别让别人决定你是谁。\n案例： 1. 《黑豹纠察队》：拥有超人能力的阿祖小时候被刻意培养成表演型人格（情感忽视），长大后特别需要别人的认可，假如失去这些，对他来说比死还难受，公司以此来从精神控制阿祖，预防失控；人是社会性动物，只要他身在群体中，就无时不刻不受环境的影响，超人也不例外\n认知失调理论\n费斯廷格认为，当人们的行为与他们的信念或态度发生冲突时，他们会感到不适（即“认知失调”），为了消除这种不适，他们会调整自己的想法来合理化行为。例如，一个人如果做出了某个行为，他们可能会改变之前的态度或信念以使行为看起来合理。\n情绪理论\n情绪的产生往往是对身体行为的反应。例如，人们先笑，才感到快乐，而不是先感到快乐才笑。\n应用\n如何让作家持续写作\n1. 建立写作习惯",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 1,
    "totalChunks": 8,
    "startPos": 315,
    "endPos": 636,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-2",
    "title": "行为决定思想 (第3段)",
    "content": "...到快乐才笑。\n应用\n如何让作家持续写作\n1. 建立写作习惯 设定小的、可实现的目标：从每天写几百字开始，而不是设定过于宏大的目标。通过实际行动（即使是小步）不断强化“我是作家”的身份认同。\n规律性写作：每天在固定时间段安排写作，通过重复行为让大脑逐渐接受并习惯这一活动。这种重复行为会慢慢塑造内心的信念，即“我是一名作家”。\n2. 使用认知失调来强化动力\n根据费斯廷格的认知失调理论，当人们的行为与信念不一致时，他们会感到不适。例如，如果一个人认为自己想成为作家，但又从不写作，这种不协调感会促使他要么调整想法（放弃成为作家的目标），要么调整行为（开始写作）。为了减少这种不适，可以鼓励他先进行写作行为，久而久之，他会调整内心的信念，进一步强化作家身份。\n3. 奖励和反馈机制",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 2,
    "totalChunks": 8,
    "startPos": 636,
    "endPos": 945,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-3",
    "title": "行为决定思想 (第4段)",
    "content": "...调整内心的信念，进一步强化作家身份。\n3. 奖励和反馈机制 自我奖励：为每次完成写作任务设置奖励，比如看一部喜欢的电影，或者吃一顿好吃的餐食。通过这种行为与奖励的关联，强化写作的积极意义。\n外部反馈：让他将写作成果分享给朋友、写作群体，获得外部的认可和反馈。正面的评价和认可会进一步促使他保持写作的行为，并强化成为作家的自我认知。\n4. 情境控制和行为提示\n行为暗示：在写作环境中放置一些与作家身份相关的物品，比如书籍、文具，或与写作相关的目标清单等，通过这些视觉暗示刺激写作行为。\n消除干扰：为自己设定一个专注的写作环境，减少外界干扰。这样可以增加实际写作行为发生的频率，进一步培养写作习惯。\n通过这些方式，想成为作家的人可以从日常的小行为入手，逐步通过行为带动内心的想法，进而形成良好的写作习惯和作家身份认同。\n附录\n表演型人格",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 3,
    "totalChunks": 8,
    "startPos": 945,
    "endPos": 1282,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-4",
    "title": "行为决定思想 (第5段)",
    "content": "...，进而形成良好的写作习惯和作家身份认同。\n附录\n表演型人格 表演型人格（Histrionic Personality Disorder, HPD）是一种人格障碍，特征在于个体极度寻求他人关注和赞美，往往通过夸张的情感表达和表演来引起他人的注意。表现出这种人格特质的人通常有以下特点：\n1. **过度的情绪表达**：他们通常以戏剧化、夸张的方式表达情绪，可能对日常事件作出强烈的反应，似乎比实际情况更加情绪化。\n2. **寻求注意**：这类人经常会感到不被关注时很不安，因此会通过各种手段，如穿着夸张、行为浮夸，甚至是制造戏剧性事件，来确保自己成为焦点。\n3. **对他人情感的敏感**：尽管他们很关注自己是否得到关注，却往往难以真正体会他人的情感，而是将他人的反应视为自己吸引注意力的一部分。",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 4,
    "totalChunks": 8,
    "startPos": 1282,
    "endPos": 1599,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-5",
    "title": "行为决定思想 (第6段)",
    "content": "...会他人的情感，而是将他人的反应视为自己吸引注意力的一部分。 4. **人际关系的肤浅和短暂**：表演型人格的人可能会试图通过快速建立密切关系来获得他人的关注，但这些关系通常不够稳固，容易破裂，因为他们更多地关心外在的关注，而非关系本身的深度。\n5. **易受外界影响**：他们通常容易受到他人意见和环境的影响，因为他们的行为往往是为了取悦他人，而非基于自己的内心需求。\n这种人格障碍属于**B型人格障碍**，与自恋型、边缘型人格障碍属于同一类型。表演型人格障碍的根本问题在于缺乏内在的自我认同，个体需要通过外界的认可来确认自己的价值。\n治疗通常包括心理治疗，尤其是认知行为疗法（CBT），帮助患者意识到其行为模式并学会更健康的情绪表达方式。\n原因",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 5,
    "totalChunks": 8,
    "startPos": 1599,
    "endPos": 1893,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-6",
    "title": "行为决定思想 (第7段)",
    "content": "...帮助患者意识到其行为模式并学会更健康的情绪表达方式。\n原因 表演型人格障碍（Histrionic Personality Disorder, HPD）的形成可能受到多种因素的影响，通常是遗传、早期生活经历和环境的复杂交互结果。以下是主要的原因和机制：\n1. **遗传因素**\n有研究表明，表演型人格障碍在家庭中有一定的遗传性。如果家族成员中有人患有类似的情感障碍或人格障碍，其他成员更容易发展出表演型人格。这表明，某些人格特质（如情绪不稳定或外向性格）可能通过基因遗传影响人格形成。\n2. **早期生活经历**\n早期儿童时期的经历对人格发展有重要影响，尤其是情感的表达和处理方式。常见的经历包括：\n**父母的过度溺爱**：如果孩子在成长过程中被父母过度关注，或父母不断强化他们的情感表达，孩子可能会学会通过夸张的行为和情绪来获得关注。",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 6,
    "totalChunks": 8,
    "startPos": 1893,
    "endPos": 2231,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/心理学 - 行为决定思想#chunk-7",
    "title": "行为决定思想 (第8段)",
    "content": "...的情感表达，孩子可能会学会通过夸张的行为和情绪来获得关注。 **情感忽视**：相反，某些孩子可能在情感需求上被忽视，因而学会通过引起他人关注的方式，来填补他们内心的空虚感。\n**不稳定的家庭关系**：家庭中的不稳定因素，如冲突、忽视或不一致的养育方式，可能促使孩子发展出过度依赖外界认可的行为模式。\n3. **文化和社会因素**\n社会和文化的影响也可以促进表演型人格的形成。某些文化或社会环境可能强化了外表、形象和表现自我重要性的价值观。例如，现代媒体和社交平台强调“被看到”以及通过夸张或戏剧化的方式展示自我，可能会助长这一类人格特质的发展。",
    "url": "/blog/心理学 - 行为决定思想",
    "chunkIndex": 7,
    "totalChunks": 8,
    "startPos": 2231,
    "endPos": 2473,
    "originalTitle": "行为决定思想"
  },
  {
    "chunkId": "/blog/改革的目标#chunk-0",
    "title": "改革的目标",
    "content": "改革的目标\n改革在一定程度上涉及到降低交易成本和组织成本。具体来说，改革旨在通过优化资源配置、提升效率、减少不必要的制度性障碍，来推动经济和社会的进步。以下是关于改革如何影响交易成本和组织成本的简要分析：\n1. **交易成本**\n   交易成本是指在市场交易过程中发生的各种成本，包括信息成本、谈判成本、监督成本等。改革可以通过多种方式降低交易成本：\n**制度创新**：通过简化繁琐的行政程序、减少不必要的审批和监管环节，使得市场主体的交易更为高效，减少不确定性。\n**透明度和法制建设**：建立和完善法律法规，增强市场透明度和可预见性，降低信息不对称带来的风险。",
    "url": "/blog/改革的目标",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 283,
    "originalTitle": "改革的目标"
  },
  {
    "chunkId": "/blog/改革的目标#chunk-1",
    "title": "改革的目标 (第2段)",
    "content": "...法规，增强市场透明度和可预见性，降低信息不对称带来的风险。 **技术进步**：推行数字化、信息化等技术手段，简化交易流程，减少交易过程中的中介成本。例如，电子政务的推行使得政府与企业之间的交易更加高效。\n   **例子**：放松对某些行业的管制，允许更多市场主体进入，可以减少由于政府垄断带来的交易壁垒，使得市场交易更加活跃和高效。\n2. **组织成本**\n   组织成本是指企业或政府在组织内部运作中为了协调生产、管理、监督而发生的各种成本。改革可以通过优化管理、改善制度设计来降低这些成本：\n**简政放权**：政府通过减少对经济活动的过度干预，可以让企业在市场中更加灵活地运营，减少过于集中的管理成本。\n**结构调整**：通过改革政府或企业的组织结构，使得决策链条更加简化、管理层级更加精简，从而降低内部协调和管理的成本。",
    "url": "/blog/改革的目标",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 283,
    "endPos": 617,
    "originalTitle": "改革的目标"
  },
  {
    "chunkId": "/blog/改革的目标#chunk-2",
    "title": "改革的目标 (第3段)",
    "content": "...更加简化、管理层级更加精简，从而降低内部协调和管理的成本。 **鼓励创新与效率**：通过推动市场化改革，促使企业提升内部管理效率，减少资源浪费。\n   **例子**：国有企业改革通过引入市场机制，削减冗余人员、改进治理结构，能够减少组织成本，提升企业竞争力。\n3. **广泛的改革目标**\n   除了交易成本和组织成本，改革还包括诸多其他目标：\n**提高生产力**：通过改革释放生产要素的潜力，推动技术进步和创新。\n**促进公平和包容性发展**：通过教育、医疗、养老等方面的社会改革，减少社会不平等，促进可持续发展。\n**环境可持续性**：推动绿色改革，减少对环境的破坏，促进资源节约型和环境友好型社会的建设。\n结论\n虽然改革确实可以显著降低交易成本和组织成本，但其本质在于通过**系统性变革**来提高整个经济和社会体系的效率、适应性和公平性。",
    "url": "/blog/改革的目标",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 617,
    "endPos": 959,
    "originalTitle": "改革的目标"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-0",
    "title": "精英过剩：理解、起源与历史镜鉴",
    "content": "当然可以。以下是整理后的文章：\n精英过剩：理解、起源与历史镜鉴\n一、什么是“精英过剩”？\n“精英过剩”（Elite Overproduction）是指一个社会中受过良好教育、有抱负并希望获得高社会地位的人数，**远超出实际能够容纳的职位或资源总量**。这会导致精英群体之间的激烈竞争，最终引发政治分裂、社会动荡，甚至革命与政权更替。\n这一现象并非仅发生在当代，而是有深厚的历史根基。现代社会的高等教育扩张、大量培养“准精英”人群，加剧了这种结构性矛盾。\n三、问题的根源是什么？\n精英过剩通常源于以下几个方面：\n1. **教育通胀**：高等教育大众化后，“本科”不再是门槛，而是起点。人们不断通过学历升级维持竞争力，造成教育军备竞赛。",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 0,
    "totalChunks": 8,
    "startPos": 0,
    "endPos": 317,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-1",
    "title": "精英过剩：理解、起源与历史镜鉴 (第2段)",
    "content": "...是起点。人们不断通过学历升级维持竞争力，造成教育军备竞赛。 2. **岗位结构滞后**：社会并没有同步创造那么多高质量的、能匹配“精英期望”的岗位。\n3. **上升通道受阻**：传统的晋升路径（比如考编、升职）变得狭窄或被既得利益集团垄断。\n4. **路径依赖问题**：上一代的成功经验（考大学、考研究生）仍被沿用，但社会已无法承接如此规模的“上升预期”。\n---\n四、这将带来什么问题？\n结构性矛盾会酿成深层危机，主要表现为：\n**社会撕裂**：精英内部的竞争逐渐转化为政治、意识形态上的分裂。\n**去合法性化**：部分精英质疑现有体制的公平性，出现激进派、民粹派、革命派。\n**反制度情绪上升**：精英无法向上，就可能掀桌子、煽动基层群众不满。\n**政治周期动荡**：旧精英集团受到新精英挑战，社会陷入政权不稳或制度更替的循环。\n---",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 1,
    "totalChunks": 8,
    "startPos": 317,
    "endPos": 658,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-2",
    "title": "精英过剩：理解、起源与历史镜鉴 (第3段)",
    "content": "...受到新精英挑战，社会陷入政权不稳或制度更替的循环。\n--- 五、如何应对精英过剩？\n解决精英过剩，并非简单的“减少教育”，而是需要**结构性改革和路径多样化**。\n国内的尝试：\n1. **职教分流（职普分流）**\n   高中阶段将一部分学生引导至职业教育体系，试图打造“技术精英”“实用型人才”，缓解高考内卷和大学挤兑。\n2. **扩展基层岗位、城乡均衡政策**\n   通过扩张基层公务员、乡村振兴项目，为精英提供新的落脚点。\n3. **鼓励创新创业、产业多元化发展**\n   让人才向二三线城市、数字经济、制造业、技术服务等新兴领域扩散。\n国外的有益经验：\n**德国“双元制教育”**：早期将学生分流至普通高中与职业高中，后者与企业深度合作，就业对口率极高。\n**日本“终身雇佣制”的松动**：让人才流动更加自由，鼓励中小企业吸纳人力。",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 2,
    "totalChunks": 8,
    "startPos": 658,
    "endPos": 998,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-3",
    "title": "精英过剩：理解、起源与历史镜鉴 (第4段)",
    "content": "...制”的松动**：让人才流动更加自由，鼓励中小企业吸纳人力。 **美国社区大学体系**：提供更便宜、更灵活的教育路径，避免所有人盲目涌向名校。\n---\n六、精英的路径依赖：是否还有出路？\n当前问题的棘手之处在于：**很多既得利益者本身就是通过旧路径（大学—研究生—官僚/学术/媒体）成功上位的**，因此改革面临制度内阻力。\n这也意味着：继续走“小学→初中→高中→大学→研究生→博士→高位”的道路，将变得**更加拥挤和激烈**。未来可能需要：\n**开辟“横向路径”**：鼓励更多人成为产业精英、技能人才、数字劳动力。\n**打破学历崇拜**：构建“去学历中心化”的社会评价体系。\n**改革教育资源分配**：真正实现因材施教，而非一刀切的升学率导向。\n---\n七、历史镜鉴：精英过剩导致了多少次王朝更替？",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 3,
    "totalChunks": 8,
    "startPos": 998,
    "endPos": 1317,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-4",
    "title": "精英过剩：理解、起源与历史镜鉴 (第5段)",
    "content": "...向。\n---\n七、历史镜鉴：精英过剩导致了多少次王朝更替？ 这一理论的重要支撑来自历史数据研究，尤其是“结构人口动力学”（Cliodynamics），这是由历史学家彼得·特尔钦（Peter Turchin）提出的一门交叉学科，融合历史学、数学建模、社会学。\n特尔钦的观察：\n历史上的王朝更替，常常在精英人口激增、资源分配恶化、社会治理崩塌的三重夹击下发生。\n精英之间的内部斗争往往比民众暴动更具决定性。\n民众动乱多数提供“动能”，真正“掌权”的依然是精英派系的更替或重组。\n中国历史印证这一观点：\n| 历史阶段        | 体现“精英过剩”的表现             | 导致的具体问题                  | 结果或影响                 |",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 4,
    "totalChunks": 8,
    "startPos": 1317,
    "endPos": 1629,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-5",
    "title": "精英过剩：理解、起源与历史镜鉴 (第6段)",
    "content": "...| 结果或影响                 | | ----------- | ----------------------- | ------------------------ | --------------------- |\n| **东汉末年**    | 科举尚未完全普及，但豪门士族数量激增，官位有限 | 士族争权激烈，宦官干政导致党锢之祸，政治腐败   | 社会动荡，黄巾起义爆发，三国割据      |\n| **唐朝中后期**   | 科举扩大，进士数量激增，官职增速跟不上     | 进士内部“牛李党争”等党派斗争，宦官与藩镇割据  | 中央权威弱化，藩镇割据严重，导致安史之乱  |",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 5,
    "totalChunks": 8,
    "startPos": 1629,
    "endPos": 1908,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-6",
    "title": "精英过剩：理解、起源与历史镜鉴 (第7段)",
    "content": "...割据  | 中央权威弱化，藩镇割据严重，导致安史之乱  | | **宋朝晚期**    | 理学兴起，士大夫群体庞大，财政压力大      | 政治派系斗争（新旧党争），政治效率低下，财政紧张 | 军事力量弱化，边疆防御失效，最终被金元侵扰 |\n| **明末**      | 科举录取人数激增，官位饱和，士人失业率高    | 东林党争激烈，宦官专权，政治腐败         | 农民起义频发，李自成攻入北京，明亡     |\n| **清朝末期**    | 旧科举废除后，新式留学生、士人数量激增     | 传统士绅与新兴知识分子冲突，政治体制转型困难   | 政权动荡，辛亥革命爆发，清朝灭亡      |",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 6,
    "totalChunks": 8,
    "startPos": 1908,
    "endPos": 2187,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/精英过剩：起源与历史镜鉴#chunk-7",
    "title": "精英过剩：理解、起源与历史镜鉴 (第8段)",
    "content": "...难   | 政权动荡，辛亥革命爆发，清朝灭亡      | | **20世纪初美国** | 法学院、研究生数量暴增，劳动力市场饱和     | 高学历失业，社会不满情绪上升           | 政治极化，社会分裂加剧，动荡频发      |\n---\n八、结语：精英不是问题，结构才是问题\n“精英”本身并不可怕，一个社会也需要大量有知识、有担当的人。但当精英的**数量**远远超过结构所能容纳的**位置**，且他们之间无法达成利益平衡时，问题就来了。\n最终的焦点是：\n如何合理配置精英资源？\n如何保持精英阶层的流动性与自我更新？\n如何建设一个能吸纳多元才能的社会结构？\n如果不解决这些问题，无论是美国、中国，还是任何文明国家，都可能在“精英过剩”的压力下，走向分裂、动荡乃至崩塌。",
    "url": "/blog/精英过剩：起源与历史镜鉴",
    "chunkIndex": 7,
    "totalChunks": 8,
    "startPos": 2187,
    "endPos": 2498,
    "originalTitle": "精英过剩：理解、起源与历史镜鉴"
  },
  {
    "chunkId": "/blog/绝对价值与相对价值#chunk-0",
    "title": "**绝对价值 vs. 相对价值**",
    "content": "**绝对价值 vs. 相对价值**  \n1. **绝对价值**（Absolute Value）  \n指事物本身所具有的内在价值或客观效用，与外部比较无关。  \n例如：黄金有化学稳定性、导电性、稀缺性，因此具有较高的绝对价值。  \n2. **相对价值**（Relative Value）  \n价值的评估取决于对比和背景，而非事物本身的属性。  \n例如：一杯水在沙漠中比在城市里更珍贵，iPhone 15 的价值是基于与前代机型或竞品的对比得出的。  \n**现实中，人们更偏向相对价值**  \n1. **决策时的参照点效应**  \n人们倾向于基于**比较**而非独立评估。例如，在购物时，一个打折的商品可能比原价商品更吸引人，即使实际价值未必更高。  \n2. **行为经济学中的锚定效应**",
    "url": "/blog/绝对价值与相对价值",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 346,
    "originalTitle": "**绝对价值 vs. 相对价值**"
  },
  {
    "chunkId": "/blog/绝对价值与相对价值#chunk-1",
    "title": "**绝对价值 vs. 相对价值** (第2段)",
    "content": "...值未必更高。  \n2. **行为经济学中的锚定效应** 例如，顾客看到一件商品原价 1000 元，折后 600 元，会觉得它更“值”，即使它的实际绝对价值可能远低于 600 元。  \n3. **社会竞争心理**  \n很多时候，价值判断与社会地位相关。例如，豪车和奢侈品的价值更多取决于“与他人相比”，而非其物理属性。  \n4. **市场价格机制**  \n股票、房价、货币等的价值很大程度上是相对的，受供需、情绪和市场环境影响，而非其内在的绝对价值。  \n为什么?\n现实中，人们更偏向**相对价值**，主要原因来自**认知限制、社会比较、进化心理**以及**市场机制**等多个因素。  \n**2. 社会比较心理：价值感来源于“比别人好”**  \n人是社会性动物，价值判断往往来自**与他人的比较**，而非事物本身的绝对属性。",
    "url": "/blog/绝对价值与相对价值",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 346,
    "endPos": 682,
    "originalTitle": "**绝对价值 vs. 相对价值**"
  },
  {
    "chunkId": "/blog/绝对价值与相对价值#chunk-2",
    "title": "**绝对价值 vs. 相对价值** (第3段)",
    "content": "...往往来自**与他人的比较**，而非事物本身的绝对属性。 **地位驱动**：人们更在意自己比别人更富有、更成功，而非单纯的财富多少。例如，一个人年收入 50 万，但身边人都赚 100 万，他可能比一个年入 30 万、但身边人都赚 20 万的人更焦虑。  \n**炫耀性消费**：奢侈品的价值很大程度上是因为“别人没有”或者“比别人的更贵”，而不是因为它本身的功能多么优越（劳力士手表 vs. 电子表）。  \n👉 **社会竞争让人更关注相对价值，而非绝对价值。**  \n---\n**3. 进化心理：适应性生存策略**  \n从进化角度看，人类的祖先在**资源有限、竞争激烈**的环境中，**关注相对优势更有生存价值**。  \n**资源分配**：如果部落里食物稀缺，重要的不是“绝对上有多少食物”，而是“比别人多多少”。拥有相对优势，生存概率更高。",
    "url": "/blog/绝对价值与相对价值",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 682,
    "endPos": 1027,
    "originalTitle": "**绝对价值 vs. 相对价值**"
  },
  {
    "chunkId": "/blog/绝对价值与相对价值#chunk-3",
    "title": "**绝对价值 vs. 相对价值** (第4段)",
    "content": "...”，而是“比别人多多少”。拥有相对优势，生存概率更高。 **择偶竞争**：很多生物（包括人类）在择偶时，会关注**相对地位**，比如男性的社会地位、女性的外貌吸引力，都是基于群体内比较，而非绝对数值。  \n👉 **关注相对价值，是进化塑造出的竞争适应性策略**。  \n---\n**4. 市场机制：价格和价值受供需影响**  \n现实世界的市场体系，本质上也是**基于相对价值的博弈**。  \n**定价策略**：商家不会单纯按照“成本+利润”定价，而是依据竞争对手的定价、用户的心理价位等**相对因素**定价。  \n**投机市场**：股票、房产、比特币的价格更多依赖市场情绪和相对预期，而不是某个固定的“绝对价值”。  \n👉 **市场经济环境也强化了人们关注相对价值的习惯**。  \n---\n**总结：相对价值更符合人性和现实逻辑**",
    "url": "/blog/绝对价值与相对价值",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 1027,
    "endPos": 1369,
    "originalTitle": "**绝对价值 vs. 相对价值**"
  },
  {
    "chunkId": "/blog/绝对价值与相对价值#chunk-4",
    "title": "**绝对价值 vs. 相对价值** (第5段)",
    "content": "...---\n**总结：相对价值更符合人性和现实逻辑** | **因素** | **为什么人更关注相对价值？** |  \n|------------|----------------|  \n| **认知限制** | 绝对价值难以直观判断，相对价值更易感知 |  \n| **社会比较** | 人们更在意自己是否比别人更好，而非绝对数值 |  \n| **进化心理** | 竞争环境让相对优势成为生存关键 |  \n| **市场机制** | 供需波动导致价格和价值以相对标准衡量 |  \n**绝对价值**在科学、工程、基础生存需求（如粮食、空气）等方面很重要，但在人类的日常决策、经济活动和社会互动中，**相对价值往往是核心驱动力**。",
    "url": "/blog/绝对价值与相对价值",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1369,
    "endPos": 1654,
    "originalTitle": "**绝对价值 vs. 相对价值**"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-0",
    "title": "麦理浩径（MacLehose Trail）",
    "content": "麦理浩径（MacLehose Trail）\n作为香港四大著名行山径之一的麦理浩径，全程百公里，是香港最早启用的一条长途远足径，于1979年10月26日启用，以时任香港总督麦理浩命名～\n第一段和第二段有便利店可以补给，第三段和第四段无补给，建议自备食物和水。第五段有士多可以买食物和水，第六段到第十段有合法营地可以补给。\n!全程总结表\n!全程路线\n第一段\n北潭涌——浪茄\n基本平地，难度较低，风景还行\n长度+横切面\n第二段（目标）\n简介\n*选择第二段原因：难度均衡，风景很好，据说是最精华的一段*\n路线：万宜水库东坝（实际是浪茄，距离东坝30分钟步行路程，但是看滴滴无法直接到达浪茄，所以选择东坝） - 北潭凹\n难度指数：3 （4个上下峰）\n风景指数：5\n徒步时长：6小时（不紧不慢）",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 0,
    "totalChunks": 8,
    "startPos": 0,
    "endPos": 342,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-1",
    "title": "麦理浩径（MacLehose Trail） (第2段)",
    "content": "...（4个上下峰）\n风景指数：5\n徒步时长：6小时（不紧不慢） 共5小时（咱普通人得6小时）：万宜水库东坝 - (30 min) -（浪茄-西灣山-吹筒坳（ 1 hr 40 min））-(20 min)- 西湾 - 50 min - 鹹田灣 - 50 min - (大浪坳 赤徑) - 45 min - 北潭凹\n!麦理浩径1-2段\n*第二段：浪茄-北潭凹*\n!第二段横切面\n计划\n整体\n（中途没有专门午休时间，所以前一晚睡好点）\n1. 福田口岸 10点集合 \n2. 入关 + 打车 + 路程1个小时到万宜水库东坝（早上11：30点，吃个午饭（带上个汉堡或者其他食物），12点从山脚出发） \n3. 徒步 6 小时（+缓冲半小时）",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 1,
    "totalChunks": 8,
    "startPos": 342,
    "endPos": 624,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-2",
    "title": "麦理浩径（MacLehose Trail） (第3段)",
    "content": "...12点从山脚出发） \n3. 徒步 6 小时（+缓冲半小时） 4. 下午6点半下山（北潭凹） - 打车+出关+路程（耗时1个半小时）到福田口岸（晚上8点，吃晚饭）；PS：如果是全程公交，则到福田口岸是10点\n细节\n徒步前准备\n港澳通行证\n流量：提前两天在支付宝或者官网买跨境流量\n货币：支付宝能用了么？\n如果兑换：建议人均换 300 人民币，带小面额\n八达通（地铁，BUS）：是否需要购买？支付宝能用了么？\n长期不使用的八达通会被禁止使用，重新激活之前无法充值、消费；需要先到香港地铁站（任意一个）内的乘客服务中心通过工作人员激活，激活后即可正常使用。\n水/食物\n建议携带2-3L的水，巧克力，水果等。（虽然中途有便利店补给，但是距离比较远，**强烈建议自带足够的补给**）\n日常\n拖鞋（想感受美丽沙滩的记得带上），泳圈（感受海浪的魅力）\n徒步裤子\n徒步衣服",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 2,
    "totalChunks": 8,
    "startPos": 624,
    "endPos": 973,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-3",
    "title": "麦理浩径（MacLehose Trail） (第4段)",
    "content": "...滩的记得带上），泳圈（感受海浪的魅力）\n徒步裤子\n徒步衣服 徒步鞋子（有个300米的爬坡），视自身情况带登山杖\n遮阳伞\n帽子\n防晒霜\n创口贴\n驱蚊水\n...\n交通（去目的地）：福田口岸（落马洲地铁站（LOK MA CHAU STATION）） - 万宜水库（东坝）\n    1. 打车（耗时 1 小时；PS：巴士只能到西坝（东西坝距离1小时步行））\n出租车： (360-399)港币左右/辆，如果是多个人一起出行，\n滴滴出行（大概349.5HKD - 399HKD），不可选多座（多于4人得注意，最好能凑 4 的倍数人）\n    2. 公交+打车（耗时 1小时左右，可能需要等比较长时间地铁）\n落马洲到大学站（5站22分钟左右）\n打车从大学站到东坝（40分钟左右，233港币）",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 3,
    "totalChunks": 8,
    "startPos": 973,
    "endPos": 1282,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-4",
    "title": "麦理浩径（MacLehose Trail） (第5段)",
    "content": "...分钟左右）\n打车从大学站到东坝（40分钟左右，233港币） 3. 公交（总过程2个多小时，这种方式比较便宜，转车多次，耗时较长，返程可考虑）\n深圳福田口岸过关就到落马洲\n地铁+公交（1小时22分）：落马洲（A 口）-9站34分- 九龙塘（换乘观塘线） -4站7分- 彩虹（C1 口） -走路3分钟- 龙翔道公交站（新界区专线小巴1路） -2站18分钟- 福民路小巴总站 -走路3分钟- 西贡总站（可以吃个午饭然后去（西贡西（东）郊野公园（Sai Kung East Country Park），也即 1-2-3-... 所在地））\n再打车到“万宜水库”东坝 35分钟（大概一辆车100港币，滴滴显示为 148HKD）。",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 4,
    "totalChunks": 8,
    "startPos": 1282,
    "endPos": 1566,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-5",
    "title": "麦理浩径（MacLehose Trail） (第6段)",
    "content": "...5分钟（大概一辆车100港币，滴滴显示为 148HKD）。 徒步中（下面会有个 planB 中途撤离）：全程15公里（网上有说13.5公里，也有说14公里的），起点处的东壩水库，沿途还会经过3处海湾（浪茄湾、西湾、咸田湾，每个海滩都有洗手间），一直行走在山峦丛林之中，真正的“上山下海”。 \n万宜水库东坝 (high island reservoir east dam，对应西坝 high island reservoir west dam) 地图有联合国教科文组织地质公园\n可以考虑去趟 **破边洲** （风景很美，过去回来需要额外 +2小时）\n浪茄（最美沙滩，海浪还比较大，带上泳圈可以感受海浪的魅力）\n西湾山（全程最高点-风景很好-西湾山海拔314米，中上难度），下山后这里可以执行 **PlanB** 返程（需要赶在6点前返回）\n吹筒坳（下山就到）",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 5,
    "totalChunks": 8,
    "startPos": 1566,
    "endPos": 1916,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-6",
    "title": "麦理浩径（MacLehose Trail） (第7段)",
    "content": "...nB** 返程（需要赶在6点前返回）\n吹筒坳（下山就到） 西湾（又一个靓丽海滩，，大浪西湾） \n鹹田灣（海滩）\n大浪坳\n赤徑（右边有海湾）\n北潭凹（PAK TAM AU）\n返程\n打车+公交（暂定：打车从北潭凹打车到大学站，然后地铁从大学站到落马洲）\n打车（1个小时，价格跟回去类似）：北潭凹（第三段起点，应该好分辨，地图上看起来有公交站，应该好打车）打车返回落马洲地铁站\n公交（需要注意下公交运营时间），跟来时类似\n或者先乘公交到好打车的点，再打车回来\nReference\n谷歌地图（参考徒步路径）\n滴滴打车（参考打车路线，及其费用）\n高德地图（参考公交路线）\n1-2段的参考图来源（链接里面风景图很多） https://m.tangshui.net/post/show/5b291b1b368ec06d0fcedf84#tangshui",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 6,
    "totalChunks": 8,
    "startPos": 1916,
    "endPos": 2257,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/麦理浩径徒步攻略#chunk-7",
    "title": "麦理浩径（MacLehose Trail） (第8段)",
    "content": "...1b1b368ec06d0fcedf84#tangshui 路线中的凹凸地势图来源 https://www.hillmanblog.com/project/maclehose-trail-2/\n徒步时间来源 https://www.oasistrek.com/mac_trail_two.php\n香港麦理浩径第二段： 轻松的路线，风景也是醉美\n第三段\n各个风景点+横切面\n长度+横切面\n第四段\n长度+横切面",
    "url": "/blog/麦理浩径徒步攻略",
    "chunkIndex": 7,
    "totalChunks": 8,
    "startPos": 2257,
    "endPos": 2430,
    "originalTitle": "麦理浩径（MacLehose Trail）"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-0",
    "title": "Reference",
    "content": "《上帝掷骰子吗》在更深层次上探讨了量子力学带来的哲学与科学观念的变革，主要集中在三个更深刻的思想层面：\n1. **客观实在与观测者的关系**\n   量子力学带来的一个极具争议的观点是，观测者的行为会影响到被观测的物体。这在经典物理学中是不可想象的，因为经典物理认为客观世界独立于观察者而存在。但量子力学中的“测量问题”表明，当一个微观粒子被测量时，它的状态会发生“坍缩”，从多种可能的状态中瞬间变成一个确定的状态。举例来说，在“双缝实验”中，粒子通过双缝时若未被观测，它会表现为波的干涉现象，但一旦进行观测，粒子则表现为粒子性，通过其中一个缝隙。这意味着“实在”并非完全客观，而是会因观测者的介入而改变。",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 0,
    "totalChunks": 8,
    "startPos": 0,
    "endPos": 303,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-1",
    "title": "Reference (第2段)",
    "content": "...这意味着“实在”并非完全客观，而是会因观测者的介入而改变。 这种现象带来的一个深刻问题是：**我们的现实到底是不是独立存在的？还是说，现实是依赖于意识和观察的？这是量子力学对哲学的一个挑战，打破了“物理现实是独立存在的”这一传统观念。**\n2. **确定性与自由意志的冲突**\n   在经典物理中，世界遵循因果律，可以通过定律预测未来，具有高度确定性。然而，量子力学指出，微观粒子的状态在本质上是随机的，没有所谓的“隐藏变量”来解释所有现象。这种随机性引发了对自由意志的深层思考：如果世界本质上是随机的，那么人类是否也具有某种“选择的自由”？或者我们的行为是否受限于量子的随机性？",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 1,
    "totalChunks": 8,
    "startPos": 303,
    "endPos": 567,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-2",
    "title": "Reference (第3段)",
    "content": "...某种“选择的自由”？或者我们的行为是否受限于量子的随机性？ 作者通过量子力学的视角带出了“自由意志”与“宿命论”的争论。在量子力学中，**世界的根本规律是不确定的，这是否意味着宇宙具有某种自我演化的自由？人类的思想与决策是否也受到这种不确定性的支配，从而可能打破绝对的因果性？**\n3. **世界的多重性与可能性**\n   量子力学引入了“多世界解释”这一激进的观点，提出所有可能的量子状态都真实存在，只是在不同的平行宇宙中实现。比如，在测量一个电子的自旋方向时，电子的自旋会随机地“向上”或“向下”，但在多世界解释中，这两个状态并非仅是可能性之一，而是在不同的平行宇宙中都发生。这意味着，我们的宇宙可能是众多宇宙中的一个，每个宇宙都包含一种不同的可能性。",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 2,
    "totalChunks": 8,
    "startPos": 567,
    "endPos": 869,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-3",
    "title": "Reference (第4段)",
    "content": "...宙可能是众多宇宙中的一个，每个宇宙都包含一种不同的可能性。 多世界解释激起了关于“存在”本身的反思：**如果存在的是无穷多个宇宙，那么我们所感知的现实是否仅仅是其中一种状态？这个观点挑战了传统的实在观，也带来了“我们是谁”“我们存在于何处”的问题。这一层次的讨论在哲学上是极其深刻的，质疑了人类对自我与现实的认识。**\n更多深刻的观点\n1. **科学确定性与“未知之海”**\n   量子力学的引入迫使人类承认知识的边界。尽管科学一直以来追求确定性，但量子力学揭示了在基本粒子的层面上，世界存在无法精确确定的“模糊地带”。书中探讨到，科学家们面临一个困境：我们的模型和定律能否真正反映自然的本质，还是说这些理论仅是对现象的粗略近似？作者暗示，人类可能永远无法彻底掌握宇宙的根本规律，因为宇宙可能本质上就存在不确定性——这是科学所不可突破的界限。",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 3,
    "totalChunks": 8,
    "startPos": 869,
    "endPos": 1214,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-4",
    "title": "Reference (第5段)",
    "content": "...宇宙可能本质上就存在不确定性——这是科学所不可突破的界限。 这种对“未知”的接受改变了科学观念：科学不再被看作揭示绝对真理的工具，而是不断修正、接近真理的过程。这一思想重新定义了科学，让人类意识到，宇宙可能永远不会向我们展示它的完整真相。\n2. **数学的极限与现实的匹配**\n   书中探讨了数学和物理学之间的微妙关系：数学构建了量子力学的框架，使科学家能够进行极为精确的计算，但这些数学结构是否真正描述了现实？比如，量子力学方程中的波函数在数学上描述了粒子的所有可能状态，但一旦观察发生，这些可能性就“坍缩”为一个确定的结果。",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 4,
    "totalChunks": 8,
    "startPos": 1214,
    "endPos": 1453,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-5",
    "title": "Reference (第6段)",
    "content": "...态，但一旦观察发生，这些可能性就“坍缩”为一个确定的结果。 这种现象引发了一个哲学思考：数学是否是自然的“语言”，或者它仅仅是人类对世界的一种抽象工具？如果数学是自然本身的组成部分，那么我们的宇宙可能符合某种“数学实在论”；否则，数学只是一个模拟现实的工具，不能保证揭示宇宙的根本真理。这一思考带来了对“数学宇宙观”的质疑——数学究竟是真实的，还是仅仅是人类理解自然的一种方式？\n3. **意识在宇宙中的作用**\n   量子力学的测量问题引出了对意识的探讨：为什么观测会导致量子状态的坍缩？这种“意识导致实在”的观点让一些科学家和哲学家推测，意识可能在构建现实中起到了某种作用。作者引用了一些量子力学的实验，如“双缝实验”，表明观察行为可能并不仅仅是被动的过程，而是对实在产生了直接影响的行为。",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 5,
    "totalChunks": 8,
    "startPos": 1453,
    "endPos": 1774,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-6",
    "title": "Reference (第7段)",
    "content": "...可能并不仅仅是被动的过程，而是对实在产生了直接影响的行为。 这一思想引发了意识与实在的关系的深层讨论：是否意识参与了宇宙的创造，或者说宇宙的某些层面必须依赖意识才能显现？这种想法在哲学上有着深远的影响，因为它暗示意识不仅仅是宇宙的偶然产物，而是可能与宇宙的结构本质上不可分离。这种“参与性实在”在科学领域并未得到完全接受，但它提供了关于意识和物质之间关系的全新视角。\n4. **宇宙的目的性与自组织性**\n   量子力学所揭示的随机性使人类不得不重新思考宇宙的目的性：如果宇宙的基础是不可预测的、随机的，那么宇宙是否有目的？作者探讨了宇宙是否可能是一种自组织的系统，即没有预设目的，而是通过量子力学的随机性和自然选择的过程，逐渐发展出复杂的结构和生命。这种思想类似于复杂性科学的观点：宇宙可能没有预设的“目标”，而是通过无数随机性逐步演变出秩序。",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 6,
    "totalChunks": 8,
    "startPos": 1774,
    "endPos": 2121,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/上帝掷骰子了吗#chunk-7",
    "title": "Reference (第8段)",
    "content": "...可能没有预设的“目标”，而是通过无数随机性逐步演变出秩序。 这种“无目的的目的性”挑战了传统的哲学思想，也影响了人类对自我、生命意义和宇宙本质的理解。它暗示，宇宙的秩序和人类的存在或许并非出于某种设计，而是随机与秩序相互作用的自然结果。这种观点将量子力学的随机性提升到更广泛的宇宙观层面，给出了一个关于宇宙进化的自然性解释。\nReference\ngpt",
    "url": "/blog/上帝掷骰子了吗",
    "chunkIndex": 7,
    "totalChunks": 8,
    "startPos": 2121,
    "endPos": 2270,
    "originalTitle": "Reference"
  },
  {
    "chunkId": "/blog/关于管理#chunk-0",
    "title": "任务分配管理",
    "content": "任务分配管理\n明确要素\n截止时间\n负责人\n背景：解决了什么问题\n目标：任务的目标\n目标管理：SMART原则（S=Specific、M=Measurable、A=Attainable、R=Relevant、T=Time-bound）\n标准：完成交付的标准\n其他要素\n反馈时间（及时反馈）\n风险点（可能影响进度点）\n资源（可以调度的资源）\n关键决策汇报管理\n三步走\n1. 问题是什么？\n2. 影响这个问题的关键有哪些？\n3. 你的建议方案？\n共识管理\n拉齐共识\n1. 团队周报：现阶段遇到的问题？视野+案例\n2. 例会\n会议管理\n专题/例行会议\n会议组织\n背景\n时间\n地点\n主持\n参会人员\n会议目的：了解真相\n会议纪要\n议题：出了什么问题？\n现状分享：问题的现状和资源情况\n方案讨论：问题的解决提议跟意见",
    "url": "/blog/关于管理",
    "chunkIndex": 0,
    "totalChunks": 2,
    "startPos": 0,
    "endPos": 351,
    "originalTitle": "任务分配管理"
  },
  {
    "chunkId": "/blog/关于管理#chunk-1",
    "title": "任务分配管理 (第2段)",
    "content": "...分享：问题的现状和资源情况\n方案讨论：问题的解决提议跟意见 形成决议：做出方案决策\n执行分工：确认分工跟执行责任人\n好纪要原则\n匹配：与会议目的流程匹配\n目的：复盘回顾，分析责任？确认目标，计划分工？\n负责：基于目标确定谁为会议纪要负责\n一致：参会人员对于会议目标，意义，以及责任人达成共识\n例会\n作用\n分享，收集，产生信息\n协调步调\n推动进度\n意义\n过程管理\n文化管理\n!例会管理\nReference\n如何写好公司会议中的会议纪要？\n如何写好会议纪要？\n例会的意义？",
    "url": "/blog/关于管理",
    "chunkIndex": 1,
    "totalChunks": 2,
    "startPos": 351,
    "endPos": 555,
    "originalTitle": "任务分配管理"
  },
  {
    "chunkId": "/blog/可能性的艺术#chunk-0",
    "title": "可能性的艺术",
    "content": "简介\n是刘瑜教授的一本比较政治学普及读物，通过30个独立又相互关联的章节，介绍了比较政治学的基本概念、方法和案例，探讨了不同国家和地区的政治现实、政治变迁和政治选择。书中运用了大量的历史、社会、经济和文化数据，以及生动有趣的故事和比喻，帮助读者理解政治的可能性和边界，以及政治对个人和社会的影响。\n主要观点\n书名中的“可能性”指的是政治可以创造出不同的社会现实，但也受到一些客观条件的制约。作者认为，政治是一种艺术，而不是一种魔术，它需要在现实和理想之间寻找平衡和妥协。",
    "url": "/blog/可能性的艺术",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 236,
    "originalTitle": "可能性的艺术"
  },
  {
    "chunkId": "/blog/可能性的艺术#chunk-1",
    "title": "可能性的艺术 (第2段)",
    "content": "...术，而不是一种魔术，它需要在现实和理想之间寻找平衡和妥协。 书中提出了两个比较政治学的核心维度：民主问责和国家能力。民主问责是指政府是否受到公民的监督和制约，是否能反映公民的意愿和利益。国家能力是指政府是否有能力维护社会秩序、提供公共服务、促进经济发展等。作者认为，这两个维度并不一定互相冲突或者互相促进，而是有可能形成不同的组合，导致不同的政治结果。\n书中分析了各种不同类型的政体，如威权政体、民主政体、联邦制、单一制、总统制、议会制等，以及它们各自的优缺点、适应条件和变迁路径。作者认为，没有一种政体是完美无缺或者适用于所有情况的，而是要根据具体的历史、文化、经济和社会背景来选择和设计。",
    "url": "/blog/可能性的艺术",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 236,
    "endPos": 503,
    "originalTitle": "可能性的艺术"
  },
  {
    "chunkId": "/blog/可能性的艺术#chunk-2",
    "title": "可能性的艺术 (第3段)",
    "content": "...，而是要根据具体的历史、文化、经济和社会背景来选择和设计。 书中探讨了很多国际上的热点问题，如全球化、文明冲突、民主倒退、国家建构等，并且提供了多角度、多层次、多维度的分析视角。作者认为，要理解当今世界的复杂性和多样性，需要运用比较的视野，把自己所面对的政治现实当作一万种可能性之一来对待，从而获得更深刻和更全面的认识。\n启发\n政治不是一种固定的、单一的、确定的现实，而是一种充满可能性的、多元的、不确定的艺术。我们可以通过比较不同国家和地区的政治制度、政治过程和政治结果，来发现政治的规律和变化，以及政治的优劣和选择。\n政治不是一种与我们无关的、高高在上的、专业化的领域，而是一种与我们密切相关的、平民化的、普及化的活动。我们可以通过参与政治，表达自己的意见和利益，影响政治的决策和行动，以及承担政治的责任和后果。",
    "url": "/blog/可能性的艺术",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 503,
    "endPos": 832,
    "originalTitle": "可能性的艺术"
  },
  {
    "chunkId": "/blog/可能性的艺术#chunk-3",
    "title": "可能性的艺术 (第4段)",
    "content": "...见和利益，影响政治的决策和行动，以及承担政治的责任和后果。 政治是一种平衡性的活动，它需要在现实和理想之间，寻找合适的妥协和折衷。政治不是一种魔术，它不能无视客观条件和主观意愿，而是要在可能性和可行性之间，找到最佳的方案。\n政治是一种相对性的活动，它需要通过比较不同国家和地区的政治制度、政治过程和政治结果，来发现政治的规律和变化，以及政治的优劣和选择。政治不是一种绝对的、直接的、简单的思维，而是一种相对的、间接的、复杂的理性。",
    "url": "/blog/可能性的艺术",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 832,
    "endPos": 1017,
    "originalTitle": "可能性的艺术"
  },
  {
    "chunkId": "/blog/复杂#chunk-0",
    "title": "复杂",
    "content": "复杂\n不论是计算创意学还是游戏设计哲学，都有一个共同的目标：去促成一种超越人类设计能力的、能够让作者自己都感到眼前一亮的前所未有的认知对象的产生和进入视野。而复杂性成为了产生这样的“认知新颖性”的关键。\n作者提出一个复杂系统的定义：复杂系统是有大量组分组成的网络，不存在中央控制，通过简单的运作规则产生出复杂的集体行为和复杂的信息处理，并通过学习和进化产生适应性。\n由于这样的系统在没有内部或外部的控制者的情况下产生了有组织的行为，我们将之称为自组织系统（Self-organizing System）。由于简单规则以难以预测的方式产生出复杂行为，这种系统的宏观行为有时也成为涌现（Emergent）。\n因此复杂系统的另一个定义就是：具有涌现和自组织行为的系统。\n案例",
    "url": "/blog/复杂",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 335,
    "originalTitle": "复杂"
  },
  {
    "chunkId": "/blog/复杂#chunk-1",
    "title": "复杂 (第2段)",
    "content": "...杂系统的另一个定义就是：具有涌现和自组织行为的系统。\n案例 1. 蜂群行为与涌现现象：每只蜜蜂的行为是简单且局部的，例如它们通过气味和跳舞来传递信息，告诉其他蜜蜂哪里有食物。但是，蜜蜂个体之间的这些简单互动，通过群体的协作，能够形成高度复杂的集体行为，如寻找食物和建造蜂巢等。\n2. 沙堆实验与临界性：将沙粒逐渐加入到一个沙堆中，直到某一时刻，堆积物会突然崩塌。重要的是，崩塌的时刻无法预测，甚至无法从之前的行为模式中推断出何时会发生。每颗沙粒看似不起眼，但它们的堆积会导致整个系统发生突变。",
    "url": "/blog/复杂",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 335,
    "endPos": 552,
    "originalTitle": "复杂"
  },
  {
    "chunkId": "/blog/复杂#chunk-2",
    "title": "复杂 (第3段)",
    "content": "...。每颗沙粒看似不起眼，但它们的堆积会导致整个系统发生突变。 3. 金融市场与复杂性：在金融市场中，投资者的行为往往是基于对未来的预期，而这些预期往往是建立在对他人行为的猜测之上。举例来说，在2008年全球金融危机前，房地产市场和股市形成了泡沫，投资者普遍认为价格将继续上涨，这导致了过度投资和借贷。而当市场开始崩塌时，投资者恐慌，导致市场在极短时间内剧烈波动。这个例子展示了金融市场的非理性行为、群体心理和反馈机制如何导致整个系统产生剧烈的波动。市场中的“局部稳定”可以掩盖全局不稳定性，直到某一突发事件引发大规模崩溃。\n4. 大脑神经元网络：大脑神经元网络是一个复杂系统，它通过简单的运作规则（如神经递质传递和突触连接）产生出复杂的集体行为（如学习和记忆）。神经元网络的局部连接和简单规则可以导致涌现出高级认知功能，如意识和自我意识。",
    "url": "/blog/复杂",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 552,
    "endPos": 891,
    "originalTitle": "复杂"
  },
  {
    "chunkId": "/blog/复杂#chunk-3",
    "title": "复杂 (第4段)",
    "content": "...接和简单规则可以导致涌现出高级认知功能，如意识和自我意识。 5. 免疫系统：免疫系统通过简单的运作规则（如识别抗原和产生抗体）产生出复杂的集体行为（如抵抗疾病和适应性免疫）。免疫系统的局部互动和简单规则可以导致涌现出复杂的适应性免疫反应。\n6. 为什么在由自私个体组成的群体中会进化出合作。从底层看\n在进化历程的一定阶段时刻，单细胞生物会互相合作以形成更复杂的多细胞生物。\n接着，又进化出蚁群这样的社会性生物，大部分蚂蚁为了蚁群的整体利益工作，甚至放弃了繁衍的能力，只让蚁后来繁衍后代。\n后来，灵长类动物群体中又涌现了更复杂的社会，社会团结，一致对外，复杂的贸易，最终出现了人类国家、政府、法律和国际条约。\n其他\n计算机领域的哥德尔不完备性定理\n网络和图论\n生物代谢的比例之谜\n自复制图灵机\n作者自己在博士论文中设计的类比程序\nReferences",
    "url": "/blog/复杂",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 891,
    "endPos": 1236,
    "originalTitle": "复杂"
  },
  {
    "chunkId": "/blog/复杂#chunk-4",
    "title": "复杂 (第5段)",
    "content": "...作者自己在博士论文中设计的类比程序\nReferences 梅拉妮·米歇尔《复杂》导读\ngpt",
    "url": "/blog/复杂",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1236,
    "endPos": 1253,
    "originalTitle": "复杂"
  },
  {
    "chunkId": "/blog/大脑如何思维#chunk-0",
    "title": "The Cerebral Code",
    "content": "The Cerebral Code\nOne of the defining pillars of physics is the second law of thermodynamics. Energy hates being concentrated. Yet here we are, squishy bags of water and energy suspended a few feet above the ground. It's a bit weird.\n物理学的决定性支柱之一是热力学第二定律。能量讨厌集中。然而我们就在这里，一袋黏糊糊的水和能量悬浮在离地面几英尺的地方。有点奇怪。",
    "url": "/blog/大脑如何思维",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 299,
    "originalTitle": "The Cerebral Code"
  },
  {
    "chunkId": "/blog/大脑如何思维#chunk-1",
    "title": "The Cerebral Code (第2段)",
    "content": "...，一袋黏糊糊的水和能量悬浮在离地面几英尺的地方。有点奇怪。 Schrodinger decided the only way that life was possible was if it led to more entropy throughout the system. Like a tornado, life is a pocket of order that sows disorder. It lives so long as it pays the entropy tax.\n薛定谔认为，生命存在的唯一途径就是在整个系统中产生更多的熵。就像龙卷风一样，生活是一片秩序，却播下了混乱的种子。只要它缴纳熵税，它就会存在。",
    "url": "/blog/大脑如何思维",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 299,
    "endPos": 586,
    "originalTitle": "The Cerebral Code"
  },
  {
    "chunkId": "/blog/大脑如何思维#chunk-2",
    "title": "The Cerebral Code (第3段)",
    "content": "...一片秩序，却播下了混乱的种子。只要它缴纳熵税，它就会存在。 To anthropomorphize a bit, The Universe is trying to maximize entropy but it has a near infinite \"problem space\". One algorithm it has found to solve this problem is evolution. To butcher a computer science phrase, I believe that evolution is the \"best case runtime\" when trying to find increasingly valid solutions to a near infinite problem space.",
    "url": "/blog/大脑如何思维",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 586,
    "endPos": 936,
    "originalTitle": "The Cerebral Code"
  },
  {
    "chunkId": "/blog/大脑如何思维#chunk-3",
    "title": "The Cerebral Code (第4段)",
    "content": "...near infinite problem space. 稍微拟人化一点，宇宙试图最大化熵，但它有一个近乎无限的“问题空间”。它发现解决这个问题的一种算法是进化。用一个计算机科学术语来说，我相信，当试图为近乎无限的问题空间找到越来越有效的解决方案时，进化是“最佳情况运行时”。\nEssentially, biology uses evolution because it is the best way to solve the problem of prediction (survival/reproduction) in a complex world.\n从本质上讲，生物学使用进化，因为它是解决复杂世界中的预测（生存/繁殖）问题的最佳方法。\nReference\n达尔文机器",
    "url": "/blog/大脑如何思维",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 936,
    "endPos": 1247,
    "originalTitle": "The Cerebral Code"
  },
  {
    "chunkId": "/blog/技术封建主义#chunk-0",
    "title": "技术封建主义",
    "content": "技术封建主义\n你是否以为，人类正在进入一个新时代----互联网高科技的时代？\n这本书说 NO，人类更像回到封建时代，只是多了高科技。\n它的书名就叫《技术封建主义》（Techno Feudalism），即技术导致的封建主义。\n作者雅尼斯·瓦鲁法基斯（Yanis Varoufakis）也不寻常。\n他是一个希腊的经济学家，曾经被 Valve 公司（世界最大游戏平台 Steam 的创造者）聘用，后来成为希腊的财政部长，离任后写了这本书。\n历史上，封建主义盛行在中世纪的欧洲，指的是大地主（又称为领主）占有大片土地，控制土地上的一切，农民也变成领主的私人财产（即农奴）。\n这跟现在的互联网有相似之处。",
    "url": "/blog/技术封建主义",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 298,
    "originalTitle": "技术封建主义"
  },
  {
    "chunkId": "/blog/技术封建主义#chunk-1",
    "title": "技术封建主义 (第2段)",
    "content": "...成领主的私人财产（即农奴）。\n这跟现在的互联网有相似之处。 互联网虽然大，但是占有统治地位的，就是那几家公司：谷歌、苹果、微软、亚马逊、Meta......它们是互联网领主，瓜分了大部分的数字领地。\n在自己的领地上，它们就是掌管一切的王。\n这本书进一步说，广大的网民实际上是数字农奴（又称云奴）。你在人家的领地里发帖子、上传照片视频，就是为领主工作。你拿不到多少回报，你的免费劳动只是为领主的公司增加价值。\n久而久之，你甚至还会产生心理依赖，一天不去领主的土地看看，心里就会万分失落。\n这些数字领主有强烈的领地意识，造出了高高的围篱，防止自己的数字资产（数据）流出，或者领地被其他公司侵占。",
    "url": "/blog/技术封建主义",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 298,
    "endPos": 564,
    "originalTitle": "技术封建主义"
  },
  {
    "chunkId": "/blog/技术封建主义#chunk-2",
    "title": "技术封建主义 (第3段)",
    "content": "...，防止自己的数字资产（数据）流出，或者领地被其他公司侵占。 如果你要使用某个领主的领地，必须交付地租（使用费）。比如，你要把自己的 App 放在苹果应用商店出售，就必须把30%的收入交给苹果。这是苹果对它的数字领地收取的地租，跟中世纪的封建制度一模一样。\n我看了书中的描述，真是脑洞大开，原来高大上的互联网经济，本质跟封建时代的地租没啥两样。\n作者瓦鲁法基斯建议，为了打破技术封建主义，防止数字领主的出现，政府必须实行一些强制措施。\n（1）征收云税，降低数字领主获取的云地租。\n（2）推行统一的数字身份，不要让每个网站都推行自己的用户体系。一旦用户使用谷歌、微软、苹果等大公司的用户身份，表示自己的互联网身份，他就会依赖这些大公司，不得不受制于它。设想一下，如果某一天你突然失去了微信账户，生活会多么不方便。",
    "url": "/blog/技术封建主义",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 564,
    "endPos": 889,
    "originalTitle": "技术封建主义"
  },
  {
    "chunkId": "/blog/技术封建主义#chunk-3",
    "title": "技术封建主义 (第4段)",
    "content": "...想一下，如果某一天你突然失去了微信账户，生活会多么不方便。 （3）推行数据共享。用户在某个应用产生的数据，应该可以移植到其他应用。比如，你在推特发的帖子，应该可以移植到其他社交媒体。这样就避免了数据被数字领主垄断。\nReference\n技术封建主义",
    "url": "/blog/技术封建主义",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 889,
    "endPos": 983,
    "originalTitle": "技术封建主义"
  },
  {
    "chunkId": "/blog/毫无意义的工作#chunk-0",
    "title": "毫无意义的工作",
    "content": "简介\n毫无意义的工作这本书主要讲了一些现代社会中存在的无用或有害的工作，作者称之为“狗屁工作”。\n作者分析了这些工作的类型、原因、后果和应对，以及它们对个人和社会的影响。\n作者认为，这些工作是资本主义制度和管理封建主义的产物，它们浪费了人类的时间、创造力和潜能，也加剧了不平等和不满。\n作者提出了一些可能的解决方案，如全民基本收入、缩短工作时间、提高照料类工作的地位等。\n这本书是一部深刻而富有挑战性的社会学著作，引发了广泛的讨论和争议。\n第一章：什么是狗屁工作？ \n介绍了狗屁工作的概念和定义，以及他为什么要写这本书。他认为，狗屁工作是指那些即使消失了也不会对社会造成任何损失，甚至可能有益的工作。他通过网上征集的故事和自己的观察，分析了狗屁工作的类型、特征和分布。",
    "url": "/blog/毫无意义的工作",
    "chunkIndex": 0,
    "totalChunks": 5,
    "startPos": 0,
    "endPos": 335,
    "originalTitle": "毫无意义的工作"
  },
  {
    "chunkId": "/blog/毫无意义的工作#chunk-1",
    "title": "毫无意义的工作 (第2段)",
    "content": "...征集的故事和自己的观察，分析了狗屁工作的类型、特征和分布。 第二章：为什么有这么多狗屁工作？ \n探讨了狗屁工作产生的原因和背景，主要归结于资本主义制度和管理封建主义的逻辑。他指出，资本主义不是一个高效的经济体系，而是一个创造无用或有害的工作的体系。管理封建主义则是指那些通过增加层级和监督来维持自己权力和地位的人。\n第三章：为什么我们不反抗？ \n分析了为什么狗屁工没有组织起来反对这种现象，而是默默忍受或者自我欺骗。他认为，这与社会的价值观、道德观、宗教观、政治观等因素有关。他批判了工作伦理、消费主义、竞争主义等思想，认为它们都是对人类自由和幸福的障碍。",
    "url": "/blog/毫无意义的工作",
    "chunkIndex": 1,
    "totalChunks": 5,
    "startPos": 335,
    "endPos": 584,
    "originalTitle": "毫无意义的工作"
  },
  {
    "chunkId": "/blog/毫无意义的工作#chunk-2",
    "title": "毫无意义的工作 (第3段)",
    "content": "...主义、竞争主义等思想，认为它们都是对人类自由和幸福的障碍。 第四章：狗屁工作对心理健康的影响。 讲述了狗屁工作对人们心理健康的负面影响，包括无聊、压抑、焦虑、愤怒、自卑、孤独等。他引用了一些心理学和社会学的研究，证明了人类需要有意义和创造性的活动，而不是空洞和机械的工作。\n第五章：狗屁工作对社会的影响。 探讨了狗屁工作对社会的影响，主要包括两方面：一是加剧了社会不平等和不公正，二是阻碍了社会进步和创新。他认为，狗屁工作不仅占用了人类的时间、资源和潜能，而且还剥夺了那些真正有用和有意义的工作的尊严和报酬。\n第六章：我们可以做些什么？ 提出了一些可能的解决方案，如全民基本收入、缩短工作时间、提高照料类工作的地位等。他认为，这些方案都可以从根本上改变人们对工作的态度和期待，让人们有更多的自由和选择，从而摆脱狗屁工作的困境。",
    "url": "/blog/毫无意义的工作",
    "chunkIndex": 2,
    "totalChunks": 5,
    "startPos": 584,
    "endPos": 918,
    "originalTitle": "毫无意义的工作"
  },
  {
    "chunkId": "/blog/毫无意义的工作#chunk-3",
    "title": "毫无意义的工作 (第4段)",
    "content": "...和期待，让人们有更多的自由和选择，从而摆脱狗屁工作的困境。 第七章：全民基本收入：一个激进的提案。 详细阐述了全民基本收入（UBI）的含义、理由、效果和挑战。他认为，UBI是一种保障每个人都能获得足够生活水平的无条件现金补贴，它可以解决贫困、失业、歧视等问题，也可以促进人们追求自己真正感兴趣和有价值的事情。\n第八章：缩短工作时间：一个温和的提案。 详细阐述了缩短工作时间的含义、理由、效果和挑战。他认为，缩短工作时间是指减少每周或每天的工作时长，而不是降低工作强度或效率。他认为，缩短工作时间可以提高人们的幸福、健康、平等、生产力等，也可以减少环境污染和资源消耗。",
    "url": "/blog/毫无意义的工作",
    "chunkIndex": 3,
    "totalChunks": 5,
    "startPos": 918,
    "endPos": 1172,
    "originalTitle": "毫无意义的工作"
  },
  {
    "chunkId": "/blog/毫无意义的工作#chunk-4",
    "title": "毫无意义的工作 (第5段)",
    "content": "...幸福、健康、平等、生产力等，也可以减少环境污染和资源消耗。 第九章：为什么照料类工作如此重要？ 详细阐述了照料类工作的含义、价值、困境和改进。他认为，照料类工作是指那些关注他人的需求和福祉的工作，如教育、医疗、护理、家务等。他认为，照料类工作是人类社会的基础和核心，但却经常被忽视和贬低。他主张提高照料类工作的地位和报酬，让更多的人参与其中。\n第十章：一个没有狗屁工作的未来。 展望了一个没有狗屁工作的未来，以及如何实现这个愿景。他认为，这个未来是一个更加自由、平等、多样、创造、协作的社会，人们可以根据自己的兴趣和才能选择自己想做的事情，而不是被迫做无聊或有害的工作。他呼吁人们勇敢地追求这个目标，而不是屈服于现实的压力和束缚。",
    "url": "/blog/毫无意义的工作",
    "chunkIndex": 4,
    "totalChunks": 5,
    "startPos": 1172,
    "endPos": 1457,
    "originalTitle": "毫无意义的工作"
  },
  {
    "chunkId": "/blog/算法之美 - 指导工作与生活#chunk-0",
    "title": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB)",
    "content": "算法之美\n第一章 - 最佳停止时间\n数学家对这个问题，已经有了充分的讨论。经过计算，成功概率最大的方法，叫做\"1/e 法则\"。e 是自然对数的底数，约等于2.718，那么 1/e 就约等于37%，所以它又称\"37%法则\"。\n\"37%法则\"的意思就是，寻找阶段进行到37%就要停止。 100个应聘者，先面试前37个，此后的面试只要遇到一个更优秀的，就立刻录取，不再继续面试了。换句话说，前37个面试者无论多么优秀，都不会录取，他们只是用来确定录取的标准。\n如果最合适的候选者偏偏在前面37%里面，那就只能错过了，作为\"寻找阶段\"不得不付出的成本。最终录取的将是不如前面候选人的次优选择。\n这个法则很实用，日常生活中，只要符合\"寻找-决策过程\"的场景，都可以适用37%法则。",
    "url": "/blog/算法之美 - 指导工作与生活",
    "chunkIndex": 0,
    "totalChunks": 4,
    "startPos": 0,
    "endPos": 336,
    "originalTitle": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB)"
  },
  {
    "chunkId": "/blog/算法之美 - 指导工作与生活#chunk-1",
    "title": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB) (第2段)",
    "content": "...，只要符合\"寻找-决策过程\"的场景，都可以适用37%法则。 （1）相亲时，假定有10个相亲对象，那么前3～4个可以作为寻找阶段，后面只要遇到一个比前面更好的人，就可以同意了。\n（2）租房时，假定有一个月的找房子时间，那么30天的37﹪也就是11天。在找了11天之后，你就要出手了。只要发现比先前更令人心动的房子，就不要犹豫，马上租下来。\n（3）读书时，假定这本书有100页，如果读了37页，还没有发现感兴趣的内容，那就可以放弃了。\n（4）一个10集的电视剧，第4集是最佳弃剧时间。\n（5）一个10分钟的视频，看了3分42秒，如果还是觉得不好看，就可以关掉了。",
    "url": "/blog/算法之美 - 指导工作与生活",
    "chunkIndex": 1,
    "totalChunks": 4,
    "startPos": 336,
    "endPos": 586,
    "originalTitle": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB)"
  },
  {
    "chunkId": "/blog/算法之美 - 指导工作与生活#chunk-2",
    "title": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB) (第3段)",
    "content": "...的视频，看了3分42秒，如果还是觉得不好看，就可以关掉了。 （6）一个年轻人想在18岁到24岁，一共7年时间里找到人生方向，确定未来想做什么。那么，他有2.59年（7 * 0.37）的时间自由尝试。也就是说，到了大三下学期就应该初步定下自己的方向，后面除非遇到更有吸引力的事情，否则就不应该转换事业方向。\n第二章 - 探索与利用：要最新的还是要最好的？\n是一类经典的决策问题，源于赌博场景中的老虎机。假设你在一个赌场里面对多个老虎机，每个老虎机都有不同的但未知的中奖概率。你必须决定如何在这些老虎机之间分配资源（比如投币次数），以便最大化你的总收益。\n问题的核心挑战在于探索与利用的平衡：你需要通过探索尝试不同的老虎机来了解它们的中奖概率（探索），同时也要利用目前收益最高的老虎机（利用），以获得最大的收益。\n第三章 - 排序 建立秩序",
    "url": "/blog/算法之美 - 指导工作与生活",
    "chunkIndex": 2,
    "totalChunks": 4,
    "startPos": 586,
    "endPos": 925,
    "originalTitle": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB)"
  },
  {
    "chunkId": "/blog/算法之美 - 指导工作与生活#chunk-3",
    "title": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB) (第4段)",
    "content": "...机（利用），以获得最大的收益。\n第三章 - 排序 建立秩序 第四章 - 缓存 忘了它吧\n第五章 - 时间调度理论 要事先行\n第六章 - 贝叶斯法则 预测未来\n第七章 - 过度拟合 不要想太多\n第八章 - 松弛 顺其自然\n第九章 - 随机性 何时应用随机\n第十章 - 网络 我们如何联系\n第十一章 - 博弈论 别人的想法\nReferences\n算法之美)",
    "url": "/blog/算法之美 - 指导工作与生活",
    "chunkIndex": 3,
    "totalChunks": 4,
    "startPos": 925,
    "endPos": 1071,
    "originalTitle": "[算法之美](https://www.scribd.com/document/778432015/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E-%E6%8C%87%E5%AF%BC%E5%B7%A5%E4%BD%9C%E4%B8%8E%E7%94%9F%E6%B4%BB)"
  },
  {
    "chunkId": "/blog/置身事内#chunk-0",
    "title": "置身事内",
    "content": "简介\n该书以地方政府投融资为主线，深入浅出地论述了中国经济的发展过程和特点，以及政府在其中所起的重要作用。该书分为上下两篇，上篇解释了地方政府的基本事务、收支、土地融资和开发、投资和债务等微观机制；下篇解释了这些微观行为与城市化、工业化、房价、地区差异、债务风险、国内外贸易冲突等宏观现象的联系。最后一章总结了全书内容，并对当前的市场化改革和政府转型进行了解读。\n主要观点\n政府和市场不是简单的二元分割，而是相互依存和影响的复杂关系。在中国，政府不仅影响资源的分配，也深度参与资源的生产。因此，不能脱离政府来理解经济现象。\n地方政府是经济发展的深度参与者，通过招商引资、土地开发、城市建设等方式，推动了工业化和城市化的进程，在发展经济的同时逐步推动了市场机制的建立和完善。",
    "url": "/blog/置身事内",
    "chunkIndex": 0,
    "totalChunks": 3,
    "startPos": 0,
    "endPos": 337,
    "originalTitle": "置身事内"
  },
  {
    "chunkId": "/blog/置身事内#chunk-1",
    "title": "置身事内 (第2段)",
    "content": "...化的进程，在发展经济的同时逐步推动了市场机制的建立和完善。 地方政府也面临着多重挑战和风险，如财税不平衡、债务压力、产能过剩、环境污染等。这些问题需要通过深化改革和转型来解决，包括要素市场改革、债务化解、再平衡和国内大循环等。\n了解政府认为应该怎么办，比了解“我们”认为应该怎么办，重要得多。因为政府的决策和行动会影响到我们每个人的生活和未来。因此，我们需要置身事内，关注政府的动向和逻辑，增进对中国发展现实的把握。\n启发\n需要从政府的角度来看待中国经济的发展，理解政府的动机、行为和逻辑，以及政府与市场的复杂互动。这有助于我们更好地把握中国经济的现状和未来，以及我们自己在其中的角色和机会。",
    "url": "/blog/置身事内",
    "chunkIndex": 1,
    "totalChunks": 3,
    "startPos": 337,
    "endPos": 604,
    "originalTitle": "置身事内"
  },
  {
    "chunkId": "/blog/置身事内#chunk-2",
    "title": "置身事内 (第3段)",
    "content": "...把握中国经济的现状和未来，以及我们自己在其中的角色和机会。 需要认识到中国经济发展的不平衡和不充分，以及政府面临的挑战和风险。这要求我们不仅要看到经济增长的成果，也要看到经济转型的必要性和紧迫性。我们需要关注政府的改革和转型，以及我们自己如何适应和参与这些变化。\n政府不是万能的，也不是万恶的。政府是由人组成的，人有优点也有缺点，有能力也有局限。政府需要市场的监督和反馈，也需要公民的参与和支持。我们需要理性地看待政府，既不盲目崇拜，也不无端指责。我们需要与政府沟通和合作，共同推动中国经济的发展和进步。\n很多事情从普通人的角度看起来无法理解甚至荒诞，但是站在政府角度却很合理；存在即合理，也即不同视角的合理",
    "url": "/blog/置身事内",
    "chunkIndex": 2,
    "totalChunks": 3,
    "startPos": 604,
    "endPos": 878,
    "originalTitle": "置身事内"
  }
]